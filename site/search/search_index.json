{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentation This directory contains all TypeORM documentation. This documentation is the TypeORM website","title":"Documentation"},{"location":"#documentation","text":"This directory contains all TypeORM documentation. This documentation is the TypeORM website","title":"Documentation"},{"location":"active-record-data-mapper/","text":"Active Record vs Data Mapper What is the Active Record pattern? What is the Data Mapper pattern? Which one should I choose? What is the Active Record pattern? In TypeORM you can use both the Active Record and the Data Mapper patterns. Using the Active Record approach, you define all your query methods inside the model itself, and you save, remove, and load objects using model methods. Simply said, the Active Record pattern is an approach to access your database within your models. You can read more about the Active Record pattern on Wikipedia . Example: import {BaseEntity, Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User extends BaseEntity { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } All active-record entities must extend the BaseEntity class, which provides methods to work with the entity. Example of how to work with such entity: // example how to save AR entity const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.isActive = true; await user.save(); // example how to remove AR entity await user.remove(); // example how to load AR entities const users = await User.find({ skip: 2, take: 5 }); const newUsers = await User.find({ isActive: true }); const timber = await User.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); BaseEntity has most of the methods of the standard Repository . Most of the time you don't need to use Repository or EntityManager with active record entities. Now let's say we want to create a function that returns users by first and last name. We can create such functions as a static method in a User class: import {BaseEntity, Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User extends BaseEntity { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; static findByName(firstName: string, lastName: string) { return this.createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName }) .andWhere(\"user.lastName = :lastName\", { lastName }) .getMany(); } } And use it just like other methods: const timber = await User.findByName(\"Timber\", \"Saw\"); What is the Data Mapper pattern? In TypeORM you can use both the Active Record and Data Mapper patterns. Using the Data Mapper approach, you define all your query methods in separate classes called \"repositories\", and you save, remove, and load objects using repositories. In data mapper your entities are very dumb - they just define their properties and may have some \"dummy\" methods. Simply said, data mapper is an approach to access your database within repositories instead of models. You can read more about data mapper on Wikipedia . Example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } Example of how to work with such entity: const userRepository = connection.getRepository(User); // example how to save DM entity const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.isActive = true; await userRepository.save(user); // example how to remove DM entity await userRepository.remove(user); // example how to load DM entities const users = await userRepository.find({ skip: 2, take: 5 }); const newUsers = await userRepository.find({ isActive: true }); const timber = await userRepository.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); Now let's say we want to create a function that returns users by first and last name. We can create such a function in a \"custom repository\". import {EntityRepository, Repository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository() export class UserRepository extends Repository<User> { findByName(firstName: string, lastName: string) { return this.createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName }) .andWhere(\"user.lastName = :lastName\", { lastName }) .getMany(); } } And use it this way: const userRepository = connection.getCustomRepository(UserRepository); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); Learn more about custom repositories . Which one should I choose? The decision is up to you. Both strategies have their own cons and pros. One thing we should always keep in mind with software development is how we are going to maintain our applications. The Data Mapper approach helps with maintainability, which is more effective in bigger apps. The Active record approach helps keep things simple which works well in smaller apps. And simplicity is always a key to better maintainability.","title":"Active Record vs Data Mapper"},{"location":"active-record-data-mapper/#active-record-vs-data-mapper","text":"What is the Active Record pattern? What is the Data Mapper pattern? Which one should I choose?","title":"Active Record vs Data Mapper"},{"location":"active-record-data-mapper/#what-is-the-active-record-pattern","text":"In TypeORM you can use both the Active Record and the Data Mapper patterns. Using the Active Record approach, you define all your query methods inside the model itself, and you save, remove, and load objects using model methods. Simply said, the Active Record pattern is an approach to access your database within your models. You can read more about the Active Record pattern on Wikipedia . Example: import {BaseEntity, Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User extends BaseEntity { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } All active-record entities must extend the BaseEntity class, which provides methods to work with the entity. Example of how to work with such entity: // example how to save AR entity const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.isActive = true; await user.save(); // example how to remove AR entity await user.remove(); // example how to load AR entities const users = await User.find({ skip: 2, take: 5 }); const newUsers = await User.find({ isActive: true }); const timber = await User.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); BaseEntity has most of the methods of the standard Repository . Most of the time you don't need to use Repository or EntityManager with active record entities. Now let's say we want to create a function that returns users by first and last name. We can create such functions as a static method in a User class: import {BaseEntity, Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User extends BaseEntity { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; static findByName(firstName: string, lastName: string) { return this.createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName }) .andWhere(\"user.lastName = :lastName\", { lastName }) .getMany(); } } And use it just like other methods: const timber = await User.findByName(\"Timber\", \"Saw\");","title":"What is the Active Record pattern?"},{"location":"active-record-data-mapper/#what-is-the-data-mapper-pattern","text":"In TypeORM you can use both the Active Record and Data Mapper patterns. Using the Data Mapper approach, you define all your query methods in separate classes called \"repositories\", and you save, remove, and load objects using repositories. In data mapper your entities are very dumb - they just define their properties and may have some \"dummy\" methods. Simply said, data mapper is an approach to access your database within repositories instead of models. You can read more about data mapper on Wikipedia . Example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } Example of how to work with such entity: const userRepository = connection.getRepository(User); // example how to save DM entity const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.isActive = true; await userRepository.save(user); // example how to remove DM entity await userRepository.remove(user); // example how to load DM entities const users = await userRepository.find({ skip: 2, take: 5 }); const newUsers = await userRepository.find({ isActive: true }); const timber = await userRepository.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); Now let's say we want to create a function that returns users by first and last name. We can create such a function in a \"custom repository\". import {EntityRepository, Repository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository() export class UserRepository extends Repository<User> { findByName(firstName: string, lastName: string) { return this.createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName }) .andWhere(\"user.lastName = :lastName\", { lastName }) .getMany(); } } And use it this way: const userRepository = connection.getCustomRepository(UserRepository); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); Learn more about custom repositories .","title":"What is the Data Mapper pattern?"},{"location":"active-record-data-mapper/#which-one-should-i-choose","text":"The decision is up to you. Both strategies have their own cons and pros. One thing we should always keep in mind with software development is how we are going to maintain our applications. The Data Mapper approach helps with maintainability, which is more effective in bigger apps. The Active record approach helps keep things simple which works well in smaller apps. And simplicity is always a key to better maintainability.","title":"Which one should I choose?"},{"location":"caching/","text":"Caching queries You can cache results selected by these QueryBuilder methods: getMany , getOne , getRawMany , getRawOne and getCount . You can also cache results selected by these Repository methods: find , findAndCount , findByIds , and count . To enable caching you need to explicitly enable it in your connection options: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: true } When you enable cache for the first time, you must synchronize your database schema (using CLI, migrations or the synchronize connection option). Then in QueryBuilder you can enable query cache for any query: const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(true) .getMany(); Equivalent Repository query: const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: true }); This will execute a query to fetch all admin users and cache the results. Next time you execute the same code, it will get all admin users from the cache. Default cache lifetime is equal to 1000 ms , e.g. 1 second. This means the cache will be invalid 1 second after the query builder code is called. In practice, this means that if users open the user page 150 times within 3 seconds, only three queries will be executed during this period. Any users inserted during the 1 second cache window won't be returned to the user. You can change cache time manually via QueryBuilder : const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(60000) // 1 minute .getMany(); Or via Repository : const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: 60000 }); Or globally in connection options: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { duration: 30000 // 30 seconds } } Also, you can set a \"cache id\" via QueryBuilder : const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(\"users_admins\", 25000) .getMany(); Or with Repository : const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: { id: \"users_admins\", milliseconds: 25000 } }); This gives you granular control of your cache, for example, clearing cached results when you insert a new user: await connection.queryResultCache.remove([\"users_admins\"]); By default, TypeORM uses a separate table called query-result-cache and stores all queries and results there. Table name is configurable, so you could change it by specifying a different value in the tableName property. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"database\", tableName: \"configurable-table-query-result-cache\" } } If storing cache in a single database table is not effective for you, you can change the cache type to \"redis\" or \"ioredis\" and TypeORM will store all cached records in redis instead. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"redis\", options: { host: \"localhost\", port: 6379 } } } \"options\" can be node_redis specific options or ioredis specific options depending on what type you're using. In case you want to connect to a redis-cluster using IORedis's cluster functionality, you can do that as well by doing the following: { type: \"mysql\", host: \"localhost\", username: \"test\", cache: { type: \"ioredis/cluster\", options: { startupNodes: [ { host: 'localhost', port: 7000, }, { host: 'localhost', port: 7001, }, { host: 'localhost', port: 7002, } ], options: { scaleReads: 'all', clusterRetryStrategy: function (times) { return null }, redisOptions: { maxRetriesPerRequest: 1 } } } } } Note that, you can still use options as the first argument of IORedis's cluster constructor. { ... cache: { type: \"ioredis/cluster\", options: [ { host: 'localhost', port: 7000, }, { host: 'localhost', port: 7001, }, { host: 'localhost', port: 7002, } ] }, ... } If none of the built-in cache providers satisfy your demands, then you can also specify your own cache provider by using a provider factory function which needs to return a new object that implements the QueryResultCache interface: class CustomQueryResultCache implements QueryResultCache { constructor(private connection: Connection) {} ... } { ... cache: { provider(connection) { return new CustomQueryResultCache(connection); } } } If you wish to ignore cache errors and want the queries to pass through to database in case of cache errors, you can use ignoreErrors option. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"redis\", options: { host: \"localhost\", port: 6379 }, ignoreErrors: true } } You can use typeorm cache:clear to clear everything stored in the cache.","title":"Caching queries"},{"location":"caching/#caching-queries","text":"You can cache results selected by these QueryBuilder methods: getMany , getOne , getRawMany , getRawOne and getCount . You can also cache results selected by these Repository methods: find , findAndCount , findByIds , and count . To enable caching you need to explicitly enable it in your connection options: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: true } When you enable cache for the first time, you must synchronize your database schema (using CLI, migrations or the synchronize connection option). Then in QueryBuilder you can enable query cache for any query: const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(true) .getMany(); Equivalent Repository query: const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: true }); This will execute a query to fetch all admin users and cache the results. Next time you execute the same code, it will get all admin users from the cache. Default cache lifetime is equal to 1000 ms , e.g. 1 second. This means the cache will be invalid 1 second after the query builder code is called. In practice, this means that if users open the user page 150 times within 3 seconds, only three queries will be executed during this period. Any users inserted during the 1 second cache window won't be returned to the user. You can change cache time manually via QueryBuilder : const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(60000) // 1 minute .getMany(); Or via Repository : const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: 60000 }); Or globally in connection options: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { duration: 30000 // 30 seconds } } Also, you can set a \"cache id\" via QueryBuilder : const users = await connection .createQueryBuilder(User, \"user\") .where(\"user.isAdmin = :isAdmin\", { isAdmin: true }) .cache(\"users_admins\", 25000) .getMany(); Or with Repository : const users = await connection .getRepository(User) .find({ where: { isAdmin: true }, cache: { id: \"users_admins\", milliseconds: 25000 } }); This gives you granular control of your cache, for example, clearing cached results when you insert a new user: await connection.queryResultCache.remove([\"users_admins\"]); By default, TypeORM uses a separate table called query-result-cache and stores all queries and results there. Table name is configurable, so you could change it by specifying a different value in the tableName property. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"database\", tableName: \"configurable-table-query-result-cache\" } } If storing cache in a single database table is not effective for you, you can change the cache type to \"redis\" or \"ioredis\" and TypeORM will store all cached records in redis instead. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"redis\", options: { host: \"localhost\", port: 6379 } } } \"options\" can be node_redis specific options or ioredis specific options depending on what type you're using. In case you want to connect to a redis-cluster using IORedis's cluster functionality, you can do that as well by doing the following: { type: \"mysql\", host: \"localhost\", username: \"test\", cache: { type: \"ioredis/cluster\", options: { startupNodes: [ { host: 'localhost', port: 7000, }, { host: 'localhost', port: 7001, }, { host: 'localhost', port: 7002, } ], options: { scaleReads: 'all', clusterRetryStrategy: function (times) { return null }, redisOptions: { maxRetriesPerRequest: 1 } } } } } Note that, you can still use options as the first argument of IORedis's cluster constructor. { ... cache: { type: \"ioredis/cluster\", options: [ { host: 'localhost', port: 7000, }, { host: 'localhost', port: 7001, }, { host: 'localhost', port: 7002, } ] }, ... } If none of the built-in cache providers satisfy your demands, then you can also specify your own cache provider by using a provider factory function which needs to return a new object that implements the QueryResultCache interface: class CustomQueryResultCache implements QueryResultCache { constructor(private connection: Connection) {} ... } { ... cache: { provider(connection) { return new CustomQueryResultCache(connection); } } } If you wish to ignore cache errors and want the queries to pass through to database in case of cache errors, you can use ignoreErrors option. Example: { type: \"mysql\", host: \"localhost\", username: \"test\", ... cache: { type: \"redis\", options: { host: \"localhost\", port: 6379 }, ignoreErrors: true } } You can use typeorm cache:clear to clear everything stored in the cache.","title":"Caching queries"},{"location":"connection-api/","text":"Connection APIs Main API Connection API ConnectionManager API Main API createConnection() - Creates a new connection and registers it in global connection manager. If connection options parameter is omitted then connection options are read from ormconfig file or environment variables. import {createConnection} from \"typeorm\"; const connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); createConnections() - Creates multiple connections and registers them in global connection manager. If connection options parameter is omitted then connection options are read from ormconfig file or environment variables. import {createConnections} from \"typeorm\"; const connection = await createConnections([{ name: \"connection1\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { name: \"connection2\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }]); getConnectionManager() - Gets connection manager which stores all created (using createConnection() or createConnections() ) connections. import {getConnectionManager} from \"typeorm\"; const defaultConnection = getConnectionManager().get(\"default\"); const secondaryConnection = getConnectionManager().get(\"secondary\"); getConnection() - Gets connection which was created by using createConnection method. import {getConnection} from \"typeorm\"; const connection = getConnection(); // if you have named connection you can specify its name: const secondaryConnection = getConnection(\"secondary-connection\"); getEntityManager() - Gets EntityManager from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getEntityManager} from \"typeorm\"; const manager = getEntityManager(); // you can use manager methods now const secondaryManager = getEntityManager(\"secondary-connection\"); // you can use secondary connection manager methods getRepository() - Gets Repository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getRepository} from \"typeorm\"; const userRepository = getRepository(User); // you can use repository methods now const blogRepository = getRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods getTreeRepository() - Gets TreeRepository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getTreeRepository} from \"typeorm\"; const userRepository = getTreeRepository(User); // you can use repository methods now const blogRepository = getTreeRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods getMongoRepository() - Gets MongoRepository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // you can use repository methods now const blogRepository = getMongoRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods Connection API name - Connection name. If you created nameless connection then it's equal to \"default\". You use this name when you work with multiple connections and call getConnection(connectionName: string) const connectionName: string = connection.name; options - Connection options used to create this connection. Learn more about Connection Options . const connectionOptions: ConnectionOptions = connection.options; // you can cast connectionOptions to MysqlConnectionOptions // or any other xxxConnectionOptions depending on the database driver you use isConnected - Indicates if a real connection to the database is established. const isConnected: boolean = connection.isConnected; driver - Underlying database driver used in this connection. const driver: Driver = connection.driver; // you can cast connectionOptions to MysqlDriver // or any other xxxDriver depending on the database driver you use manager - EntityManager used to work with connection entities. Learn more about Entity Manager and Repository . const manager: EntityManager = connection.manager; // you can call manager methods, for example find: const user = await manager.findOne(1); mongoManager - MongoEntityManager used to work with connection entities in mongodb connections. For more information about MongoEntityManager see MongoDB documentation. const manager: MongoEntityManager = connection.mongoManager; // you can call manager or mongodb-manager specific methods, for example find: const user = await manager.findOne(1); connect - Performs connection to the database. When you use createConnection it automatically calls connect and you don't need to call it yourself. await connection.connect(); close - Closes connection with the database. Usually, you call this method when your application is shutting down. await connection.close(); synchronize - Synchronizes database schema. When synchronize: true is set in connection options it calls this method. Usually, you call this method when your application is starting. await connection.synchronize(); dropDatabase - Drops the database and all its data. Be careful with this method on production since this method will erase all your database tables and their data. Can be used only after connection to the database is established. await connection.dropDatabase(); runMigrations - Runs all pending migrations. await connection.runMigrations(); undoLastMigration - Reverts last executed migration. await connection.undoLastMigration(); hasMetadata - Checks if metadata for a given entity is registered. Learn more about Entity Metadata . if (connection.hasMetadata(User)) const userMetadata = connection.getMetadata(User); getMetadata - Gets EntityMetadata of the given entity. You can also specify a table name and if entity metadata with such table name is found it will be returned. Learn more about Entity Metadata . const userMetadata = connection.getMetadata(User); // now you can get any information about User entity getRepository - Gets Repository of the given entity. You can also specify a table name and if repository for given table is found it will be returned. Learn more about Repositories . const repository = connection.getRepository(User); // now you can call repository methods, for example find: const users = await repository.findOne(1); getTreeRepository - Gets TreeRepository of the given entity. You can also specify a table name and if repository for given table is found it will be returned. Learn more about Repositories . const repository = connection.getTreeRepository(Category); // now you can call tree repository methods, for example findTrees: const categories = await repository.findTrees(); getMongoRepository - Gets MongoRepository of the given entity. This repository is used for entities in MongoDB connection. Learn more about MongoDB support . const repository = connection.getMongoRepository(User); // now you can call mongodb-specific repository methods, for example createEntityCursor: const categoryCursor = repository.createEntityCursor(); const category1 = await categoryCursor.next(); const category2 = await categoryCursor.next(); getCustomRepository - Gets custom defined repository. Learn more about custom repositories . const userRepository = connection.getCustomRepository(UserRepository); // now you can call methods inside your custom repository - UserRepository class const crazyUsers = await userRepository.findCrazyUsers(); transaction - Provides a single transaction where multiple database requests will be executed in a single database transaction. Learn more about Transactions . await connection.transaction(async manager => { // NOTE: you must perform all database operations using given manager instance // its a special instance of EntityManager working with this transaction // and don't forget to await things here }); query - Executes a raw SQL query. const rawData = await connection.query(`SELECT * FROM USERS`); createQueryBuilder - Creates a query builder, which can be used to build queries. Learn more about QueryBuilder . const users = await connection.createQueryBuilder() .select() .from(User, \"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); createQueryRunner - Creates a query runner used to manage and work with a single real database connection. Learn more about QueryRunner . const queryRunner = connection.createQueryRunner(); // you can use its methods only after you call connect // which performs real database connection await queryRunner.connect(); // .. now you can work with query runner and call its methods // very important - don't forget to release query runner once you finished working with it await queryRunner.release(); ConnectionManager API create - Creates a new connection and register it in the manager. const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); get - Gets already created connection stored in the manager by its name. const defaultConnection = connectionManager.get(\"default\"); const secondaryConnection = connectionManager.get(\"secondary\"); has - Checks if a connection is registered in the given connection manager. if (connectionManager.has(\"default\")) { // ... }","title":"Connection APIs"},{"location":"connection-api/#connection-apis","text":"Main API Connection API ConnectionManager API","title":"Connection APIs"},{"location":"connection-api/#main-api","text":"createConnection() - Creates a new connection and registers it in global connection manager. If connection options parameter is omitted then connection options are read from ormconfig file or environment variables. import {createConnection} from \"typeorm\"; const connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); createConnections() - Creates multiple connections and registers them in global connection manager. If connection options parameter is omitted then connection options are read from ormconfig file or environment variables. import {createConnections} from \"typeorm\"; const connection = await createConnections([{ name: \"connection1\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { name: \"connection2\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }]); getConnectionManager() - Gets connection manager which stores all created (using createConnection() or createConnections() ) connections. import {getConnectionManager} from \"typeorm\"; const defaultConnection = getConnectionManager().get(\"default\"); const secondaryConnection = getConnectionManager().get(\"secondary\"); getConnection() - Gets connection which was created by using createConnection method. import {getConnection} from \"typeorm\"; const connection = getConnection(); // if you have named connection you can specify its name: const secondaryConnection = getConnection(\"secondary-connection\"); getEntityManager() - Gets EntityManager from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getEntityManager} from \"typeorm\"; const manager = getEntityManager(); // you can use manager methods now const secondaryManager = getEntityManager(\"secondary-connection\"); // you can use secondary connection manager methods getRepository() - Gets Repository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getRepository} from \"typeorm\"; const userRepository = getRepository(User); // you can use repository methods now const blogRepository = getRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods getTreeRepository() - Gets TreeRepository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getTreeRepository} from \"typeorm\"; const userRepository = getTreeRepository(User); // you can use repository methods now const blogRepository = getTreeRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods getMongoRepository() - Gets MongoRepository for given entity from connection. Connection name can be specified to indicate what connection's entity manager should be taken. import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // you can use repository methods now const blogRepository = getMongoRepository(Blog, \"secondary-connection\"); // you can use secondary connection repository methods","title":"Main API"},{"location":"connection-api/#connection-api","text":"name - Connection name. If you created nameless connection then it's equal to \"default\". You use this name when you work with multiple connections and call getConnection(connectionName: string) const connectionName: string = connection.name; options - Connection options used to create this connection. Learn more about Connection Options . const connectionOptions: ConnectionOptions = connection.options; // you can cast connectionOptions to MysqlConnectionOptions // or any other xxxConnectionOptions depending on the database driver you use isConnected - Indicates if a real connection to the database is established. const isConnected: boolean = connection.isConnected; driver - Underlying database driver used in this connection. const driver: Driver = connection.driver; // you can cast connectionOptions to MysqlDriver // or any other xxxDriver depending on the database driver you use manager - EntityManager used to work with connection entities. Learn more about Entity Manager and Repository . const manager: EntityManager = connection.manager; // you can call manager methods, for example find: const user = await manager.findOne(1); mongoManager - MongoEntityManager used to work with connection entities in mongodb connections. For more information about MongoEntityManager see MongoDB documentation. const manager: MongoEntityManager = connection.mongoManager; // you can call manager or mongodb-manager specific methods, for example find: const user = await manager.findOne(1); connect - Performs connection to the database. When you use createConnection it automatically calls connect and you don't need to call it yourself. await connection.connect(); close - Closes connection with the database. Usually, you call this method when your application is shutting down. await connection.close(); synchronize - Synchronizes database schema. When synchronize: true is set in connection options it calls this method. Usually, you call this method when your application is starting. await connection.synchronize(); dropDatabase - Drops the database and all its data. Be careful with this method on production since this method will erase all your database tables and their data. Can be used only after connection to the database is established. await connection.dropDatabase(); runMigrations - Runs all pending migrations. await connection.runMigrations(); undoLastMigration - Reverts last executed migration. await connection.undoLastMigration(); hasMetadata - Checks if metadata for a given entity is registered. Learn more about Entity Metadata . if (connection.hasMetadata(User)) const userMetadata = connection.getMetadata(User); getMetadata - Gets EntityMetadata of the given entity. You can also specify a table name and if entity metadata with such table name is found it will be returned. Learn more about Entity Metadata . const userMetadata = connection.getMetadata(User); // now you can get any information about User entity getRepository - Gets Repository of the given entity. You can also specify a table name and if repository for given table is found it will be returned. Learn more about Repositories . const repository = connection.getRepository(User); // now you can call repository methods, for example find: const users = await repository.findOne(1); getTreeRepository - Gets TreeRepository of the given entity. You can also specify a table name and if repository for given table is found it will be returned. Learn more about Repositories . const repository = connection.getTreeRepository(Category); // now you can call tree repository methods, for example findTrees: const categories = await repository.findTrees(); getMongoRepository - Gets MongoRepository of the given entity. This repository is used for entities in MongoDB connection. Learn more about MongoDB support . const repository = connection.getMongoRepository(User); // now you can call mongodb-specific repository methods, for example createEntityCursor: const categoryCursor = repository.createEntityCursor(); const category1 = await categoryCursor.next(); const category2 = await categoryCursor.next(); getCustomRepository - Gets custom defined repository. Learn more about custom repositories . const userRepository = connection.getCustomRepository(UserRepository); // now you can call methods inside your custom repository - UserRepository class const crazyUsers = await userRepository.findCrazyUsers(); transaction - Provides a single transaction where multiple database requests will be executed in a single database transaction. Learn more about Transactions . await connection.transaction(async manager => { // NOTE: you must perform all database operations using given manager instance // its a special instance of EntityManager working with this transaction // and don't forget to await things here }); query - Executes a raw SQL query. const rawData = await connection.query(`SELECT * FROM USERS`); createQueryBuilder - Creates a query builder, which can be used to build queries. Learn more about QueryBuilder . const users = await connection.createQueryBuilder() .select() .from(User, \"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); createQueryRunner - Creates a query runner used to manage and work with a single real database connection. Learn more about QueryRunner . const queryRunner = connection.createQueryRunner(); // you can use its methods only after you call connect // which performs real database connection await queryRunner.connect(); // .. now you can work with query runner and call its methods // very important - don't forget to release query runner once you finished working with it await queryRunner.release();","title":"Connection API"},{"location":"connection-api/#connectionmanager-api","text":"create - Creates a new connection and register it in the manager. const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); get - Gets already created connection stored in the manager by its name. const defaultConnection = connectionManager.get(\"default\"); const secondaryConnection = connectionManager.get(\"secondary\"); has - Checks if a connection is registered in the given connection manager. if (connectionManager.has(\"default\")) { // ... }","title":"ConnectionManager API"},{"location":"connection-options/","text":"Connection Options What is ConnectionOptions Common connection options mysql / mariadb connection options postgres / cockroachdb connection options sqlite connection options better-sqlite3 connection options capacitor connection options cordova connection options react-native connection options nativescript connection options mssql connection options mongodb connection options sql.js connection options expo connection options Connection options example What is ConnectionOptions Connection options is a connection configuration you pass to createConnection or define in ormconfig file. Different databases have their own specific connection options. Common connection options type - Database type. You must specify what database engine you use. Possible values are \"mysql\", \"postgres\", \"cockroachdb\", \"mariadb\", \"sqlite\", \"better-sqlite3\", \"capacitor\", \"cordova\", \"nativescript\", \"oracle\", \"mssql\", \"mongodb\", \"sqljs\", \"react-native\". This option is required . name - Connection name. You'll use it to get connection you need using getConnection(name: string) or ConnectionManager.get(name: string) . Connection names for different connections cannot be same - they all must be unique. If connection name is not given then it will be called \"default\". extra - Extra connection options to be passed to the underlying driver. Use it if you want to pass extra settings to underlying database driver. entities - Entities, or Entity Schemas, to be loaded and used for this connection. Accepts both entity classes, entity schema classes, and directories paths to load from. Directories support glob patterns. Example: entities: [Post, Category, \"entity/*.js\", \"modules/**/entity/*.js\"] . Learn more about Entities . Learn more about Entity Schemas . subscribers - Subscribers to be loaded and used for this connection. Accepts both entity classes and directories to load from. Directories support glob patterns. Example: subscribers: [PostSubscriber, AppSubscriber, \"subscriber/*.js\", \"modules/**/subscriber/*.js\"] . Learn more about Subscribers . migrations - Migrations to be loaded and used for this connection. Accepts both migration classes and directories to load from. Directories support glob patterns. Example: migrations: [FirstMigration, SecondMigration, \"migration/*.js\", \"modules/**/migration/*.js\"] . Learn more about Migrations . logging - Indicates if logging is enabled or not. If set to true then query and error logging will be enabled. You can also specify different types of logging to be enabled, for example [\"query\", \"error\", \"schema\"] . Learn more about Logging . logger - Logger to be used for logging purposes. Possible values are \"advanced-console\", \"simple-console\" and \"file\". Default is \"advanced-console\". You can also specify a logger class that implements Logger interface. Learn more about Logging . maxQueryExecutionTime - If query execution time exceed this given max execution time (in milliseconds) then logger will log this query. namingStrategy - Naming strategy to be used to name tables and columns in the database. Learn more about Naming strategies . entityPrefix - Prefixes with the given string all tables (or collections) on this database connection. entitySkipConstructor - Indicates if TypeORM should skip constructors when deserializing entities from the database. Note that when you do not call the constructor both private properties and default properties will not operate as expected. dropSchema - Drops the schema each time connection is being established. Be careful with this option and don't use this in production - otherwise you'll lose all production data. This option is useful during debug and development. synchronize - Indicates if database schema should be auto created on every application launch. Be careful with this option and don't use this in production - otherwise you can lose production data. This option is useful during debug and development. As an alternative to it, you can use CLI and run schema:sync command. Note that for MongoDB database it does not create schema, because MongoDB is schemaless. Instead, it syncs just by creating indices. migrationsRun - Indicates if migrations should be auto run on every application launch. As an alternative, you can use CLI and run migration:run command. migrationsTableName - Name of the table in the database which is going to contain information about executed migrations. By default this table is called \"migrations\". migrationsTransactionMode - Control transactions for migrations (default: all ), can be one of all | none | each cache - Enables entity result caching. You can also configure cache type and other cache options here. Read more about caching here . cli.entitiesDir - Directory where entities should be created by default by CLI. cli.migrationsDir - Directory where migrations should be created by default by CLI. cli.subscribersDir - Directory where subscribers should be created by default by CLI. mysql / mariadb connection options url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mysql port is 3306 . username - Database username. password - Database password. database - Database name. charset - The charset for the connection. This is called \"collation\" in the SQL-level of MySQL (like utf8_general_ci). If a SQL-level charset is specified (like utf8mb4) then the default collation for that charset is used. (Default: UTF8_GENERAL_CI ). timezone - the timezone configured on the MySQL server. This is used to typecast server date/time values to JavaScript Date object and vice versa. This can be local , Z , or an offset in the form +HH:MM or -HH:MM . (Default: local ) connectTimeout - The milliseconds before a timeout occurs during the initial connection to the MySQL server. (Default: 10000 ) acquireTimeout - The milliseconds before a timeout occurs during the initial connection to the MySql server. It differs from connectTimeout as it governs the TCP connection timeout where as connectTimeout does not. (default: 10000 ) insecureAuth - Allow connecting to MySQL instances that ask for the old (insecure) authentication method. (Default: false ) supportBigNumbers - When dealing with big numbers ( BIGINT and DECIMAL columns) in the database, you should enable this option (Default: true ) bigNumberStrings - Enabling both supportBigNumbers and bigNumberStrings forces big numbers ( BIGINT and DECIMAL columns) to be always returned as JavaScript String objects (Default: true ). Enabling supportBigNumbers but leaving bigNumberStrings disabled will return big numbers as String objects only when they cannot be accurately represented with JavaScript Number objects (which happens when they exceed the [-2^53, +2^53] range), otherwise they will be returned as Number objects. This option is ignored if supportBigNumbers is disabled. dateStrings - Force date types ( TIMESTAMP , DATETIME , DATE ) to be returned as strings rather than inflated into JavaScript Date objects. Can be true/false or an array of type names to keep as strings. (Default: false ) debug - Prints protocol details to stdout. Can be true/false or an array of packet type names that should be printed. (Default: false ) trace - Generates stack traces on Error to include call site of library entrance (\"long stack traces\"). Slight performance penalty for most calls. (Default: true ) multipleStatements - Allow multiple mysql statements per query. Be careful with this, it could increase the scope of SQL injection attacks. (Default: false ) legacySpatialSupport - Use spatial functions like GeomFromText and AsText which are removed in MySQL 8. (Default: true) flags - List of connection flags to use other than the default ones. It is also possible to blacklist default ones. For more information, check Connection Flags . ssl - object with ssl parameters or a string containing the name of ssl profile. See SSL options . postgres / cockroachdb connection options url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default postgres port is 5432 . username - Database username. password - Database password. database - Database name. schema - Schema name. Default is \"public\". connectTimeoutMS - The milliseconds before a timeout occurs during the initial connection to the postgres server. If undefined , or set to 0 , there is no timeout. Defaults to undefined . ssl - Object with ssl parameters. See TLS/SSL . uuidExtension - The Postgres extension to use when generating UUIDs. Defaults to uuid-ossp . Can be changed to pgcrypto if the uuid-ossp extension is unavailable. poolErrorHandler - A function that get's called when underlying pool emits 'error' event. Takes single parameter (error instance) and defaults to logging with warn level. logNotifications - A boolean to determine whether postgres server notice messages and notification events should be included in client's logs with info level (default: false ). installExtensions - A boolean to control whether to install necessary postgres extensions automatically or not (default: true ) applicationName - A string visible in statistics and logs to help referencing an application to a connection (default: undefined ) sqlite connection options database - Database path. For example \"./mydb.sql\" better-sqlite3 connection options database - Database path. For example \"./mydb.sql\" statementCacheSize - Cache size of sqlite statement to speed up queries (default 100). prepareDatabase - Function to run before a database is used in typeorm. You can access original better-sqlite3 Database object here. capacitor connection options database - Database name (capacitor-sqlite will add the suffix SQLite.db ) driver - The capacitor-sqlite instance. For example, new SQLiteConnection(CapacitorSQLite) . mode - Set the mode for database encryption: \"no-encryption\" | \"encryption\" | \"secret\" | \"newsecret\" version - Database version journalMode - The SQLite journal mode (optional) cordova connection options database - Database name location - Where to save the database. See cordova-sqlite-storage for options. react-native connection options database - Database name location - Where to save the database. See react-native-sqlite-storage for options. nativescript connection options database - Database name mssql connection options url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mssql port is 1433 . username - Database username. password - Database password. database - Database name. schema - Schema name. Default is \"public\". domain - Once you set domain, the driver will connect to SQL Server using domain login. connectionTimeout - Connection timeout in ms (default: 15000 ). requestTimeout - Request timeout in ms (default: 15000 ). NOTE: msnodesqlv8 driver doesn't support timeouts < 1 second. stream - Stream recordsets/rows instead of returning them all at once as an argument of callback (default: false ). You can also enable streaming for each request independently ( request.stream = true ). Always set to true if you plan to work with a large amount of rows. pool.max - The maximum number of connections there can be in the pool (default: 10 ). pool.min - The minimum of connections there can be in the pool (default: 0 ). pool.maxWaitingClients - maximum number of queued requests allowed, additional acquire calls will be callback with an err in a future cycle of the event loop. pool.testOnBorrow - should the pool validate resources before giving them to clients. Requires that either factory.validate or factory.validateAsync to be specified. pool.acquireTimeoutMillis - max milliseconds an acquire call will wait for a resource before timing out. (default no limit), if supplied should non-zero positive integer. pool.fifo - if true the oldest resources will be first to be allocated. If false the most recently released resources will be the first to be allocated. This in effect turns the pool's behaviour from a queue into a stack. boolean, (default true ). pool.priorityRange - int between 1 and x - if set, borrowers can specify their relative priority in the queue if no resources are available. see example. (default 1 ). pool.evictionRunIntervalMillis - How often to run eviction checks. Default: 0 (does not run). pool.numTestsPerRun - Number of resources to check each eviction run. Default: 3 . pool.softIdleTimeoutMillis - amount of time an object may sit idle in the pool before it is eligible for eviction by the idle object evictor (if any), with the extra condition that at least \"min idle\" object instances remain in the pool. Default -1 (nothing can get evicted). pool.idleTimeoutMillis - the minimum amount of time that an object may sit idle in the pool before it is eligible for eviction due to idle time. Supersedes softIdleTimeoutMillis . Default: 30000 . pool.errorHandler - A function that get's called when underlying pool emits 'error' event. Takes single parameter (error instance) and defaults to logging with warn level. options.fallbackToDefaultDb - By default, if the database requestion by options.database cannot be accessed, the connection will fail with an error. However, if options.fallbackToDefaultDb is set to true , then the user's default database will be used instead (Default: false ). options.instanceName - The instance name to connect to. The SQL Server Browser service must be running on the database server, and UDP port 1434 on the database server must be reachable. Mutually exclusive with port . (no default). options.enableAnsiNullDefault - If true, SET ANSI_NULL_DFLT_ON ON will be set in the initial sql. This means new columns will be nullable by default. See the T-SQL documentation for more details. (Default: true ). options.cancelTimeout - The number of milliseconds before the cancel (abort) of a request is considered failed (default: 5000 ). options.packetSize - The size of TDS packets (subject to negotiation with the server). Should be a power of 2. (default: 4096 ). options.useUTC - A boolean determining whether to pass time values in UTC or local time. (default: true ). options.abortTransactionOnError - A boolean determining whether to rollback a transaction automatically if any error is encountered during the given transaction's execution. This sets the value for SET XACT_ABORT during the initial SQL phase of a connection ( documentation ). options.localAddress - A string indicating which network interface (ip address) to use when connecting to SQL Server. options.useColumnNames - A boolean determining whether to return rows as arrays or key-value collections. (default: false ). options.camelCaseColumns - A boolean, controlling whether the column names returned will have the first letter converted to lower case ( true ) or not. This value is ignored if you provide a columnNameReplacer . (default: false ). options.isolationLevel - The default isolation level that transactions will be run with. The isolation levels are available from require('tedious').ISOLATION_LEVEL . READ_UNCOMMITTED READ_COMMITTED REPEATABLE_READ SERIALIZABLE SNAPSHOT (default: READ_COMMITTED ) options.connectionIsolationLevel - The default isolation level for new connections. All out-of-transaction queries are executed with this setting. The isolation levels are available from require('tedious').ISOLATION_LEVEL . READ_UNCOMMITTED READ_COMMITTED REPEATABLE_READ SERIALIZABLE SNAPSHOT (default: READ_COMMITTED ) options.readOnlyIntent - A boolean, determining whether the connection will request read-only access from a SQL Server Availability Group. For more information, see here. (default: false ). options.encrypt - A boolean determining whether or not the connection will be encrypted. Set to true if you're on Windows Azure. (default: false ). options.cryptoCredentialsDetails - When encryption is used, an object may be supplied that will be used for the first argument when calling tls.createSecurePair (default: {} ). options.rowCollectionOnDone - A boolean, that when true will expose received rows in Requests' done* events. See done, doneInProc and doneProc . (default: false ) Caution: If many rows are received, enabling this option could result in excessive memory usage. options.rowCollectionOnRequestCompletion - A boolean, that when true will expose received rows in Requests' completion callback. See new Request . (default: false ) Caution: If many rows are received, enabling this option could result in excessive memory usage. options.tdsVersion - The version of TDS to use. If the server doesn't support the specified version, a negotiated version is used instead. The versions are available from require('tedious').TDS_VERSION . 7_1 7_2 7_3_A 7_3_B 7_4 (default: 7_4 ) options.debug.packet - A boolean, controlling whether debug events will be emitted with text describing packet details (default: false ). options.debug.data - A boolean, controlling whether debug events will be emitted with text describing packet data details (default: false ). options.debug.payload - A boolean, controlling whether debug events will be emitted with text describing packet payload details (default: false ). options.debug.token - A boolean, controlling whether debug events will be emitted with text describing token stream tokens (default: false ). mongodb connection options url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mongodb port is 27017 . username - Database username (replacement for auth.user ). password - Database password (replacement for auth.password ). database - Database name. poolSize - Set the maximum pool size for each individual server or proxy connection. ssl - Use ssl connection (needs to have a mongod server with ssl support). Default: false . sslValidate - Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher). Default: true . sslCA - Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher). sslCert - String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher) sslKey - String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher). sslPass - String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher). autoReconnect - Reconnect on error. Default: true . noDelay - TCP Socket NoDelay option. Default: true . keepAlive - The number of milliseconds to wait before initiating keepAlive on the TCP socket. Default: 30000 . connectTimeoutMS - TCP Connection timeout setting. Default: 30000 . socketTimeoutMS - TCP Socket timeout setting. Default: 360000 . reconnectTries - Server attempt to reconnect #times. Default: 30 . reconnectInterval - Server will wait #milliseconds between retries. Default: 1000 . ha - Turn on high availability monitoring. Default: true . haInterval - Time between each replicaset status check. Default: 10000,5000 . replicaSet - The name of the replicaset to connect to. acceptableLatencyMS - Sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms). Default: 15 . secondaryAcceptableLatencyMS - Sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms). Default: 15 . connectWithNoPrimary - Sets if the driver should connect even if no primary is available. Default: false . authSource - If the database authentication is dependent on another databaseName. w - The write concern. wtimeout - The write concern timeout value. j - Specify a journal write concern. Default: false . forceServerObjectId - Force server to assign _id values instead of driver. Default: false . serializeFunctions - Serialize functions on any object. Default: false . ignoreUndefined - Specify if the BSON serializer should ignore undefined fields. Default: false . raw - Return document results as raw BSON buffers. Default: false . promoteLongs - Promotes Long values to number if they fit inside the 53 bits resolution. Default: true . promoteBuffers - Promotes Binary BSON values to native Node Buffers. Default: false . promoteValues - Promotes BSON values to native types where possible, set to false to only receive wrapper types. Default: true . domainsEnabled - Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit. Default: false . bufferMaxEntries - Sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited. readPreference - The preferred read preference. ReadPreference.PRIMARY ReadPreference.PRIMARY_PREFERRED ReadPreference.SECONDARY ReadPreference.SECONDARY_PREFERRED ReadPreference.NEAREST pkFactory - A primary key factory object for generation of custom _id keys. promiseLibrary - A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible. readConcern - Specify a read concern for the collection. (only MongoDB 3.2 or higher supported). maxStalenessSeconds - Specify a maxStalenessSeconds value for secondary reads, minimum is 90 seconds. appname - The name of the application that created this MongoClient instance. MongoDB 3.4 and newer will print this value in the server log upon establishing each connection. It is also recorded in the slow query log and profile collections loggerLevel - Specify the log level used by the driver logger ( error/warn/info/debug ). logger - Specify a customer logger mechanism, can be used to log using your app level logger. authMechanism - Sets the authentication mechanism that MongoDB will use to authenticate the connection. sql.js connection options database : The raw UInt8Array database that should be imported. sqlJsConfig : Optional initialize config for sql.js. autoSave : Whether or not autoSave should be disabled. If set to true the database will be saved to the given file location (Node.js) or LocalStorage element (browser) when a change happens and location is specified. Otherwise autoSaveCallback can be used. autoSaveCallback : A function that get's called when changes to the database are made and autoSave is enabled. The function gets a UInt8Array that represents the database. location : The file location to load and save the database to. useLocalForage : Enables the usage of the localforage library (https://github.com/localForage/localForage) to save & load the database asynchronously from the indexedDB instead of using the synchron local storage methods in a browser environment. The localforage node module needs to be added to your project and the localforage.js should be imported in your page. expo connection options database - Name of the database. For example, \"mydb\". driver - The Expo SQLite module. For example, require('expo-sqlite') . Connection options example Here is a small example of connection options for mysql: { host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", logging: true, synchronize: true, entities: [ \"entity/*.js\" ], subscribers: [ \"subscriber/*.js\" ], entitySchemas: [ \"schema/*.json\" ], migrations: [ \"migration/*.js\" ], cli: { entitiesDir: \"entity\", migrationsDir: \"migration\", subscribersDir: \"subscriber\" } }","title":"Connection Options"},{"location":"connection-options/#connection-options","text":"What is ConnectionOptions Common connection options mysql / mariadb connection options postgres / cockroachdb connection options sqlite connection options better-sqlite3 connection options capacitor connection options cordova connection options react-native connection options nativescript connection options mssql connection options mongodb connection options sql.js connection options expo connection options Connection options example","title":"Connection Options"},{"location":"connection-options/#what-is-connectionoptions","text":"Connection options is a connection configuration you pass to createConnection or define in ormconfig file. Different databases have their own specific connection options.","title":"What is ConnectionOptions"},{"location":"connection-options/#common-connection-options","text":"type - Database type. You must specify what database engine you use. Possible values are \"mysql\", \"postgres\", \"cockroachdb\", \"mariadb\", \"sqlite\", \"better-sqlite3\", \"capacitor\", \"cordova\", \"nativescript\", \"oracle\", \"mssql\", \"mongodb\", \"sqljs\", \"react-native\". This option is required . name - Connection name. You'll use it to get connection you need using getConnection(name: string) or ConnectionManager.get(name: string) . Connection names for different connections cannot be same - they all must be unique. If connection name is not given then it will be called \"default\". extra - Extra connection options to be passed to the underlying driver. Use it if you want to pass extra settings to underlying database driver. entities - Entities, or Entity Schemas, to be loaded and used for this connection. Accepts both entity classes, entity schema classes, and directories paths to load from. Directories support glob patterns. Example: entities: [Post, Category, \"entity/*.js\", \"modules/**/entity/*.js\"] . Learn more about Entities . Learn more about Entity Schemas . subscribers - Subscribers to be loaded and used for this connection. Accepts both entity classes and directories to load from. Directories support glob patterns. Example: subscribers: [PostSubscriber, AppSubscriber, \"subscriber/*.js\", \"modules/**/subscriber/*.js\"] . Learn more about Subscribers . migrations - Migrations to be loaded and used for this connection. Accepts both migration classes and directories to load from. Directories support glob patterns. Example: migrations: [FirstMigration, SecondMigration, \"migration/*.js\", \"modules/**/migration/*.js\"] . Learn more about Migrations . logging - Indicates if logging is enabled or not. If set to true then query and error logging will be enabled. You can also specify different types of logging to be enabled, for example [\"query\", \"error\", \"schema\"] . Learn more about Logging . logger - Logger to be used for logging purposes. Possible values are \"advanced-console\", \"simple-console\" and \"file\". Default is \"advanced-console\". You can also specify a logger class that implements Logger interface. Learn more about Logging . maxQueryExecutionTime - If query execution time exceed this given max execution time (in milliseconds) then logger will log this query. namingStrategy - Naming strategy to be used to name tables and columns in the database. Learn more about Naming strategies . entityPrefix - Prefixes with the given string all tables (or collections) on this database connection. entitySkipConstructor - Indicates if TypeORM should skip constructors when deserializing entities from the database. Note that when you do not call the constructor both private properties and default properties will not operate as expected. dropSchema - Drops the schema each time connection is being established. Be careful with this option and don't use this in production - otherwise you'll lose all production data. This option is useful during debug and development. synchronize - Indicates if database schema should be auto created on every application launch. Be careful with this option and don't use this in production - otherwise you can lose production data. This option is useful during debug and development. As an alternative to it, you can use CLI and run schema:sync command. Note that for MongoDB database it does not create schema, because MongoDB is schemaless. Instead, it syncs just by creating indices. migrationsRun - Indicates if migrations should be auto run on every application launch. As an alternative, you can use CLI and run migration:run command. migrationsTableName - Name of the table in the database which is going to contain information about executed migrations. By default this table is called \"migrations\". migrationsTransactionMode - Control transactions for migrations (default: all ), can be one of all | none | each cache - Enables entity result caching. You can also configure cache type and other cache options here. Read more about caching here . cli.entitiesDir - Directory where entities should be created by default by CLI. cli.migrationsDir - Directory where migrations should be created by default by CLI. cli.subscribersDir - Directory where subscribers should be created by default by CLI.","title":"Common connection options"},{"location":"connection-options/#mysql-mariadb-connection-options","text":"url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mysql port is 3306 . username - Database username. password - Database password. database - Database name. charset - The charset for the connection. This is called \"collation\" in the SQL-level of MySQL (like utf8_general_ci). If a SQL-level charset is specified (like utf8mb4) then the default collation for that charset is used. (Default: UTF8_GENERAL_CI ). timezone - the timezone configured on the MySQL server. This is used to typecast server date/time values to JavaScript Date object and vice versa. This can be local , Z , or an offset in the form +HH:MM or -HH:MM . (Default: local ) connectTimeout - The milliseconds before a timeout occurs during the initial connection to the MySQL server. (Default: 10000 ) acquireTimeout - The milliseconds before a timeout occurs during the initial connection to the MySql server. It differs from connectTimeout as it governs the TCP connection timeout where as connectTimeout does not. (default: 10000 ) insecureAuth - Allow connecting to MySQL instances that ask for the old (insecure) authentication method. (Default: false ) supportBigNumbers - When dealing with big numbers ( BIGINT and DECIMAL columns) in the database, you should enable this option (Default: true ) bigNumberStrings - Enabling both supportBigNumbers and bigNumberStrings forces big numbers ( BIGINT and DECIMAL columns) to be always returned as JavaScript String objects (Default: true ). Enabling supportBigNumbers but leaving bigNumberStrings disabled will return big numbers as String objects only when they cannot be accurately represented with JavaScript Number objects (which happens when they exceed the [-2^53, +2^53] range), otherwise they will be returned as Number objects. This option is ignored if supportBigNumbers is disabled. dateStrings - Force date types ( TIMESTAMP , DATETIME , DATE ) to be returned as strings rather than inflated into JavaScript Date objects. Can be true/false or an array of type names to keep as strings. (Default: false ) debug - Prints protocol details to stdout. Can be true/false or an array of packet type names that should be printed. (Default: false ) trace - Generates stack traces on Error to include call site of library entrance (\"long stack traces\"). Slight performance penalty for most calls. (Default: true ) multipleStatements - Allow multiple mysql statements per query. Be careful with this, it could increase the scope of SQL injection attacks. (Default: false ) legacySpatialSupport - Use spatial functions like GeomFromText and AsText which are removed in MySQL 8. (Default: true) flags - List of connection flags to use other than the default ones. It is also possible to blacklist default ones. For more information, check Connection Flags . ssl - object with ssl parameters or a string containing the name of ssl profile. See SSL options .","title":"mysql / mariadb connection options"},{"location":"connection-options/#postgres-cockroachdb-connection-options","text":"url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default postgres port is 5432 . username - Database username. password - Database password. database - Database name. schema - Schema name. Default is \"public\". connectTimeoutMS - The milliseconds before a timeout occurs during the initial connection to the postgres server. If undefined , or set to 0 , there is no timeout. Defaults to undefined . ssl - Object with ssl parameters. See TLS/SSL . uuidExtension - The Postgres extension to use when generating UUIDs. Defaults to uuid-ossp . Can be changed to pgcrypto if the uuid-ossp extension is unavailable. poolErrorHandler - A function that get's called when underlying pool emits 'error' event. Takes single parameter (error instance) and defaults to logging with warn level. logNotifications - A boolean to determine whether postgres server notice messages and notification events should be included in client's logs with info level (default: false ). installExtensions - A boolean to control whether to install necessary postgres extensions automatically or not (default: true ) applicationName - A string visible in statistics and logs to help referencing an application to a connection (default: undefined )","title":"postgres / cockroachdb connection options"},{"location":"connection-options/#sqlite-connection-options","text":"database - Database path. For example \"./mydb.sql\"","title":"sqlite connection options"},{"location":"connection-options/#better-sqlite3-connection-options","text":"database - Database path. For example \"./mydb.sql\" statementCacheSize - Cache size of sqlite statement to speed up queries (default 100). prepareDatabase - Function to run before a database is used in typeorm. You can access original better-sqlite3 Database object here.","title":"better-sqlite3 connection options"},{"location":"connection-options/#capacitor-connection-options","text":"database - Database name (capacitor-sqlite will add the suffix SQLite.db ) driver - The capacitor-sqlite instance. For example, new SQLiteConnection(CapacitorSQLite) . mode - Set the mode for database encryption: \"no-encryption\" | \"encryption\" | \"secret\" | \"newsecret\" version - Database version journalMode - The SQLite journal mode (optional)","title":"capacitor connection options"},{"location":"connection-options/#cordova-connection-options","text":"database - Database name location - Where to save the database. See cordova-sqlite-storage for options.","title":"cordova connection options"},{"location":"connection-options/#react-native-connection-options","text":"database - Database name location - Where to save the database. See react-native-sqlite-storage for options.","title":"react-native connection options"},{"location":"connection-options/#nativescript-connection-options","text":"database - Database name","title":"nativescript connection options"},{"location":"connection-options/#mssql-connection-options","text":"url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mssql port is 1433 . username - Database username. password - Database password. database - Database name. schema - Schema name. Default is \"public\". domain - Once you set domain, the driver will connect to SQL Server using domain login. connectionTimeout - Connection timeout in ms (default: 15000 ). requestTimeout - Request timeout in ms (default: 15000 ). NOTE: msnodesqlv8 driver doesn't support timeouts < 1 second. stream - Stream recordsets/rows instead of returning them all at once as an argument of callback (default: false ). You can also enable streaming for each request independently ( request.stream = true ). Always set to true if you plan to work with a large amount of rows. pool.max - The maximum number of connections there can be in the pool (default: 10 ). pool.min - The minimum of connections there can be in the pool (default: 0 ). pool.maxWaitingClients - maximum number of queued requests allowed, additional acquire calls will be callback with an err in a future cycle of the event loop. pool.testOnBorrow - should the pool validate resources before giving them to clients. Requires that either factory.validate or factory.validateAsync to be specified. pool.acquireTimeoutMillis - max milliseconds an acquire call will wait for a resource before timing out. (default no limit), if supplied should non-zero positive integer. pool.fifo - if true the oldest resources will be first to be allocated. If false the most recently released resources will be the first to be allocated. This in effect turns the pool's behaviour from a queue into a stack. boolean, (default true ). pool.priorityRange - int between 1 and x - if set, borrowers can specify their relative priority in the queue if no resources are available. see example. (default 1 ). pool.evictionRunIntervalMillis - How often to run eviction checks. Default: 0 (does not run). pool.numTestsPerRun - Number of resources to check each eviction run. Default: 3 . pool.softIdleTimeoutMillis - amount of time an object may sit idle in the pool before it is eligible for eviction by the idle object evictor (if any), with the extra condition that at least \"min idle\" object instances remain in the pool. Default -1 (nothing can get evicted). pool.idleTimeoutMillis - the minimum amount of time that an object may sit idle in the pool before it is eligible for eviction due to idle time. Supersedes softIdleTimeoutMillis . Default: 30000 . pool.errorHandler - A function that get's called when underlying pool emits 'error' event. Takes single parameter (error instance) and defaults to logging with warn level. options.fallbackToDefaultDb - By default, if the database requestion by options.database cannot be accessed, the connection will fail with an error. However, if options.fallbackToDefaultDb is set to true , then the user's default database will be used instead (Default: false ). options.instanceName - The instance name to connect to. The SQL Server Browser service must be running on the database server, and UDP port 1434 on the database server must be reachable. Mutually exclusive with port . (no default). options.enableAnsiNullDefault - If true, SET ANSI_NULL_DFLT_ON ON will be set in the initial sql. This means new columns will be nullable by default. See the T-SQL documentation for more details. (Default: true ). options.cancelTimeout - The number of milliseconds before the cancel (abort) of a request is considered failed (default: 5000 ). options.packetSize - The size of TDS packets (subject to negotiation with the server). Should be a power of 2. (default: 4096 ). options.useUTC - A boolean determining whether to pass time values in UTC or local time. (default: true ). options.abortTransactionOnError - A boolean determining whether to rollback a transaction automatically if any error is encountered during the given transaction's execution. This sets the value for SET XACT_ABORT during the initial SQL phase of a connection ( documentation ). options.localAddress - A string indicating which network interface (ip address) to use when connecting to SQL Server. options.useColumnNames - A boolean determining whether to return rows as arrays or key-value collections. (default: false ). options.camelCaseColumns - A boolean, controlling whether the column names returned will have the first letter converted to lower case ( true ) or not. This value is ignored if you provide a columnNameReplacer . (default: false ). options.isolationLevel - The default isolation level that transactions will be run with. The isolation levels are available from require('tedious').ISOLATION_LEVEL . READ_UNCOMMITTED READ_COMMITTED REPEATABLE_READ SERIALIZABLE SNAPSHOT (default: READ_COMMITTED ) options.connectionIsolationLevel - The default isolation level for new connections. All out-of-transaction queries are executed with this setting. The isolation levels are available from require('tedious').ISOLATION_LEVEL . READ_UNCOMMITTED READ_COMMITTED REPEATABLE_READ SERIALIZABLE SNAPSHOT (default: READ_COMMITTED ) options.readOnlyIntent - A boolean, determining whether the connection will request read-only access from a SQL Server Availability Group. For more information, see here. (default: false ). options.encrypt - A boolean determining whether or not the connection will be encrypted. Set to true if you're on Windows Azure. (default: false ). options.cryptoCredentialsDetails - When encryption is used, an object may be supplied that will be used for the first argument when calling tls.createSecurePair (default: {} ). options.rowCollectionOnDone - A boolean, that when true will expose received rows in Requests' done* events. See done, doneInProc and doneProc . (default: false ) Caution: If many rows are received, enabling this option could result in excessive memory usage. options.rowCollectionOnRequestCompletion - A boolean, that when true will expose received rows in Requests' completion callback. See new Request . (default: false ) Caution: If many rows are received, enabling this option could result in excessive memory usage. options.tdsVersion - The version of TDS to use. If the server doesn't support the specified version, a negotiated version is used instead. The versions are available from require('tedious').TDS_VERSION . 7_1 7_2 7_3_A 7_3_B 7_4 (default: 7_4 ) options.debug.packet - A boolean, controlling whether debug events will be emitted with text describing packet details (default: false ). options.debug.data - A boolean, controlling whether debug events will be emitted with text describing packet data details (default: false ). options.debug.payload - A boolean, controlling whether debug events will be emitted with text describing packet payload details (default: false ). options.debug.token - A boolean, controlling whether debug events will be emitted with text describing token stream tokens (default: false ).","title":"mssql connection options"},{"location":"connection-options/#mongodb-connection-options","text":"url - Connection url where perform connection to. Please note that other connection options will override parameters set from url. host - Database host. port - Database host port. Default mongodb port is 27017 . username - Database username (replacement for auth.user ). password - Database password (replacement for auth.password ). database - Database name. poolSize - Set the maximum pool size for each individual server or proxy connection. ssl - Use ssl connection (needs to have a mongod server with ssl support). Default: false . sslValidate - Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher). Default: true . sslCA - Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher). sslCert - String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher) sslKey - String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher). sslPass - String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher). autoReconnect - Reconnect on error. Default: true . noDelay - TCP Socket NoDelay option. Default: true . keepAlive - The number of milliseconds to wait before initiating keepAlive on the TCP socket. Default: 30000 . connectTimeoutMS - TCP Connection timeout setting. Default: 30000 . socketTimeoutMS - TCP Socket timeout setting. Default: 360000 . reconnectTries - Server attempt to reconnect #times. Default: 30 . reconnectInterval - Server will wait #milliseconds between retries. Default: 1000 . ha - Turn on high availability monitoring. Default: true . haInterval - Time between each replicaset status check. Default: 10000,5000 . replicaSet - The name of the replicaset to connect to. acceptableLatencyMS - Sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms). Default: 15 . secondaryAcceptableLatencyMS - Sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms). Default: 15 . connectWithNoPrimary - Sets if the driver should connect even if no primary is available. Default: false . authSource - If the database authentication is dependent on another databaseName. w - The write concern. wtimeout - The write concern timeout value. j - Specify a journal write concern. Default: false . forceServerObjectId - Force server to assign _id values instead of driver. Default: false . serializeFunctions - Serialize functions on any object. Default: false . ignoreUndefined - Specify if the BSON serializer should ignore undefined fields. Default: false . raw - Return document results as raw BSON buffers. Default: false . promoteLongs - Promotes Long values to number if they fit inside the 53 bits resolution. Default: true . promoteBuffers - Promotes Binary BSON values to native Node Buffers. Default: false . promoteValues - Promotes BSON values to native types where possible, set to false to only receive wrapper types. Default: true . domainsEnabled - Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit. Default: false . bufferMaxEntries - Sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited. readPreference - The preferred read preference. ReadPreference.PRIMARY ReadPreference.PRIMARY_PREFERRED ReadPreference.SECONDARY ReadPreference.SECONDARY_PREFERRED ReadPreference.NEAREST pkFactory - A primary key factory object for generation of custom _id keys. promiseLibrary - A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible. readConcern - Specify a read concern for the collection. (only MongoDB 3.2 or higher supported). maxStalenessSeconds - Specify a maxStalenessSeconds value for secondary reads, minimum is 90 seconds. appname - The name of the application that created this MongoClient instance. MongoDB 3.4 and newer will print this value in the server log upon establishing each connection. It is also recorded in the slow query log and profile collections loggerLevel - Specify the log level used by the driver logger ( error/warn/info/debug ). logger - Specify a customer logger mechanism, can be used to log using your app level logger. authMechanism - Sets the authentication mechanism that MongoDB will use to authenticate the connection.","title":"mongodb connection options"},{"location":"connection-options/#sqljs-connection-options","text":"database : The raw UInt8Array database that should be imported. sqlJsConfig : Optional initialize config for sql.js. autoSave : Whether or not autoSave should be disabled. If set to true the database will be saved to the given file location (Node.js) or LocalStorage element (browser) when a change happens and location is specified. Otherwise autoSaveCallback can be used. autoSaveCallback : A function that get's called when changes to the database are made and autoSave is enabled. The function gets a UInt8Array that represents the database. location : The file location to load and save the database to. useLocalForage : Enables the usage of the localforage library (https://github.com/localForage/localForage) to save & load the database asynchronously from the indexedDB instead of using the synchron local storage methods in a browser environment. The localforage node module needs to be added to your project and the localforage.js should be imported in your page.","title":"sql.js connection options"},{"location":"connection-options/#expo-connection-options","text":"database - Name of the database. For example, \"mydb\". driver - The Expo SQLite module. For example, require('expo-sqlite') .","title":"expo connection options"},{"location":"connection-options/#connection-options-example","text":"Here is a small example of connection options for mysql: { host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", logging: true, synchronize: true, entities: [ \"entity/*.js\" ], subscribers: [ \"subscriber/*.js\" ], entitySchemas: [ \"schema/*.json\" ], migrations: [ \"migration/*.js\" ], cli: { entitiesDir: \"entity\", migrationsDir: \"migration\", subscribersDir: \"subscriber\" } }","title":"Connection options example"},{"location":"connection/","text":"Working with Connection What is Connection Creating a new connection Using ConnectionManager Working with connection What is Connection Your interaction with the database is only possible once you setup a connection. TypeORM's Connection does not setup a database connection as it might seem, instead it sets up a connection pool. If you are interested in a real database connection, then refer to QueryRunner documentation. Each instance of QueryRunner is a separate isolated database connection. Connection pool setup is established once connect method of the Connection is called. connect method is called automatically if you setup your connection using createConnection function. Disconnection (closing all connections in the pool) is made when close is called. Generally, you must create connection only once in your application bootstrap, and close it after you completely finished working with the database. In practice, if you are building a backend for your site and your backend server always stays running - you never close a connection. Creating a new connection There are several ways how a connection can be created. The most simple and common way is to use createConnection and createConnections functions. createConnection creates a single connection: import {createConnection, Connection} from \"typeorm\"; const connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); A single url attribute, plus the type attribute, will work too. createConnection({ type: 'postgres', url: 'postgres://test:test@localhost/test' }) createConnections creates multiple connections: import {createConnections, Connection} from \"typeorm\"; const connections = await createConnections([{ name: \"default\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { name: \"test2-connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test2\" }]); Both these functions create Connection based on connection options you pass and call a connect method. You can create ormconfig.json file in the root of your project and connection options will be automatically read from this file by those methods. Root of your project is the same level where your node_modules directory is. import {createConnection, createConnections, Connection} from \"typeorm\"; // here createConnection will load connection options from // ormconfig.json / ormconfig.js / ormconfig.yml / ormconfig.env / ormconfig.xml // files, or from special environment variables const connection: Connection = await createConnection(); // you can specify the name of the connection to create // (if you omit name it will create a connection without name specified) const secondConnection: Connection = await createConnection(\"test2-connection\"); // if createConnections is called instead of createConnection then // it will initialize and return all connections defined in ormconfig file const connections: Connection[] = await createConnections(); Different connections must have different names. By default, if connection name is not specified it's equal to default . Usually, you use multiple connections when you use multiple databases or multiple connection configurations. Once you created a connection you can obtain it anywhere from your app, using getConnection function: import {getConnection} from \"typeorm\"; // can be used once createConnection is called and is resolved const connection = getConnection(); // if you have multiple connections you can get connection by name const secondConnection = getConnection(\"test2-connection\"); Avoid creating extra classes / services to store and manage your connections. This functionality is already embedded into TypeORM - you don't need to overengineer and create useless abstractions. Using ConnectionManager You can create connection using ConnectionManager class. For example: import {getConnectionManager, ConnectionManager, Connection} from \"typeorm\"; const connectionManager = getConnectionManager(); const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", }); await connection.connect(); // performs connection This is not a general way of creating a connection, but it may be useful for some users. For example, users who want to create connection and store its instance, but have to control when the actual \"connection\" will be established. Also you can create and maintain your own ConnectionManager : import {getConnectionManager, ConnectionManager, Connection} from \"typeorm\"; const connectionManager = new ConnectionManager(); const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", }); await connection.connect(); // performs connection But note, this way you won't be able to use getConnection() anymore - you'll need to store your connection manager instance and use connectionManager.get to get a connection you need. Generally avoid this method and avoid unnecessary complications in your application, use ConnectionManager only if you really think you need it. Working with connection Once you set your connection up, you can use it anywhere in your app using getConnection function: import {getConnection} from \"typeorm\"; import {User} from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll() { return getConnection().manager.find(User); } } You can also use ConnectionManager#get to get a connection, but using getConnection() is enough in most cases. Using Connection you execute database operations with your entities, particularly using connection's EntityManager and Repository . For more information about them see Entity Manager and Repository documentation. But generally, you don't use Connection much. Most of the time you only create a connection and use getRepository() and getManager() to access your connection's manager and repositories without directly using connection object: import {getManager, getRepository} from \"typeorm\"; import {User} from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll() { return getManager().find(User); } @Get(\"/users/:id\") getAll(@Param(\"id\") userId: number) { return getRepository(User).findOne(userId); } }","title":"Working with Connection"},{"location":"connection/#working-with-connection","text":"What is Connection Creating a new connection Using ConnectionManager Working with connection","title":"Working with Connection"},{"location":"connection/#what-is-connection","text":"Your interaction with the database is only possible once you setup a connection. TypeORM's Connection does not setup a database connection as it might seem, instead it sets up a connection pool. If you are interested in a real database connection, then refer to QueryRunner documentation. Each instance of QueryRunner is a separate isolated database connection. Connection pool setup is established once connect method of the Connection is called. connect method is called automatically if you setup your connection using createConnection function. Disconnection (closing all connections in the pool) is made when close is called. Generally, you must create connection only once in your application bootstrap, and close it after you completely finished working with the database. In practice, if you are building a backend for your site and your backend server always stays running - you never close a connection.","title":"What is Connection"},{"location":"connection/#creating-a-new-connection","text":"There are several ways how a connection can be created. The most simple and common way is to use createConnection and createConnections functions. createConnection creates a single connection: import {createConnection, Connection} from \"typeorm\"; const connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }); A single url attribute, plus the type attribute, will work too. createConnection({ type: 'postgres', url: 'postgres://test:test@localhost/test' }) createConnections creates multiple connections: import {createConnections, Connection} from \"typeorm\"; const connections = await createConnections([{ name: \"default\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { name: \"test2-connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test2\" }]); Both these functions create Connection based on connection options you pass and call a connect method. You can create ormconfig.json file in the root of your project and connection options will be automatically read from this file by those methods. Root of your project is the same level where your node_modules directory is. import {createConnection, createConnections, Connection} from \"typeorm\"; // here createConnection will load connection options from // ormconfig.json / ormconfig.js / ormconfig.yml / ormconfig.env / ormconfig.xml // files, or from special environment variables const connection: Connection = await createConnection(); // you can specify the name of the connection to create // (if you omit name it will create a connection without name specified) const secondConnection: Connection = await createConnection(\"test2-connection\"); // if createConnections is called instead of createConnection then // it will initialize and return all connections defined in ormconfig file const connections: Connection[] = await createConnections(); Different connections must have different names. By default, if connection name is not specified it's equal to default . Usually, you use multiple connections when you use multiple databases or multiple connection configurations. Once you created a connection you can obtain it anywhere from your app, using getConnection function: import {getConnection} from \"typeorm\"; // can be used once createConnection is called and is resolved const connection = getConnection(); // if you have multiple connections you can get connection by name const secondConnection = getConnection(\"test2-connection\"); Avoid creating extra classes / services to store and manage your connections. This functionality is already embedded into TypeORM - you don't need to overengineer and create useless abstractions.","title":"Creating a new connection"},{"location":"connection/#using-connectionmanager","text":"You can create connection using ConnectionManager class. For example: import {getConnectionManager, ConnectionManager, Connection} from \"typeorm\"; const connectionManager = getConnectionManager(); const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", }); await connection.connect(); // performs connection This is not a general way of creating a connection, but it may be useful for some users. For example, users who want to create connection and store its instance, but have to control when the actual \"connection\" will be established. Also you can create and maintain your own ConnectionManager : import {getConnectionManager, ConnectionManager, Connection} from \"typeorm\"; const connectionManager = new ConnectionManager(); const connection = connectionManager.create({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", }); await connection.connect(); // performs connection But note, this way you won't be able to use getConnection() anymore - you'll need to store your connection manager instance and use connectionManager.get to get a connection you need. Generally avoid this method and avoid unnecessary complications in your application, use ConnectionManager only if you really think you need it.","title":"Using ConnectionManager"},{"location":"connection/#working-with-connection_1","text":"Once you set your connection up, you can use it anywhere in your app using getConnection function: import {getConnection} from \"typeorm\"; import {User} from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll() { return getConnection().manager.find(User); } } You can also use ConnectionManager#get to get a connection, but using getConnection() is enough in most cases. Using Connection you execute database operations with your entities, particularly using connection's EntityManager and Repository . For more information about them see Entity Manager and Repository documentation. But generally, you don't use Connection much. Most of the time you only create a connection and use getRepository() and getManager() to access your connection's manager and repositories without directly using connection object: import {getManager, getRepository} from \"typeorm\"; import {User} from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll() { return getManager().find(User); } @Get(\"/users/:id\") getAll(@Param(\"id\") userId: number) { return getRepository(User).findOne(userId); } }","title":"Working with connection"},{"location":"custom-repository/","text":"Custom repositories You can create a custom repository which should contain methods to work with your database. Usually custom repositories are created for a single entity and contains its specific queries. For example, let's say we want to have a method called findByName(firstName: string, lastName: string) which will search for users by a given first and last names. The best place for this method is in Repository , so we could call it like userRepository.findByName(...) . You can achieve this using custom repositories. There are several ways how custom repositories can be created. Custom repository extends standard Repository Custom repository extends standard AbstractRepository Custom repository without extends Using custom repositories in transactions Custom repository extends standard Repository The first way to create a custom repository is to extend Repository . Example: import {EntityRepository, Repository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository(User) export class UserRepository extends Repository<User> { findByName(firstName: string, lastName: string) { return this.findOne({ firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() const user = userRepository.create(); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; await userRepository.save(user); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); As you can see you can \"get\" the repository using getCustomRepository and you can access any method created inside it and any method in the standard entity repository. Custom repository extends standard AbstractRepository The second way to create a custom repository is to extend AbstractRepository : import {EntityRepository, AbstractRepository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository(User) export class UserRepository extends AbstractRepository<User> { createAndSave(firstName: string, lastName: string) { const user = new User(); user.firstName = firstName; user.lastName = lastName; return this.manager.save(user); } findByName(firstName: string, lastName: string) { return this.repository.findOne({ firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); The difference between this type of repository and the previous one is that it does not expose all the methods Repository has. AbstractRepository does not have any public methods, it only has protected methods, like manager and repository , which you can use in your own public methods. Extending AbstractRepository is useful if you don't want to expose all methods the standard Repository has to the public. Custom repository without extends The third way to create a repository is to not extend anything, but define a constructor which always accepts an entity manager instance: import {EntityRepository, Repository, EntityManager} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository() export class UserRepository { constructor(private manager: EntityManager) { } createAndSave(firstName: string, lastName: string) { const user = new User(); user.firstName = firstName; user.lastName = lastName; return this.manager.save(user); } findByName(firstName: string, lastName: string) { return this.manager.findOne(User, { firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); This type of repository does not extend anything - you only need to define a constructor which must accept EntityManager . Then you can use it everywhere in your repository methods. Also, this type of repository is not bound to a specific entity, thus, you can operate with multiple entities inside them. Using custom repositories in transactions or why custom repositories cannot be services Custom repositories cannot be services, because there isn't a single instance of a custom repository (just like regular repositories or entity manager) in the app. Besides the fact that there can be multiple connections in your app (where entity manager and repositories are different) repositories and managers are different in transactions as well. For example: await connection.transaction(async manager => { // in transactions you MUST use manager instance provided by a transaction, // you cannot use global managers, repositories or custom repositories // because this manager is exclusive and transactional // and if let's say we would do custom repository as a service // it has a \"manager\" property which should be unique instance of EntityManager // but there is no global EntityManager instance and cannot be // thats why custom managers are specific to each EntityManager and cannot be services. // this also opens opportunity to use custom repositories in transactions without any issues: const userRepository = manager.getCustomRepository(UserRepository); // DONT USE GLOBAL getCustomRepository here! await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); });","title":"Custom repositories"},{"location":"custom-repository/#custom-repositories","text":"You can create a custom repository which should contain methods to work with your database. Usually custom repositories are created for a single entity and contains its specific queries. For example, let's say we want to have a method called findByName(firstName: string, lastName: string) which will search for users by a given first and last names. The best place for this method is in Repository , so we could call it like userRepository.findByName(...) . You can achieve this using custom repositories. There are several ways how custom repositories can be created. Custom repository extends standard Repository Custom repository extends standard AbstractRepository Custom repository without extends Using custom repositories in transactions","title":"Custom repositories"},{"location":"custom-repository/#custom-repository-extends-standard-repository","text":"The first way to create a custom repository is to extend Repository . Example: import {EntityRepository, Repository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository(User) export class UserRepository extends Repository<User> { findByName(firstName: string, lastName: string) { return this.findOne({ firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() const user = userRepository.create(); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; await userRepository.save(user); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); As you can see you can \"get\" the repository using getCustomRepository and you can access any method created inside it and any method in the standard entity repository.","title":"Custom repository extends standard Repository"},{"location":"custom-repository/#custom-repository-extends-standard-abstractrepository","text":"The second way to create a custom repository is to extend AbstractRepository : import {EntityRepository, AbstractRepository} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository(User) export class UserRepository extends AbstractRepository<User> { createAndSave(firstName: string, lastName: string) { const user = new User(); user.firstName = firstName; user.lastName = lastName; return this.manager.save(user); } findByName(firstName: string, lastName: string) { return this.repository.findOne({ firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); The difference between this type of repository and the previous one is that it does not expose all the methods Repository has. AbstractRepository does not have any public methods, it only has protected methods, like manager and repository , which you can use in your own public methods. Extending AbstractRepository is useful if you don't want to expose all methods the standard Repository has to the public.","title":"Custom repository extends standard AbstractRepository"},{"location":"custom-repository/#custom-repository-without-extends","text":"The third way to create a repository is to not extend anything, but define a constructor which always accepts an entity manager instance: import {EntityRepository, Repository, EntityManager} from \"typeorm\"; import {User} from \"../entity/User\"; @EntityRepository() export class UserRepository { constructor(private manager: EntityManager) { } createAndSave(firstName: string, lastName: string) { const user = new User(); user.firstName = firstName; user.lastName = lastName; return this.manager.save(user); } findByName(firstName: string, lastName: string) { return this.manager.findOne(User, { firstName, lastName }); } } Then you can use it this way: import {getCustomRepository} from \"typeorm\"; import {UserRepository} from \"./repository/UserRepository\"; const userRepository = getCustomRepository(UserRepository); // or connection.getCustomRepository or manager.getCustomRepository() await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); This type of repository does not extend anything - you only need to define a constructor which must accept EntityManager . Then you can use it everywhere in your repository methods. Also, this type of repository is not bound to a specific entity, thus, you can operate with multiple entities inside them.","title":"Custom repository without extends"},{"location":"custom-repository/#using-custom-repositories-in-transactions-or-why-custom-repositories-cannot-be-services","text":"Custom repositories cannot be services, because there isn't a single instance of a custom repository (just like regular repositories or entity manager) in the app. Besides the fact that there can be multiple connections in your app (where entity manager and repositories are different) repositories and managers are different in transactions as well. For example: await connection.transaction(async manager => { // in transactions you MUST use manager instance provided by a transaction, // you cannot use global managers, repositories or custom repositories // because this manager is exclusive and transactional // and if let's say we would do custom repository as a service // it has a \"manager\" property which should be unique instance of EntityManager // but there is no global EntityManager instance and cannot be // thats why custom managers are specific to each EntityManager and cannot be services. // this also opens opportunity to use custom repositories in transactions without any issues: const userRepository = manager.getCustomRepository(UserRepository); // DONT USE GLOBAL getCustomRepository here! await userRepository.createAndSave(\"Timber\", \"Saw\"); const timber = await userRepository.findByName(\"Timber\", \"Saw\"); });","title":"Using custom repositories in transactions or why custom repositories cannot be services"},{"location":"decorator-reference/","text":"Decorators reference Entity decorators @Entity @ViewEntity Column decorators @Column @PrimaryColumn @PrimaryGeneratedColumn @ObjectIdColumn @CreateDateColumn @UpdateDateColumn @DeleteDateColumn @VersionColumn @Generated Relation decorators @OneToOne @ManyToOne @OneToMany @ManyToMany @JoinColumn @JoinTable @RelationId Subscriber and listener decorators @AfterLoad @BeforeInsert @AfterInsert @BeforeUpdate @AfterUpdate @BeforeRemove @AfterRemove @EventSubscriber Other decorators @Index @Unique @Check @Exclusion @Transaction , @TransactionManager and @TransactionRepository @EntityRepository Entity decorators @Entity Marks your model as an entity. Entity is a class which is transformed into a database table. You can specify the table name in the entity: @Entity(\"users\") export class User { This code will create a database table named \"users\". You can also specify some additional entity options: name - table name. If not specified, then table name is generated from entity class name. database - database name in selected DB server. schema - schema name. engine - database engine to be set during table creation (works only in some databases). synchronize - entities marked with false are skipped from schema updates. orderBy - specifies default ordering for entities when using find operations and QueryBuilder . Example: @Entity({ name: \"users\", engine: \"MyISAM\", database: 'example_dev', schema: 'schema_with_best_tables', synchronize: false, orderBy: { name: \"ASC\", id: \"DESC\" } }) export class User { Learn more about Entities . @ViewEntity View entity is a class that maps to a database view. @ViewEntity() accepts following options: name - view name. If not specified, then view name is generated from entity class name. database - database name in selected DB server. schema - schema name. expression - view definition. Required parameter . expression can be string with properly escaped columns and tables, depend on database used (postgres in example): @ViewEntity({ expression: ` SELECT \"post\".\"id\" \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) export class PostCategory { or an instance of QueryBuilder @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { Note: parameter binding is not supported due to drivers limitations. Use the literal parameters instead. @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") .where(\"category.name = :name\", { name: \"Cars\" }) // <-- this is wrong .where(\"category.name = 'Cars'\") // <-- and this is right }) export class PostCategory { Learn more about View Entities . Column decorators @Column Marks a property in your entity as a table column. Example: @Entity(\"users\") export class User { @Column({ primary: true }) id: number; @Column({ type: \"varchar\", length: 200, unique: true }) firstName: string; @Column({ nullable: true }) lastName: string; @Column({ default: false }) isActive: boolean; } @Column accept several options you can use: type: ColumnType - Column type. One of the supported column types . name: string - Column name in the database table. By default the column name is generated from the name of the property. You can change it by specifying your own name. length: string|number - Column type's length. For example, if you want to create varchar(150) type you specify column type and length options. width: number - column type's display width. Used only for MySQL integer types onUpdate: string - ON UPDATE trigger. Used only in MySQL . nullable: boolean - Makes column NULL or NOT NULL in the database. By default column is nullable: false . update: boolean - Indicates if column value is updated by \"save\" operation. If false, you'll be able to write this value only when you first time insert the object. Default value is true . insert: boolean - Indicates if column value is set the first time you insert the object. Default value is true . select: boolean - Defines whether or not to hide this column by default when making queries. When set to false , the column data will not show with a standard query. By default column is select: true default: string - Adds database-level column's DEFAULT value. primary: boolean - Marks column as primary. Same as using @PrimaryColumn . unique: boolean - Marks column as unique column (creates unique constraint). Default value is false. comment: string - Database's column comment. Not supported by all database types. precision: number - The precision for a decimal (exact numeric) column (applies only for decimal column), which is the maximum number of digits that are stored for the values. Used in some column types. scale: number - The scale for a decimal (exact numeric) column (applies only for decimal column), which represents the number of digits to the right of the decimal point and must not be greater than precision. Used in some column types. zerofill: boolean - Puts ZEROFILL attribute on to a numeric column. Used only in MySQL. If true , MySQL automatically adds the UNSIGNED attribute to this column. unsigned: boolean - Puts UNSIGNED attribute on to a numeric column. Used only in MySQL. charset: string - Defines a column character set. Not supported by all database types. collation: string - Defines a column collation. enum: string[]|AnyEnum - Used in enum column type to specify list of allowed enum values. You can specify array of values or specify a enum class. enumName: string - A name for generated enum type. If not specified, TypeORM will generate a enum type from entity and column names - so it's neccessary if you intend to use the same enum type in different tables. asExpression: string - Generated column expression. Used only in MySQL . generatedType: \"VIRTUAL\"|\"STORED\" - Generated column type. Used only in MySQL . hstoreType: \"object\"|\"string\" - Return type of HSTORE column. Returns value as string or as object. Used only in Postgres . array: boolean - Used for postgres and cockroachdb column types which can be array (for example int[]). transformer: ValueTransformer|ValueTransformer[] - Specifies a value transformer (or array of value transformers) that is to be used to (un)marshal this column when reading or writing to the database. In case of an array, the value transformers will be applied in the natural order from entityValue to databaseValue, and in reverse order from databaseValue to entityValue. spatialFeatureType: string - Optional feature type ( Point , Polygon , LineString , Geometry ) used as a constraint on a spatial column. If not specified, it will behave as though Geometry was provided. Used only in PostgreSQL. srid: number - Optional Spatial Reference ID used as a constraint on a spatial column. If not specified, it will default to 0 . Standard geographic coordinates (latitude/longitude in the WGS84 datum) correspond to EPSG 4326 . Used only in PostgreSQL. Learn more about entity columns . @PrimaryColumn Marks a property in your entity as a table primary column. Same as @Column decorator but sets its primary option to true. Example: @Entity() export class User { @PrimaryColumn() id: number; } Learn more about entity columns . @PrimaryGeneratedColumn Marks a property in your entity as a table-generated primary column. Column it creates is primary and its value is auto-generated. Example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; } There are two generation strategies: increment - uses AUTO_INCREMENT / SERIAL / SEQUENCE (depend on database type) to generate incremental number. uuid - generates unique uuid string. rowid - only for CockroachDB . Value is automatically generated using the unique_rowid() function. This produces a 64-bit integer from the current timestamp and ID of the node executing the INSERT or UPSERT operation. Note: property with a rowid generation strategy must be a string data type Default generation strategy is increment , to change it to another strategy, simply pass it as the first argument to decorator: @Entity() export class User { @PrimaryGeneratedColumn(\"uuid\") id: string; } Learn more about entity columns . @ObjectIdColumn Marks a property in your entity as ObjectID. This decorator is only used in MongoDB. Every entity in MongoDB must have a ObjectID column. Example: @Entity() export class User { @ObjectIdColumn() id: ObjectID; } Learn more about MongoDB . @CreateDateColumn Special column that is automatically set to the entity's insertion time. You don't need to write a value into this column - it will be automatically set. Example: @Entity() export class User { @CreateDateColumn() createdDate: Date; } @UpdateDateColumn Special column that is automatically set to the entity's update time each time you call save from entity manager or repository. You don't need to write a value into this column - it will be automatically set. @Entity() export class User { @UpdateDateColumn() updatedDate: Date; } @DeleteDateColumn Special column that is automatically set to the entity's delete time each time you call soft-delete of entity manager or repository. You don't need to set this column - it will be automatically set. TypeORM's own soft delete functionality utilizes global scopes to only pull \"non-deleted\" entities from the database. If the @DeleteDateColumn is set, the default scope will be \"non-deleted\". @Entity() export class User { @DeleteDateColumn() deletedDate: Date; } @VersionColumn Special column that is automatically set to the entity's version (incremental number) each time you call save from entity manager or repository. You don't need to write a value into this column - it will be automatically set. @Entity() export class User { @VersionColumn() version: number; } @Generated Marks column to be a generated value. For example: @Entity() export class User { @Column() @Generated(\"uuid\") uuid: string; } Value will be generated only once, before inserting the entity into the database. Relation decorators @OneToOne One-to-one is a relation where A contains only once instance of B, and B contains only one instance of A. Let's take for example User and Profile entities. User can have only a single profile, and a single profile is owned by only a single user. Example: import {Entity, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @OneToOne(type => Profile, profile => profile.user) @JoinColumn() profile: Profile; } Learn more about one-to-one relations . @ManyToOne Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only one single user. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(type => User, user => user.photos) user: User; } Learn more about many-to-one / one-to-many relations . @OneToMany Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only a single user. Example: import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(type => Photo, photo => photo.user) photos: Photo[]; } Learn more about many-to-one / one-to-many relations . @ManyToMany Many-to-many is a relation where A contains multiple instances of B, and B contain multiple instances of A. Let's take for example Question and Category entities. Question can have multiple categories, and each category can have multiple questions. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category) @JoinTable() categories: Category[]; } Learn more about many-to-many relations . @JoinColumn Defines which side of the relation contains the join column with a foreign key and allows you to customize the join column name and referenced column name. Example: @Entity() export class Post { @ManyToOne(type => Category) @JoinColumn({ name: \"cat_id\", referencedColumnName: \"name\" }) category: Category; } @JoinTable Used for many-to-many relations and describes join columns of the \"junction\" table. Junction table is a special, separate table created automatically by TypeORM with columns referenced to the related entities. You can change the column names inside the junction table and their referenced columns with the @JoinColumn decorator. You can also change the name of the generated \"junction\" table. Example: @Entity() export class Post { @ManyToMany(type => Category) @JoinTable({ name: \"question_categories\", joinColumn: { name: \"question\", referencedColumnName: \"id\" }, inverseJoinColumn: { name: \"category\", referencedColumnName: \"id\" } }) categories: Category[]; } If the destination table has composite primary keys, then an array of properties must be sent to the @JoinTable decorator. @RelationId Loads id (or ids) of specific relations into properties. For example, if you have a many-to-one category in your Post entity, you can have a new category id by marking a new property with @RelationId . Example: @Entity() export class Post { @ManyToOne(type => Category) category: Category; @RelationId((post: Post) => post.category) // you need to specify target relation categoryId: number; } This functionality works for all kind of relations, including many-to-many : @Entity() export class Post { @ManyToMany(type => Category) categories: Category[]; @RelationId((post: Post) => post.categories) categoryIds: number[]; } Relation id is used only for representation. The underlying relation is not added/removed/changed when chaining the value. Subscriber and listener decorators @AfterLoad You can define a method with any name in entity and mark it with @AfterLoad and TypeORM will call it each time the entity is loaded using QueryBuilder or repository/manager find methods. Example: @Entity() export class Post { @AfterLoad() updateCounters() { if (this.likesCount === undefined) this.likesCount = 0; } } Learn more about listeners . @BeforeInsert You can define a method with any name in entity and mark it with @BeforeInsert and TypeORM will call it before the entity is inserted using repository/manager save . Example: @Entity() export class Post { @BeforeInsert() updateDates() { this.createdDate = new Date(); } } Learn more about listeners . @AfterInsert You can define a method with any name in entity and mark it with @AfterInsert and TypeORM will call it after the entity is inserted using repository/manager save . Example: @Entity() export class Post { @AfterInsert() resetCounters() { this.counters = 0; } } Learn more about listeners . @BeforeUpdate You can define a method with any name in the entity and mark it with @BeforeUpdate and TypeORM will call it before an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @BeforeUpdate() updateDates() { this.updatedDate = new Date(); } } Learn more about listeners . @AfterUpdate You can define a method with any name in the entity and mark it with @AfterUpdate and TypeORM will call it after an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @AfterUpdate() updateCounters() { this.counter = 0; } } Learn more about listeners . @BeforeRemove You can define a method with any name in the entity and mark it with @BeforeRemove and TypeORM will call it before a entity is removed using repository/manager remove . Example: @Entity() export class Post { @BeforeRemove() updateStatus() { this.status = \"removed\"; } } Learn more about listeners . @AfterRemove You can define a method with any name in the entity and mark it with @AfterRemove and TypeORM will call it after the entity is removed using repository/manager remove . Example: @Entity() export class Post { @AfterRemove() updateStatus() { this.status = \"removed\"; } } Learn more about listeners . @EventSubscriber Marks a class as an event subscriber which can listen to specific entity events or any entity's events. Events are fired using QueryBuilder and repository/manager methods. Example: @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface<Post> { /** * Indicates that this subscriber only listen to Post events. */ listenTo() { return Post; } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<Post>) { console.log(`BEFORE POST INSERTED: `, event.entity); } } You can implement any method from EntitySubscriberInterface . To listen to any entity, you just omit the listenTo method and use any : @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface { /** * Called before entity insertion. */ beforeInsert(event: InsertEvent<any>) { console.log(`BEFORE ENTITY INSERTED: `, event.entity); } } Learn more about subscribers . Other decorators @Index This decorator allows you to create a database index for a specific column or columns. It also allows you to mark column or columns to be unique. This decorator can be applied to columns or an entity itself. Use it on a column when an index on a single column is needed and use it on the entity when a single index on multiple columns is required. Examples: @Entity() export class User { @Index() @Column() firstName: string; @Index({ unique: true }) @Column() lastName: string; } @Entity() @Index([\"firstName\", \"lastName\"]) @Index([\"lastName\", \"middleName\"]) @Index([\"firstName\", \"lastName\", \"middleName\"], { unique: true }) export class User { @Column() firstName: string; @Column() lastName: string; @Column() middleName: string; } Learn more about indices . @Unique This decorator allows you to create a database unique constraint for a specific column or columns. This decorator can be applied only to an entity itself. You must specify the entity field names (not database column names) as arguments. Examples: @Entity() @Unique([\"firstName\"]) @Unique([\"lastName\", \"middleName\"]) @Unique(\"UQ_NAMES\", [\"firstName\", \"lastName\", \"middleName\"]) export class User { @Column({ name: 'first_name' }) firstName: string; @Column({ name: 'last_name' }) lastName: string; @Column({ name: 'middle_name' }) middleName: string; } Note: MySQL stores unique constraints as unique indices @Check This decorator allows you to create a database check constraint for a specific column or columns. This decorator can be applied only to an entity itself. Examples: @Entity() @Check(`\"firstName\" <> 'John' AND \"lastName\" <> 'Doe'`) @Check(`\"age\" > 18`) export class User { @Column() firstName: string; @Column() lastName: string; @Column() age: number; } Note: MySQL does not support check constraints. @Exclusion This decorator allows you to create a database exclusion constraint for a specific column or columns. This decorator can be applied only to an entity itself. Examples: @Entity() @Exclusion(`USING gist (\"room\" WITH =, tsrange(\"from\", \"to\") WITH &&)`) export class RoomBooking { @Column() room: string; @Column() from: Date; @Column() to: Date; } Note: Only PostgreSQL supports exclusion constraints. @Transaction , @TransactionManager and @TransactionRepository @Transaction is used on a method and wraps all its execution into a single database transaction. All database queries must be performed using the @TransactionManager provided manager or with the transaction repositories injected with @TransactionRepository . Examples: @Transaction() save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } @Transaction() save(user: User, @TransactionRepository(User) userRepository: Repository<User>) { return userRepository.save(user); } @Transaction() save(@QueryParam(\"name\") name: string, @TransactionRepository() userRepository: UserRepository) { return userRepository.findByName(name); } Note: all operations inside a transaction MUST ONLY use the provided instance of EntityManager or injected repositories. Using any other source of queries (global manager, global repositories, etc.) will lead to bugs and errors. Learn more about transactions . @EntityRepository Marks a custom class as an entity repository. Example: @EntityRepository() export class UserRepository { /// ... custom repository methods ... } You can obtain any custom created repository using connection.getCustomRepository or entityManager.getCustomRepository methods. Learn more about custom entity repositories . Note: some decorators (like @Tree , @ChildEntity , etc.) aren't documented in this reference because they are treated as experimental at the moment. Expect to see their documentation in the future.","title":"Decorators reference"},{"location":"decorator-reference/#decorators-reference","text":"Entity decorators @Entity @ViewEntity Column decorators @Column @PrimaryColumn @PrimaryGeneratedColumn @ObjectIdColumn @CreateDateColumn @UpdateDateColumn @DeleteDateColumn @VersionColumn @Generated Relation decorators @OneToOne @ManyToOne @OneToMany @ManyToMany @JoinColumn @JoinTable @RelationId Subscriber and listener decorators @AfterLoad @BeforeInsert @AfterInsert @BeforeUpdate @AfterUpdate @BeforeRemove @AfterRemove @EventSubscriber Other decorators @Index @Unique @Check @Exclusion @Transaction , @TransactionManager and @TransactionRepository @EntityRepository","title":"Decorators reference"},{"location":"decorator-reference/#entity-decorators","text":"","title":"Entity decorators"},{"location":"decorator-reference/#entity","text":"Marks your model as an entity. Entity is a class which is transformed into a database table. You can specify the table name in the entity: @Entity(\"users\") export class User { This code will create a database table named \"users\". You can also specify some additional entity options: name - table name. If not specified, then table name is generated from entity class name. database - database name in selected DB server. schema - schema name. engine - database engine to be set during table creation (works only in some databases). synchronize - entities marked with false are skipped from schema updates. orderBy - specifies default ordering for entities when using find operations and QueryBuilder . Example: @Entity({ name: \"users\", engine: \"MyISAM\", database: 'example_dev', schema: 'schema_with_best_tables', synchronize: false, orderBy: { name: \"ASC\", id: \"DESC\" } }) export class User { Learn more about Entities .","title":"@Entity"},{"location":"decorator-reference/#viewentity","text":"View entity is a class that maps to a database view. @ViewEntity() accepts following options: name - view name. If not specified, then view name is generated from entity class name. database - database name in selected DB server. schema - schema name. expression - view definition. Required parameter . expression can be string with properly escaped columns and tables, depend on database used (postgres in example): @ViewEntity({ expression: ` SELECT \"post\".\"id\" \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) export class PostCategory { or an instance of QueryBuilder @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { Note: parameter binding is not supported due to drivers limitations. Use the literal parameters instead. @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") .where(\"category.name = :name\", { name: \"Cars\" }) // <-- this is wrong .where(\"category.name = 'Cars'\") // <-- and this is right }) export class PostCategory { Learn more about View Entities .","title":"@ViewEntity"},{"location":"decorator-reference/#column-decorators","text":"","title":"Column decorators"},{"location":"decorator-reference/#column","text":"Marks a property in your entity as a table column. Example: @Entity(\"users\") export class User { @Column({ primary: true }) id: number; @Column({ type: \"varchar\", length: 200, unique: true }) firstName: string; @Column({ nullable: true }) lastName: string; @Column({ default: false }) isActive: boolean; } @Column accept several options you can use: type: ColumnType - Column type. One of the supported column types . name: string - Column name in the database table. By default the column name is generated from the name of the property. You can change it by specifying your own name. length: string|number - Column type's length. For example, if you want to create varchar(150) type you specify column type and length options. width: number - column type's display width. Used only for MySQL integer types onUpdate: string - ON UPDATE trigger. Used only in MySQL . nullable: boolean - Makes column NULL or NOT NULL in the database. By default column is nullable: false . update: boolean - Indicates if column value is updated by \"save\" operation. If false, you'll be able to write this value only when you first time insert the object. Default value is true . insert: boolean - Indicates if column value is set the first time you insert the object. Default value is true . select: boolean - Defines whether or not to hide this column by default when making queries. When set to false , the column data will not show with a standard query. By default column is select: true default: string - Adds database-level column's DEFAULT value. primary: boolean - Marks column as primary. Same as using @PrimaryColumn . unique: boolean - Marks column as unique column (creates unique constraint). Default value is false. comment: string - Database's column comment. Not supported by all database types. precision: number - The precision for a decimal (exact numeric) column (applies only for decimal column), which is the maximum number of digits that are stored for the values. Used in some column types. scale: number - The scale for a decimal (exact numeric) column (applies only for decimal column), which represents the number of digits to the right of the decimal point and must not be greater than precision. Used in some column types. zerofill: boolean - Puts ZEROFILL attribute on to a numeric column. Used only in MySQL. If true , MySQL automatically adds the UNSIGNED attribute to this column. unsigned: boolean - Puts UNSIGNED attribute on to a numeric column. Used only in MySQL. charset: string - Defines a column character set. Not supported by all database types. collation: string - Defines a column collation. enum: string[]|AnyEnum - Used in enum column type to specify list of allowed enum values. You can specify array of values or specify a enum class. enumName: string - A name for generated enum type. If not specified, TypeORM will generate a enum type from entity and column names - so it's neccessary if you intend to use the same enum type in different tables. asExpression: string - Generated column expression. Used only in MySQL . generatedType: \"VIRTUAL\"|\"STORED\" - Generated column type. Used only in MySQL . hstoreType: \"object\"|\"string\" - Return type of HSTORE column. Returns value as string or as object. Used only in Postgres . array: boolean - Used for postgres and cockroachdb column types which can be array (for example int[]). transformer: ValueTransformer|ValueTransformer[] - Specifies a value transformer (or array of value transformers) that is to be used to (un)marshal this column when reading or writing to the database. In case of an array, the value transformers will be applied in the natural order from entityValue to databaseValue, and in reverse order from databaseValue to entityValue. spatialFeatureType: string - Optional feature type ( Point , Polygon , LineString , Geometry ) used as a constraint on a spatial column. If not specified, it will behave as though Geometry was provided. Used only in PostgreSQL. srid: number - Optional Spatial Reference ID used as a constraint on a spatial column. If not specified, it will default to 0 . Standard geographic coordinates (latitude/longitude in the WGS84 datum) correspond to EPSG 4326 . Used only in PostgreSQL. Learn more about entity columns .","title":"@Column"},{"location":"decorator-reference/#primarycolumn","text":"Marks a property in your entity as a table primary column. Same as @Column decorator but sets its primary option to true. Example: @Entity() export class User { @PrimaryColumn() id: number; } Learn more about entity columns .","title":"@PrimaryColumn"},{"location":"decorator-reference/#primarygeneratedcolumn","text":"Marks a property in your entity as a table-generated primary column. Column it creates is primary and its value is auto-generated. Example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; } There are two generation strategies: increment - uses AUTO_INCREMENT / SERIAL / SEQUENCE (depend on database type) to generate incremental number. uuid - generates unique uuid string. rowid - only for CockroachDB . Value is automatically generated using the unique_rowid() function. This produces a 64-bit integer from the current timestamp and ID of the node executing the INSERT or UPSERT operation. Note: property with a rowid generation strategy must be a string data type Default generation strategy is increment , to change it to another strategy, simply pass it as the first argument to decorator: @Entity() export class User { @PrimaryGeneratedColumn(\"uuid\") id: string; } Learn more about entity columns .","title":"@PrimaryGeneratedColumn"},{"location":"decorator-reference/#objectidcolumn","text":"Marks a property in your entity as ObjectID. This decorator is only used in MongoDB. Every entity in MongoDB must have a ObjectID column. Example: @Entity() export class User { @ObjectIdColumn() id: ObjectID; } Learn more about MongoDB .","title":"@ObjectIdColumn"},{"location":"decorator-reference/#createdatecolumn","text":"Special column that is automatically set to the entity's insertion time. You don't need to write a value into this column - it will be automatically set. Example: @Entity() export class User { @CreateDateColumn() createdDate: Date; }","title":"@CreateDateColumn"},{"location":"decorator-reference/#updatedatecolumn","text":"Special column that is automatically set to the entity's update time each time you call save from entity manager or repository. You don't need to write a value into this column - it will be automatically set. @Entity() export class User { @UpdateDateColumn() updatedDate: Date; }","title":"@UpdateDateColumn"},{"location":"decorator-reference/#deletedatecolumn","text":"Special column that is automatically set to the entity's delete time each time you call soft-delete of entity manager or repository. You don't need to set this column - it will be automatically set. TypeORM's own soft delete functionality utilizes global scopes to only pull \"non-deleted\" entities from the database. If the @DeleteDateColumn is set, the default scope will be \"non-deleted\". @Entity() export class User { @DeleteDateColumn() deletedDate: Date; }","title":"@DeleteDateColumn"},{"location":"decorator-reference/#versioncolumn","text":"Special column that is automatically set to the entity's version (incremental number) each time you call save from entity manager or repository. You don't need to write a value into this column - it will be automatically set. @Entity() export class User { @VersionColumn() version: number; }","title":"@VersionColumn"},{"location":"decorator-reference/#generated","text":"Marks column to be a generated value. For example: @Entity() export class User { @Column() @Generated(\"uuid\") uuid: string; } Value will be generated only once, before inserting the entity into the database.","title":"@Generated"},{"location":"decorator-reference/#relation-decorators","text":"","title":"Relation decorators"},{"location":"decorator-reference/#onetoone","text":"One-to-one is a relation where A contains only once instance of B, and B contains only one instance of A. Let's take for example User and Profile entities. User can have only a single profile, and a single profile is owned by only a single user. Example: import {Entity, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @OneToOne(type => Profile, profile => profile.user) @JoinColumn() profile: Profile; } Learn more about one-to-one relations .","title":"@OneToOne"},{"location":"decorator-reference/#manytoone","text":"Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only one single user. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(type => User, user => user.photos) user: User; } Learn more about many-to-one / one-to-many relations .","title":"@ManyToOne"},{"location":"decorator-reference/#onetomany","text":"Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only a single user. Example: import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(type => Photo, photo => photo.user) photos: Photo[]; } Learn more about many-to-one / one-to-many relations .","title":"@OneToMany"},{"location":"decorator-reference/#manytomany","text":"Many-to-many is a relation where A contains multiple instances of B, and B contain multiple instances of A. Let's take for example Question and Category entities. Question can have multiple categories, and each category can have multiple questions. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category) @JoinTable() categories: Category[]; } Learn more about many-to-many relations .","title":"@ManyToMany"},{"location":"decorator-reference/#joincolumn","text":"Defines which side of the relation contains the join column with a foreign key and allows you to customize the join column name and referenced column name. Example: @Entity() export class Post { @ManyToOne(type => Category) @JoinColumn({ name: \"cat_id\", referencedColumnName: \"name\" }) category: Category; }","title":"@JoinColumn"},{"location":"decorator-reference/#jointable","text":"Used for many-to-many relations and describes join columns of the \"junction\" table. Junction table is a special, separate table created automatically by TypeORM with columns referenced to the related entities. You can change the column names inside the junction table and their referenced columns with the @JoinColumn decorator. You can also change the name of the generated \"junction\" table. Example: @Entity() export class Post { @ManyToMany(type => Category) @JoinTable({ name: \"question_categories\", joinColumn: { name: \"question\", referencedColumnName: \"id\" }, inverseJoinColumn: { name: \"category\", referencedColumnName: \"id\" } }) categories: Category[]; } If the destination table has composite primary keys, then an array of properties must be sent to the @JoinTable decorator.","title":"@JoinTable"},{"location":"decorator-reference/#relationid","text":"Loads id (or ids) of specific relations into properties. For example, if you have a many-to-one category in your Post entity, you can have a new category id by marking a new property with @RelationId . Example: @Entity() export class Post { @ManyToOne(type => Category) category: Category; @RelationId((post: Post) => post.category) // you need to specify target relation categoryId: number; } This functionality works for all kind of relations, including many-to-many : @Entity() export class Post { @ManyToMany(type => Category) categories: Category[]; @RelationId((post: Post) => post.categories) categoryIds: number[]; } Relation id is used only for representation. The underlying relation is not added/removed/changed when chaining the value.","title":"@RelationId"},{"location":"decorator-reference/#subscriber-and-listener-decorators","text":"","title":"Subscriber and listener decorators"},{"location":"decorator-reference/#afterload","text":"You can define a method with any name in entity and mark it with @AfterLoad and TypeORM will call it each time the entity is loaded using QueryBuilder or repository/manager find methods. Example: @Entity() export class Post { @AfterLoad() updateCounters() { if (this.likesCount === undefined) this.likesCount = 0; } } Learn more about listeners .","title":"@AfterLoad"},{"location":"decorator-reference/#beforeinsert","text":"You can define a method with any name in entity and mark it with @BeforeInsert and TypeORM will call it before the entity is inserted using repository/manager save . Example: @Entity() export class Post { @BeforeInsert() updateDates() { this.createdDate = new Date(); } } Learn more about listeners .","title":"@BeforeInsert"},{"location":"decorator-reference/#afterinsert","text":"You can define a method with any name in entity and mark it with @AfterInsert and TypeORM will call it after the entity is inserted using repository/manager save . Example: @Entity() export class Post { @AfterInsert() resetCounters() { this.counters = 0; } } Learn more about listeners .","title":"@AfterInsert"},{"location":"decorator-reference/#beforeupdate","text":"You can define a method with any name in the entity and mark it with @BeforeUpdate and TypeORM will call it before an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @BeforeUpdate() updateDates() { this.updatedDate = new Date(); } } Learn more about listeners .","title":"@BeforeUpdate"},{"location":"decorator-reference/#afterupdate","text":"You can define a method with any name in the entity and mark it with @AfterUpdate and TypeORM will call it after an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @AfterUpdate() updateCounters() { this.counter = 0; } } Learn more about listeners .","title":"@AfterUpdate"},{"location":"decorator-reference/#beforeremove","text":"You can define a method with any name in the entity and mark it with @BeforeRemove and TypeORM will call it before a entity is removed using repository/manager remove . Example: @Entity() export class Post { @BeforeRemove() updateStatus() { this.status = \"removed\"; } } Learn more about listeners .","title":"@BeforeRemove"},{"location":"decorator-reference/#afterremove","text":"You can define a method with any name in the entity and mark it with @AfterRemove and TypeORM will call it after the entity is removed using repository/manager remove . Example: @Entity() export class Post { @AfterRemove() updateStatus() { this.status = \"removed\"; } } Learn more about listeners .","title":"@AfterRemove"},{"location":"decorator-reference/#eventsubscriber","text":"Marks a class as an event subscriber which can listen to specific entity events or any entity's events. Events are fired using QueryBuilder and repository/manager methods. Example: @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface<Post> { /** * Indicates that this subscriber only listen to Post events. */ listenTo() { return Post; } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<Post>) { console.log(`BEFORE POST INSERTED: `, event.entity); } } You can implement any method from EntitySubscriberInterface . To listen to any entity, you just omit the listenTo method and use any : @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface { /** * Called before entity insertion. */ beforeInsert(event: InsertEvent<any>) { console.log(`BEFORE ENTITY INSERTED: `, event.entity); } } Learn more about subscribers .","title":"@EventSubscriber"},{"location":"decorator-reference/#other-decorators","text":"","title":"Other decorators"},{"location":"decorator-reference/#index","text":"This decorator allows you to create a database index for a specific column or columns. It also allows you to mark column or columns to be unique. This decorator can be applied to columns or an entity itself. Use it on a column when an index on a single column is needed and use it on the entity when a single index on multiple columns is required. Examples: @Entity() export class User { @Index() @Column() firstName: string; @Index({ unique: true }) @Column() lastName: string; } @Entity() @Index([\"firstName\", \"lastName\"]) @Index([\"lastName\", \"middleName\"]) @Index([\"firstName\", \"lastName\", \"middleName\"], { unique: true }) export class User { @Column() firstName: string; @Column() lastName: string; @Column() middleName: string; } Learn more about indices .","title":"@Index"},{"location":"decorator-reference/#unique","text":"This decorator allows you to create a database unique constraint for a specific column or columns. This decorator can be applied only to an entity itself. You must specify the entity field names (not database column names) as arguments. Examples: @Entity() @Unique([\"firstName\"]) @Unique([\"lastName\", \"middleName\"]) @Unique(\"UQ_NAMES\", [\"firstName\", \"lastName\", \"middleName\"]) export class User { @Column({ name: 'first_name' }) firstName: string; @Column({ name: 'last_name' }) lastName: string; @Column({ name: 'middle_name' }) middleName: string; } Note: MySQL stores unique constraints as unique indices","title":"@Unique"},{"location":"decorator-reference/#check","text":"This decorator allows you to create a database check constraint for a specific column or columns. This decorator can be applied only to an entity itself. Examples: @Entity() @Check(`\"firstName\" <> 'John' AND \"lastName\" <> 'Doe'`) @Check(`\"age\" > 18`) export class User { @Column() firstName: string; @Column() lastName: string; @Column() age: number; } Note: MySQL does not support check constraints.","title":"@Check"},{"location":"decorator-reference/#exclusion","text":"This decorator allows you to create a database exclusion constraint for a specific column or columns. This decorator can be applied only to an entity itself. Examples: @Entity() @Exclusion(`USING gist (\"room\" WITH =, tsrange(\"from\", \"to\") WITH &&)`) export class RoomBooking { @Column() room: string; @Column() from: Date; @Column() to: Date; } Note: Only PostgreSQL supports exclusion constraints.","title":"@Exclusion"},{"location":"decorator-reference/#transaction-transactionmanager-and-transactionrepository","text":"@Transaction is used on a method and wraps all its execution into a single database transaction. All database queries must be performed using the @TransactionManager provided manager or with the transaction repositories injected with @TransactionRepository . Examples: @Transaction() save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } @Transaction() save(user: User, @TransactionRepository(User) userRepository: Repository<User>) { return userRepository.save(user); } @Transaction() save(@QueryParam(\"name\") name: string, @TransactionRepository() userRepository: UserRepository) { return userRepository.findByName(name); } Note: all operations inside a transaction MUST ONLY use the provided instance of EntityManager or injected repositories. Using any other source of queries (global manager, global repositories, etc.) will lead to bugs and errors. Learn more about transactions .","title":"@Transaction, @TransactionManager and @TransactionRepository"},{"location":"decorator-reference/#entityrepository","text":"Marks a custom class as an entity repository. Example: @EntityRepository() export class UserRepository { /// ... custom repository methods ... } You can obtain any custom created repository using connection.getCustomRepository or entityManager.getCustomRepository methods. Learn more about custom entity repositories . Note: some decorators (like @Tree , @ChildEntity , etc.) aren't documented in this reference because they are treated as experimental at the moment. Expect to see their documentation in the future.","title":"@EntityRepository"},{"location":"delete-query-builder/","text":"Delete using Query Builder Delete using Query Builder Delete Soft-Delete Restore-Soft-Delete Delete You can create DELETE queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .delete() .from(User) .where(\"id = :id\", { id: 1 }) .execute(); This is the most efficient way in terms of performance to delete entities from your database. Soft-Delete Applying Soft Delete to QueryBuilder import {createConnection} from \"typeorm\"; import {Entity} from \"./entity\"; createConnection(/*...*/).then(async connection => { await connection .getRepository(Entity) .createQueryBuilder() .softDelete() }).catch(error => console.log(error)); Restore-Soft-Delete Alternatively, You can recover the soft deleted rows by using the restore() method: import {createConnection} from \"typeorm\"; import {Entity} from \"./entity\"; createConnection(/*...*/).then(async connection => { await connection .getRepository(Entity) .createQueryBuilder() .restore() }).catch(error => console.log(error));","title":"Delete using Query Builder"},{"location":"delete-query-builder/#delete-using-query-builder","text":"Delete using Query Builder Delete Soft-Delete Restore-Soft-Delete","title":"Delete using Query Builder"},{"location":"delete-query-builder/#delete","text":"You can create DELETE queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .delete() .from(User) .where(\"id = :id\", { id: 1 }) .execute(); This is the most efficient way in terms of performance to delete entities from your database.","title":"Delete"},{"location":"delete-query-builder/#soft-delete","text":"Applying Soft Delete to QueryBuilder import {createConnection} from \"typeorm\"; import {Entity} from \"./entity\"; createConnection(/*...*/).then(async connection => { await connection .getRepository(Entity) .createQueryBuilder() .softDelete() }).catch(error => console.log(error));","title":"Soft-Delete"},{"location":"delete-query-builder/#restore-soft-delete","text":"Alternatively, You can recover the soft deleted rows by using the restore() method: import {createConnection} from \"typeorm\"; import {Entity} from \"./entity\"; createConnection(/*...*/).then(async connection => { await connection .getRepository(Entity) .createQueryBuilder() .restore() }).catch(error => console.log(error));","title":"Restore-Soft-Delete"},{"location":"eager-and-lazy-relations/","text":"Eager and Lazy Relations Eager relations Eager relations are loaded automatically each time you load entities from the database. For example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions, { eager: true }) @JoinTable() categories: Category[]; } Now when you load questions you don't need to join or specify relations you want to load. They will be loaded automatically: const questionRepository = connection.getRepository(Question); // questions will be loaded with its categories const questions = await questionRepository.find(); Eager relations only work when you use find* methods. If you use QueryBuilder eager relations are disabled and have to use leftJoinAndSelect to load the relation. Eager relations can only be used on one side of the relationship, using eager: true on both sides of relationship is disallowed. Lazy relations Entities in lazy relations are loaded once you access them. Such relations must have Promise as type - you store your value in a promise, and when you load them a promise is returned as well. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Promise<Question[]>; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions) @JoinTable() categories: Promise<Category[]>; } categories is a Promise. It means it is lazy and it can store only a promise with a value inside. Example how to save such relation: const category1 = new Category(); category1.name = \"animals\"; await connection.manager.save(category1); const category2 = new Category(); category2.name = \"zoo\"; await connection.manager.save(category2); const question = new Question(); question.categories = Promise.resolve([category1, category2]); await connection.manager.save(question); Example how to load objects inside lazy relations: const question = await connection.getRepository(Question).findOne(1); const categories = await question.categories; // you'll have all question's categories inside \"categories\" variable now Note: if you came from other languages (Java, PHP, etc.) and are used to use lazy relations everywhere - be careful. Those languages aren't asynchronous and lazy loading is achieved different way, that's why you don't work with promises there. In JavaScript and Node.JS you have to use promises if you want to have lazy-loaded relations. This is non-standard technique and considered experimental in TypeORM.","title":"Eager and Lazy Relations"},{"location":"eager-and-lazy-relations/#eager-and-lazy-relations","text":"","title":"Eager and Lazy Relations"},{"location":"eager-and-lazy-relations/#eager-relations","text":"Eager relations are loaded automatically each time you load entities from the database. For example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions, { eager: true }) @JoinTable() categories: Category[]; } Now when you load questions you don't need to join or specify relations you want to load. They will be loaded automatically: const questionRepository = connection.getRepository(Question); // questions will be loaded with its categories const questions = await questionRepository.find(); Eager relations only work when you use find* methods. If you use QueryBuilder eager relations are disabled and have to use leftJoinAndSelect to load the relation. Eager relations can only be used on one side of the relationship, using eager: true on both sides of relationship is disallowed.","title":"Eager relations"},{"location":"eager-and-lazy-relations/#lazy-relations","text":"Entities in lazy relations are loaded once you access them. Such relations must have Promise as type - you store your value in a promise, and when you load them a promise is returned as well. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Promise<Question[]>; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions) @JoinTable() categories: Promise<Category[]>; } categories is a Promise. It means it is lazy and it can store only a promise with a value inside. Example how to save such relation: const category1 = new Category(); category1.name = \"animals\"; await connection.manager.save(category1); const category2 = new Category(); category2.name = \"zoo\"; await connection.manager.save(category2); const question = new Question(); question.categories = Promise.resolve([category1, category2]); await connection.manager.save(question); Example how to load objects inside lazy relations: const question = await connection.getRepository(Question).findOne(1); const categories = await question.categories; // you'll have all question's categories inside \"categories\" variable now Note: if you came from other languages (Java, PHP, etc.) and are used to use lazy relations everywhere - be careful. Those languages aren't asynchronous and lazy loading is achieved different way, that's why you don't work with promises there. In JavaScript and Node.JS you have to use promises if you want to have lazy-loaded relations. This is non-standard technique and considered experimental in TypeORM.","title":"Lazy relations"},{"location":"embedded-entities/","text":"Embedded Entities There is an amazing way to reduce duplication in your app (using composition over inheritance) by using embedded columns . Embedded column is a column which accepts a class with its own columns and merges those columns into the current entity's database table. Example: Let's say we have User , Employee and Student entities. All those entities have few things in common - first name and last name properties import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Employee { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() salary: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Student { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() faculty: string; } What we can do is to reduce firstName and lastName duplication by creating a new class with those columns: import {Column} from \"typeorm\"; export class Name { @Column() first: string; @Column() last: string; } Then you can \"connect\" those columns in your entities: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class User { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() isActive: boolean; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class Employee { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() salary: number; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class Student { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() faculty: string; } All columns defined in the Name entity will be merged into user , employee and student : +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | isActive | boolean | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | employee | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | salary | int(11) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | student | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | faculty | varchar(255) | | +-------------+--------------+----------------------------+ This way code duplication in the entity classes is reduced. You can use as many columns (or relations) in embedded classes as you need. You even can have nested embedded columns inside embedded classes.","title":"Embedded Entities"},{"location":"embedded-entities/#embedded-entities","text":"There is an amazing way to reduce duplication in your app (using composition over inheritance) by using embedded columns . Embedded column is a column which accepts a class with its own columns and merges those columns into the current entity's database table. Example: Let's say we have User , Employee and Student entities. All those entities have few things in common - first name and last name properties import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Employee { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() salary: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Student { @PrimaryGeneratedColumn() id: string; @Column() firstName: string; @Column() lastName: string; @Column() faculty: string; } What we can do is to reduce firstName and lastName duplication by creating a new class with those columns: import {Column} from \"typeorm\"; export class Name { @Column() first: string; @Column() last: string; } Then you can \"connect\" those columns in your entities: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class User { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() isActive: boolean; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class Employee { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() salary: number; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Name} from \"./Name\"; @Entity() export class Student { @PrimaryGeneratedColumn() id: string; @Column(() => Name) name: Name; @Column() faculty: string; } All columns defined in the Name entity will be merged into user , employee and student : +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | isActive | boolean | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | employee | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | salary | int(11) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | student | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | nameFirst | varchar(255) | | | nameLast | varchar(255) | | | faculty | varchar(255) | | +-------------+--------------+----------------------------+ This way code duplication in the entity classes is reduced. You can use as many columns (or relations) in embedded classes as you need. You even can have nested embedded columns inside embedded classes.","title":"Embedded Entities"},{"location":"entities/","text":"Entities What is Entity? Entity columns Primary columns Special columns Spatial columns Column types Column types for mysql / mariadb Column types for postgres / cockroachdb Column types for sqlite / cordova / react-native / expo Column types for mssql enum column type simple-array column type simple-json column type Columns with generated values Column options What is Entity? Entity is a class that maps to a database table (or collection when using MongoDB). You can create an entity by defining a new class and mark it with @Entity() : import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } This will create following database table: +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | firstName | varchar(255) | | | lastName | varchar(255) | | | isActive | boolean | | +-------------+--------------+----------------------------+ Basic entities consist of columns and relations. Each entity MUST have a primary column (or ObjectId column if are using MongoDB). Each entity must be registered in your connection options: import {createConnection, Connection} from \"typeorm\"; import {User} from \"./entity/User\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [User] }); Or you can specify the whole directory with all entities inside - and all of them will be loaded: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [\"entity/*.js\"] }); If you want to use an alternative table name for the User entity you can specify it in @Entity : @Entity(\"my_users\") . If you want to set a base prefix for all database tables in your application you can specify entityPrefix in connection options. When using an entity constructor its arguments must be optional . Since ORM creates instances of entity classes when loading from the database, therefore it is not aware of your constructor arguments. Learn more about parameters @Entity in Decorators reference . Entity columns Since database tables consist of columns your entities must consist of columns too. Each entity class property you marked with @Column will be mapped to a database table column. Primary columns Each entity must have at least one primary column. There are several types of primary columns: @PrimaryColumn() creates a primary column which takes any value of any type. You can specify the column type. If you don't specify a column type it will be inferred from the property type. The example below will create id with int as type which you must manually assign before save. import {Entity, PrimaryColumn} from \"typeorm\"; @Entity() export class User { @PrimaryColumn() id: number; } @PrimaryGeneratedColumn() creates a primary column which value will be automatically generated with an auto-increment value. It will create int column with auto-increment / serial / sequence (depend on the database). You don't have to manually assign its value before save - value will be automatically generated. import {Entity, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; } @PrimaryGeneratedColumn(\"uuid\") creates a primary column which value will be automatically generated with uuid . Uuid is a unique string id. You don't have to manually assign its value before save - value will be automatically generated. import {Entity, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn(\"uuid\") id: string; } You can have composite primary columns as well: import {Entity, PrimaryColumn} from \"typeorm\"; @Entity() export class User { @PrimaryColumn() firstName: string; @PrimaryColumn() lastName: string; } When you save entities using save it always tries to find an entity in the database with the given entity id (or ids). If id/ids are found then it will update this row in the database. If there is no row with the id/ids, a new row will be inserted. To find an entity by id you can use manager.findOne or repository.findOne . Example: // find one by id with single primary key const person = await connection.manager.findOne(Person, 1); const person = await connection.getRepository(Person).findOne(1); // find one by id with composite primary keys const user = await connection.manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); const user = await connection.getRepository(User).findOne({ firstName: \"Timber\", lastName: \"Saw\" }); Special columns There are several special column types with additional functionality available: @CreateDateColumn is a special column that is automatically set to the entity's insertion date. You don't need to set this column - it will be automatically set. @UpdateDateColumn is a special column that is automatically set to the entity's update time each time you call save of entity manager or repository. You don't need to set this column - it will be automatically set. @DeleteDateColumn is a special column that is automatically set to the entity's delete time each time you call soft-delete of entity manager or repository. You don't need to set this column - it will be automatically set. If the @DeleteDateColumn is set, the default scope will be \"non-deleted\". @VersionColumn is a special column that is automatically set to the version of the entity (incremental number) each time you call save of entity manager or repository. You don't need to set this column - it will be automatically set. Spatial columns MS SQL, MySQL / MariaDB, and PostgreSQL all support spatial columns. TypeORM's support for each varies slightly between databases, particularly as the column names vary between databases. MS SQL and MySQL / MariaDB's TypeORM support exposes (and expects) geometries to be provided as well-known text (WKT) , so geometry columns should be tagged with the string type. TypeORM's PostgreSQL support uses GeoJSON as an interchange format, so geometry columns should be tagged either as object or Geometry (or subclasses, e.g. Point ) after importing geojson types . TypeORM tries to do the right thing, but it's not always possible to determine when a value being inserted or the result of a PostGIS function should be treated as a geometry. As a result, you may find yourself writing code similar to the following, where values are converted into PostGIS geometry s from GeoJSON and into GeoJSON as json : const origin = { type: \"Point\", coordinates: [0, 0] }; await getManager() .createQueryBuilder(Thing, \"thing\") // convert stringified GeoJSON into a geometry with an SRID that matches the // table specification .where(\"ST_Distance(geom, ST_SetSRID(ST_GeomFromGeoJSON(:origin), ST_SRID(geom))) > 0\") .orderBy({ \"ST_Distance(geom, ST_SetSRID(ST_GeomFromGeoJSON(:origin), ST_SRID(geom)))\": { order: \"ASC\" } }) .setParameters({ // stringify GeoJSON origin: JSON.stringify(origin) }) .getMany(); await getManager() .createQueryBuilder(Thing, \"thing\") // convert geometry result into GeoJSON, treated as JSON (so that TypeORM // will know to deserialize it) .select(\"ST_AsGeoJSON(ST_Buffer(geom, 0.1))::json geom\") .from(\"thing\") .getMany(); Column types TypeORM supports all of the most commonly used database-supported column types. Column types are database-type specific - this provides more flexibility on how your database schema will look like. You can specify column type as first parameter of @Column or in the column options of @Column , for example: @Column(\"int\") or @Column({ type: \"int\" }) If you want to specify additional type parameters you can do it via column options. For example: @Column(\"varchar\", { length: 200 }) or @Column({ type: \"int\", width: 200 }) Note about bigint type: bigint column type, used in SQL databases, doesn't fit into the regular number type and maps property to a string instead. Column types for mysql / mariadb bit , int , integer , tinyint , smallint , mediumint , bigint , float , double , double precision , dec , decimal , numeric , fixed , bool , boolean , date , datetime , timestamp , time , year , char , nchar , national char , varchar , nvarchar , national varchar , text , tinytext , mediumtext , blob , longtext , tinyblob , mediumblob , longblob , enum , set , json , binary , varbinary , geometry , point , linestring , polygon , multipoint , multilinestring , multipolygon , geometrycollection Column types for postgres int , int2 , int4 , int8 , smallint , integer , bigint , decimal , numeric , real , float , float4 , float8 , double precision , money , character varying , varchar , character , char , text , citext , hstore , bytea , bit , varbit , bit varying , timetz , timestamptz , timestamp , timestamp without time zone , timestamp with time zone , date , time , time without time zone , time with time zone , interval , bool , boolean , enum , point , line , lseg , box , path , polygon , circle , cidr , inet , macaddr , tsvector , tsquery , uuid , xml , json , jsonb , int4range , int8range , numrange , tsrange , tstzrange , daterange , geometry , geography , cube , ltree Column types for cockroachdb array , bool , boolean , bytes , bytea , blob , date , numeric , decimal , dec , float , float4 , float8 , double precision , real , inet , int , integer , int2 , int8 , int64 , smallint , bigint , interval , string , character varying , character , char , char varying , varchar , text , time , time without time zone , timestamp , timestamptz , timestamp without time zone , timestamp with time zone , json , jsonb , uuid Note: CockroachDB returns all numeric data types as string . However if you omit column type and define your property as number ORM will parseInt string into number. Column types for sqlite / cordova / react-native / expo int , int2 , int8 , integer , tinyint , smallint , mediumint , bigint , decimal , numeric , float , double , real , double precision , datetime , varying character , character , native character , varchar , nchar , nvarchar2 , unsigned big int , boolean , blob , text , clob , date Column types for mssql int , bigint , bit , decimal , money , numeric , smallint , smallmoney , tinyint , float , real , date , datetime2 , datetime , datetimeoffset , smalldatetime , time , char , varchar , text , nchar , nvarchar , ntext , binary , image , varbinary , hierarchyid , sql_variant , timestamp , uniqueidentifier , xml , geometry , geography , rowversion Column types for oracle char , nchar , nvarchar2 , varchar2 , long , raw , long raw , number , numeric , float , dec , decimal , integer , int , smallint , real , double precision , date , timestamp , timestamp with time zone , timestamp with local time zone , interval year to month , interval day to second , bfile , blob , clob , nclob , rowid , urowid enum column type enum column type is supported by postgres and mysql . There are various possible column definitions: Using typescript enums: export enum UserRole { ADMIN = \"admin\", EDITOR = \"editor\", GHOST = \"ghost\" } @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"enum\", enum: UserRole, default: UserRole.GHOST }) role: UserRole } Note: String, numeric and heterogeneous enums are supported. Using array with enum values: export type UserRoleType = \"admin\" | \"editor\" | \"ghost\", @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"enum\", enum: [\"admin\", \"editor\", \"ghost\"], default: \"ghost\" }) role: UserRoleType } set column type set column type is supported by mariadb and mysql . There are various possible column definitions: Using typescript enums: export enum UserRole { ADMIN = \"admin\", EDITOR = \"editor\", GHOST = \"ghost\" } @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"set\", enum: UserRole, default: [UserRole.GHOST, UserRole.EDITOR] }) roles: UserRole[] } Using array with set values: export type UserRoleType = \"admin\" | \"editor\" | \"ghost\", @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"set\", enum: [\"admin\", \"editor\", \"ghost\"], default: [\"ghost\", \"editor\"] }) roles: UserRoleType[] } simple-array column type There is a special column type called simple-array which can store primitive array values in a single string column. All values are separated by a comma. For example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column(\"simple-array\") names: string[]; } const user = new User(); user.names = [ \"Alexander\", \"Alex\", \"Sasha\", \"Shurik\" ]; Will be stored in a single database column as Alexander,Alex,Sasha,Shurik value. When you'll load data from the database, the names will be returned as an array of names, just like you stored them. Note you MUST NOT have any comma in values you write. simple-json column type There is a special column type called simple-json which can store any values which can be stored in database via JSON.stringify. Very useful when you do not have json type in your database and you want to store and load object without any hassle. For example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column(\"simple-json\") profile: { name: string, nickname: string }; } const user = new User(); user.profile = { name: \"John\", nickname: \"Malkovich\" }; Will be stored in a single database column as {\"name\":\"John\",\"nickname\":\"Malkovich\"} value. When you'll load data from the database, you will have your object/array/primitive back via JSON.parse Columns with generated values You can create column with generated value using @Generated decorator. For example: @Entity() export class User { @PrimaryColumn() id: number; @Column() @Generated(\"uuid\") uuid: string; } uuid value will be automatically generated and stored into the database. Besides \"uuid\" there is also \"increment\" and \"rowid\" (CockroachDB only) generated types, however there are some limitations on some database platforms with this type of generation (for example some databases can only have one increment column, or some of them require increment to be a primary key). Column options Column options defines additional options for your entity columns. You can specify column options on @Column : @Column({ type: \"varchar\", length: 150, unique: true, // ... }) name: string; List of available options in ColumnOptions : type: ColumnType - Column type. One of the type listed above . name: string - Column name in the database table. By default the column name is generated from the name of the property. You can change it by specifying your own name. length: number - Column type's length. For example if you want to create varchar(150) type you specify column type and length options. width: number - column type's display width. Used only for MySQL integer types onUpdate: string - ON UPDATE trigger. Used only in MySQL . nullable: boolean - Makes column NULL or NOT NULL in the database. By default column is nullable: false . update: boolean - Indicates if column value is updated by \"save\" operation. If false, you'll be able to write this value only when you first time insert the object. Default value is true . insert: boolean - Indicates if column value is set the first time you insert the object. Default value is true . select: boolean - Defines whether or not to hide this column by default when making queries. When set to false , the column data will not show with a standard query. By default column is select: true default: string - Adds database-level column's DEFAULT value. primary: boolean - Marks column as primary. Same if you use @PrimaryColumn . unique: boolean - Marks column as unique column (creates unique constraint). comment: string - Database's column comment. Not supported by all database types. precision: number - The precision for a decimal (exact numeric) column (applies only for decimal column), which is the maximum number of digits that are stored for the values. Used in some column types. scale: number - The scale for a decimal (exact numeric) column (applies only for decimal column), which represents the number of digits to the right of the decimal point and must not be greater than precision. Used in some column types. zerofill: boolean - Puts ZEROFILL attribute on to a numeric column. Used only in MySQL. If true , MySQL automatically adds the UNSIGNED attribute to this column. unsigned: boolean - Puts UNSIGNED attribute on to a numeric column. Used only in MySQL. charset: string - Defines a column character set. Not supported by all database types. collation: string - Defines a column collation. enum: string[]|AnyEnum - Used in enum column type to specify list of allowed enum values. You can specify array of values or specify a enum class. enumName: string - Defines the name for the used enum. asExpression: string - Generated column expression. Used only in MySQL . generatedType: \"VIRTUAL\"|\"STORED\" - Generated column type. Used only in MySQL . hstoreType: \"object\"|\"string\" - Return type of HSTORE column. Returns value as string or as object. Used only in Postgres . array: boolean - Used for postgres and cockroachdb column types which can be array (for example int[]) transformer: { from(value: DatabaseType): EntityType, to(value: EntityType): DatabaseType } - Used to marshal properties of arbitrary type EntityType into a type DatabaseType supported by the database. Array of transformers are also supported and will be applied in natural order when writing, and in reverse order when reading. e.g. [lowercase, encrypt] will first lowercase the string then encrypt it when writing, and will decrypt then do nothing when reading. Note: most of those column options are RDBMS-specific and aren't available in MongoDB . Entity inheritance You can reduce duplication in your code by using entity inheritance. For example, you have Photo , Question , Post entities: @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() size: string; } @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() answersCount: number; } @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() viewCount: number; } As you can see all those entities have common columns: id , title , description . To reduce duplication and produce a better abstraction we can create a base class called Content for them: export abstract class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @Entity() export class Photo extends Content { @Column() size: string; } @Entity() export class Question extends Content { @Column() answersCount: number; } @Entity() export class Post extends Content { @Column() viewCount: number; } All columns (relations, embeds, etc.) from parent entities (parent can extend other entity as well) will be inherited and created in final entities. Tree entities TypeORM supports the Adjacency list and Closure table patterns of storing tree structures. Adjacency list Adjacency list is a simple model with self-referencing. Benefit of this approach is simplicity, drawback is you can't load a big tree at once because of join limitations. Example: import {Entity, Column, PrimaryGeneratedColumn, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @ManyToOne(type => Category, category => category.children) parent: Category; @OneToMany(type => Category, category => category.parent) children: Category[]; } Closure table A closure table stores relations between parent and child in a separate table in a special way. Its efficient in both reads and writes. To learn more about closure table take a look at this awesome presentation by Bill Karwin . Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"closure-table\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; @TreeLevelColumn() level: number; }","title":"Entities"},{"location":"entities/#entities","text":"What is Entity? Entity columns Primary columns Special columns Spatial columns Column types Column types for mysql / mariadb Column types for postgres / cockroachdb Column types for sqlite / cordova / react-native / expo Column types for mssql enum column type simple-array column type simple-json column type Columns with generated values Column options","title":"Entities"},{"location":"entities/#what-is-entity","text":"Entity is a class that maps to a database table (or collection when using MongoDB). You can create an entity by defining a new class and mark it with @Entity() : import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; @Column() isActive: boolean; } This will create following database table: +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | firstName | varchar(255) | | | lastName | varchar(255) | | | isActive | boolean | | +-------------+--------------+----------------------------+ Basic entities consist of columns and relations. Each entity MUST have a primary column (or ObjectId column if are using MongoDB). Each entity must be registered in your connection options: import {createConnection, Connection} from \"typeorm\"; import {User} from \"./entity/User\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [User] }); Or you can specify the whole directory with all entities inside - and all of them will be loaded: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [\"entity/*.js\"] }); If you want to use an alternative table name for the User entity you can specify it in @Entity : @Entity(\"my_users\") . If you want to set a base prefix for all database tables in your application you can specify entityPrefix in connection options. When using an entity constructor its arguments must be optional . Since ORM creates instances of entity classes when loading from the database, therefore it is not aware of your constructor arguments. Learn more about parameters @Entity in Decorators reference .","title":"What is Entity?"},{"location":"entities/#entity-columns","text":"Since database tables consist of columns your entities must consist of columns too. Each entity class property you marked with @Column will be mapped to a database table column.","title":"Entity columns"},{"location":"entities/#primary-columns","text":"Each entity must have at least one primary column. There are several types of primary columns: @PrimaryColumn() creates a primary column which takes any value of any type. You can specify the column type. If you don't specify a column type it will be inferred from the property type. The example below will create id with int as type which you must manually assign before save. import {Entity, PrimaryColumn} from \"typeorm\"; @Entity() export class User { @PrimaryColumn() id: number; } @PrimaryGeneratedColumn() creates a primary column which value will be automatically generated with an auto-increment value. It will create int column with auto-increment / serial / sequence (depend on the database). You don't have to manually assign its value before save - value will be automatically generated. import {Entity, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; } @PrimaryGeneratedColumn(\"uuid\") creates a primary column which value will be automatically generated with uuid . Uuid is a unique string id. You don't have to manually assign its value before save - value will be automatically generated. import {Entity, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn(\"uuid\") id: string; } You can have composite primary columns as well: import {Entity, PrimaryColumn} from \"typeorm\"; @Entity() export class User { @PrimaryColumn() firstName: string; @PrimaryColumn() lastName: string; } When you save entities using save it always tries to find an entity in the database with the given entity id (or ids). If id/ids are found then it will update this row in the database. If there is no row with the id/ids, a new row will be inserted. To find an entity by id you can use manager.findOne or repository.findOne . Example: // find one by id with single primary key const person = await connection.manager.findOne(Person, 1); const person = await connection.getRepository(Person).findOne(1); // find one by id with composite primary keys const user = await connection.manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); const user = await connection.getRepository(User).findOne({ firstName: \"Timber\", lastName: \"Saw\" });","title":"Primary columns"},{"location":"entities/#special-columns","text":"There are several special column types with additional functionality available: @CreateDateColumn is a special column that is automatically set to the entity's insertion date. You don't need to set this column - it will be automatically set. @UpdateDateColumn is a special column that is automatically set to the entity's update time each time you call save of entity manager or repository. You don't need to set this column - it will be automatically set. @DeleteDateColumn is a special column that is automatically set to the entity's delete time each time you call soft-delete of entity manager or repository. You don't need to set this column - it will be automatically set. If the @DeleteDateColumn is set, the default scope will be \"non-deleted\". @VersionColumn is a special column that is automatically set to the version of the entity (incremental number) each time you call save of entity manager or repository. You don't need to set this column - it will be automatically set.","title":"Special columns"},{"location":"entities/#spatial-columns","text":"MS SQL, MySQL / MariaDB, and PostgreSQL all support spatial columns. TypeORM's support for each varies slightly between databases, particularly as the column names vary between databases. MS SQL and MySQL / MariaDB's TypeORM support exposes (and expects) geometries to be provided as well-known text (WKT) , so geometry columns should be tagged with the string type. TypeORM's PostgreSQL support uses GeoJSON as an interchange format, so geometry columns should be tagged either as object or Geometry (or subclasses, e.g. Point ) after importing geojson types . TypeORM tries to do the right thing, but it's not always possible to determine when a value being inserted or the result of a PostGIS function should be treated as a geometry. As a result, you may find yourself writing code similar to the following, where values are converted into PostGIS geometry s from GeoJSON and into GeoJSON as json : const origin = { type: \"Point\", coordinates: [0, 0] }; await getManager() .createQueryBuilder(Thing, \"thing\") // convert stringified GeoJSON into a geometry with an SRID that matches the // table specification .where(\"ST_Distance(geom, ST_SetSRID(ST_GeomFromGeoJSON(:origin), ST_SRID(geom))) > 0\") .orderBy({ \"ST_Distance(geom, ST_SetSRID(ST_GeomFromGeoJSON(:origin), ST_SRID(geom)))\": { order: \"ASC\" } }) .setParameters({ // stringify GeoJSON origin: JSON.stringify(origin) }) .getMany(); await getManager() .createQueryBuilder(Thing, \"thing\") // convert geometry result into GeoJSON, treated as JSON (so that TypeORM // will know to deserialize it) .select(\"ST_AsGeoJSON(ST_Buffer(geom, 0.1))::json geom\") .from(\"thing\") .getMany();","title":"Spatial columns"},{"location":"entities/#column-types","text":"TypeORM supports all of the most commonly used database-supported column types. Column types are database-type specific - this provides more flexibility on how your database schema will look like. You can specify column type as first parameter of @Column or in the column options of @Column , for example: @Column(\"int\") or @Column({ type: \"int\" }) If you want to specify additional type parameters you can do it via column options. For example: @Column(\"varchar\", { length: 200 }) or @Column({ type: \"int\", width: 200 }) Note about bigint type: bigint column type, used in SQL databases, doesn't fit into the regular number type and maps property to a string instead.","title":"Column types"},{"location":"entities/#column-types-for-mysql-mariadb","text":"bit , int , integer , tinyint , smallint , mediumint , bigint , float , double , double precision , dec , decimal , numeric , fixed , bool , boolean , date , datetime , timestamp , time , year , char , nchar , national char , varchar , nvarchar , national varchar , text , tinytext , mediumtext , blob , longtext , tinyblob , mediumblob , longblob , enum , set , json , binary , varbinary , geometry , point , linestring , polygon , multipoint , multilinestring , multipolygon , geometrycollection","title":"Column types for mysql / mariadb"},{"location":"entities/#column-types-for-postgres","text":"int , int2 , int4 , int8 , smallint , integer , bigint , decimal , numeric , real , float , float4 , float8 , double precision , money , character varying , varchar , character , char , text , citext , hstore , bytea , bit , varbit , bit varying , timetz , timestamptz , timestamp , timestamp without time zone , timestamp with time zone , date , time , time without time zone , time with time zone , interval , bool , boolean , enum , point , line , lseg , box , path , polygon , circle , cidr , inet , macaddr , tsvector , tsquery , uuid , xml , json , jsonb , int4range , int8range , numrange , tsrange , tstzrange , daterange , geometry , geography , cube , ltree","title":"Column types for postgres"},{"location":"entities/#column-types-for-cockroachdb","text":"array , bool , boolean , bytes , bytea , blob , date , numeric , decimal , dec , float , float4 , float8 , double precision , real , inet , int , integer , int2 , int8 , int64 , smallint , bigint , interval , string , character varying , character , char , char varying , varchar , text , time , time without time zone , timestamp , timestamptz , timestamp without time zone , timestamp with time zone , json , jsonb , uuid Note: CockroachDB returns all numeric data types as string . However if you omit column type and define your property as number ORM will parseInt string into number.","title":"Column types for cockroachdb"},{"location":"entities/#column-types-for-sqlite-cordova-react-native-expo","text":"int , int2 , int8 , integer , tinyint , smallint , mediumint , bigint , decimal , numeric , float , double , real , double precision , datetime , varying character , character , native character , varchar , nchar , nvarchar2 , unsigned big int , boolean , blob , text , clob , date","title":"Column types for sqlite / cordova / react-native / expo"},{"location":"entities/#column-types-for-mssql","text":"int , bigint , bit , decimal , money , numeric , smallint , smallmoney , tinyint , float , real , date , datetime2 , datetime , datetimeoffset , smalldatetime , time , char , varchar , text , nchar , nvarchar , ntext , binary , image , varbinary , hierarchyid , sql_variant , timestamp , uniqueidentifier , xml , geometry , geography , rowversion","title":"Column types for mssql"},{"location":"entities/#column-types-for-oracle","text":"char , nchar , nvarchar2 , varchar2 , long , raw , long raw , number , numeric , float , dec , decimal , integer , int , smallint , real , double precision , date , timestamp , timestamp with time zone , timestamp with local time zone , interval year to month , interval day to second , bfile , blob , clob , nclob , rowid , urowid","title":"Column types for oracle"},{"location":"entities/#enum-column-type","text":"enum column type is supported by postgres and mysql . There are various possible column definitions: Using typescript enums: export enum UserRole { ADMIN = \"admin\", EDITOR = \"editor\", GHOST = \"ghost\" } @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"enum\", enum: UserRole, default: UserRole.GHOST }) role: UserRole } Note: String, numeric and heterogeneous enums are supported. Using array with enum values: export type UserRoleType = \"admin\" | \"editor\" | \"ghost\", @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"enum\", enum: [\"admin\", \"editor\", \"ghost\"], default: \"ghost\" }) role: UserRoleType }","title":"enum column type"},{"location":"entities/#set-column-type","text":"set column type is supported by mariadb and mysql . There are various possible column definitions: Using typescript enums: export enum UserRole { ADMIN = \"admin\", EDITOR = \"editor\", GHOST = \"ghost\" } @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"set\", enum: UserRole, default: [UserRole.GHOST, UserRole.EDITOR] }) roles: UserRole[] } Using array with set values: export type UserRoleType = \"admin\" | \"editor\" | \"ghost\", @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column({ type: \"set\", enum: [\"admin\", \"editor\", \"ghost\"], default: [\"ghost\", \"editor\"] }) roles: UserRoleType[] }","title":"set column type"},{"location":"entities/#simple-array-column-type","text":"There is a special column type called simple-array which can store primitive array values in a single string column. All values are separated by a comma. For example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column(\"simple-array\") names: string[]; } const user = new User(); user.names = [ \"Alexander\", \"Alex\", \"Sasha\", \"Shurik\" ]; Will be stored in a single database column as Alexander,Alex,Sasha,Shurik value. When you'll load data from the database, the names will be returned as an array of names, just like you stored them. Note you MUST NOT have any comma in values you write.","title":"simple-array column type"},{"location":"entities/#simple-json-column-type","text":"There is a special column type called simple-json which can store any values which can be stored in database via JSON.stringify. Very useful when you do not have json type in your database and you want to store and load object without any hassle. For example: @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column(\"simple-json\") profile: { name: string, nickname: string }; } const user = new User(); user.profile = { name: \"John\", nickname: \"Malkovich\" }; Will be stored in a single database column as {\"name\":\"John\",\"nickname\":\"Malkovich\"} value. When you'll load data from the database, you will have your object/array/primitive back via JSON.parse","title":"simple-json column type"},{"location":"entities/#columns-with-generated-values","text":"You can create column with generated value using @Generated decorator. For example: @Entity() export class User { @PrimaryColumn() id: number; @Column() @Generated(\"uuid\") uuid: string; } uuid value will be automatically generated and stored into the database. Besides \"uuid\" there is also \"increment\" and \"rowid\" (CockroachDB only) generated types, however there are some limitations on some database platforms with this type of generation (for example some databases can only have one increment column, or some of them require increment to be a primary key).","title":"Columns with generated values"},{"location":"entities/#column-options","text":"Column options defines additional options for your entity columns. You can specify column options on @Column : @Column({ type: \"varchar\", length: 150, unique: true, // ... }) name: string; List of available options in ColumnOptions : type: ColumnType - Column type. One of the type listed above . name: string - Column name in the database table. By default the column name is generated from the name of the property. You can change it by specifying your own name. length: number - Column type's length. For example if you want to create varchar(150) type you specify column type and length options. width: number - column type's display width. Used only for MySQL integer types onUpdate: string - ON UPDATE trigger. Used only in MySQL . nullable: boolean - Makes column NULL or NOT NULL in the database. By default column is nullable: false . update: boolean - Indicates if column value is updated by \"save\" operation. If false, you'll be able to write this value only when you first time insert the object. Default value is true . insert: boolean - Indicates if column value is set the first time you insert the object. Default value is true . select: boolean - Defines whether or not to hide this column by default when making queries. When set to false , the column data will not show with a standard query. By default column is select: true default: string - Adds database-level column's DEFAULT value. primary: boolean - Marks column as primary. Same if you use @PrimaryColumn . unique: boolean - Marks column as unique column (creates unique constraint). comment: string - Database's column comment. Not supported by all database types. precision: number - The precision for a decimal (exact numeric) column (applies only for decimal column), which is the maximum number of digits that are stored for the values. Used in some column types. scale: number - The scale for a decimal (exact numeric) column (applies only for decimal column), which represents the number of digits to the right of the decimal point and must not be greater than precision. Used in some column types. zerofill: boolean - Puts ZEROFILL attribute on to a numeric column. Used only in MySQL. If true , MySQL automatically adds the UNSIGNED attribute to this column. unsigned: boolean - Puts UNSIGNED attribute on to a numeric column. Used only in MySQL. charset: string - Defines a column character set. Not supported by all database types. collation: string - Defines a column collation. enum: string[]|AnyEnum - Used in enum column type to specify list of allowed enum values. You can specify array of values or specify a enum class. enumName: string - Defines the name for the used enum. asExpression: string - Generated column expression. Used only in MySQL . generatedType: \"VIRTUAL\"|\"STORED\" - Generated column type. Used only in MySQL . hstoreType: \"object\"|\"string\" - Return type of HSTORE column. Returns value as string or as object. Used only in Postgres . array: boolean - Used for postgres and cockroachdb column types which can be array (for example int[]) transformer: { from(value: DatabaseType): EntityType, to(value: EntityType): DatabaseType } - Used to marshal properties of arbitrary type EntityType into a type DatabaseType supported by the database. Array of transformers are also supported and will be applied in natural order when writing, and in reverse order when reading. e.g. [lowercase, encrypt] will first lowercase the string then encrypt it when writing, and will decrypt then do nothing when reading. Note: most of those column options are RDBMS-specific and aren't available in MongoDB .","title":"Column options"},{"location":"entities/#entity-inheritance","text":"You can reduce duplication in your code by using entity inheritance. For example, you have Photo , Question , Post entities: @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() size: string; } @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() answersCount: number; } @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() viewCount: number; } As you can see all those entities have common columns: id , title , description . To reduce duplication and produce a better abstraction we can create a base class called Content for them: export abstract class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @Entity() export class Photo extends Content { @Column() size: string; } @Entity() export class Question extends Content { @Column() answersCount: number; } @Entity() export class Post extends Content { @Column() viewCount: number; } All columns (relations, embeds, etc.) from parent entities (parent can extend other entity as well) will be inherited and created in final entities.","title":"Entity inheritance"},{"location":"entities/#tree-entities","text":"TypeORM supports the Adjacency list and Closure table patterns of storing tree structures.","title":"Tree entities"},{"location":"entities/#adjacency-list","text":"Adjacency list is a simple model with self-referencing. Benefit of this approach is simplicity, drawback is you can't load a big tree at once because of join limitations. Example: import {Entity, Column, PrimaryGeneratedColumn, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @ManyToOne(type => Category, category => category.children) parent: Category; @OneToMany(type => Category, category => category.parent) children: Category[]; }","title":"Adjacency list"},{"location":"entities/#closure-table","text":"A closure table stores relations between parent and child in a separate table in a special way. Its efficient in both reads and writes. To learn more about closure table take a look at this awesome presentation by Bill Karwin . Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"closure-table\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; @TreeLevelColumn() level: number; }","title":"Closure table"},{"location":"entity-inheritance/","text":"Entity Inheritance Concrete Table Inheritance Single Table Inheritance Using embeddeds Concrete Table Inheritance You can reduce duplication in your code by using entity inheritance patterns. The simplest and the most effective is concrete table inheritance. For example, you have Photo , Question , Post entities: @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() size: string; } @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() answersCount: number; } @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() viewCount: number; } As you can see all those entities have common columns: id , title , description . To reduce duplication and produce a better abstraction we can create a base class called Content for them: export abstract class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @Entity() export class Photo extends Content { @Column() size: string; } @Entity() export class Question extends Content { @Column() answersCount: number; } @Entity() export class Post extends Content { @Column() viewCount: number; } All columns (relations, embeds, etc.) from parent entities (parent can extend other entity as well) will be inherited and created in final entities. This example will create 3 tables - photo , question and post . Single Table Inheritance TypeORM also supports single table inheritance. Single table inheritance is a pattern when you have multiple classes with their own properties, but in the database they are stored in the same table. @Entity() @TableInheritance({ column: { type: \"varchar\", name: \"type\" } }) export class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @ChildEntity() export class Photo extends Content { @Column() size: string; } @ChildEntity() export class Question extends Content { @Column() answersCount: number; } @ChildEntity() export class Post extends Content { @Column() viewCount: number; } This will create a single table called content and all instances of photos, questions and posts will be saved into this table. Using embeddeds There is an amazing way to reduce duplication in your app (using composition over inheritance) by using embedded columns . Read more about embedded entities here .","title":"Entity Inheritance"},{"location":"entity-inheritance/#entity-inheritance","text":"Concrete Table Inheritance Single Table Inheritance Using embeddeds","title":"Entity Inheritance"},{"location":"entity-inheritance/#concrete-table-inheritance","text":"You can reduce duplication in your code by using entity inheritance patterns. The simplest and the most effective is concrete table inheritance. For example, you have Photo , Question , Post entities: @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() size: string; } @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() answersCount: number; } @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; @Column() viewCount: number; } As you can see all those entities have common columns: id , title , description . To reduce duplication and produce a better abstraction we can create a base class called Content for them: export abstract class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @Entity() export class Photo extends Content { @Column() size: string; } @Entity() export class Question extends Content { @Column() answersCount: number; } @Entity() export class Post extends Content { @Column() viewCount: number; } All columns (relations, embeds, etc.) from parent entities (parent can extend other entity as well) will be inherited and created in final entities. This example will create 3 tables - photo , question and post .","title":"Concrete Table Inheritance"},{"location":"entity-inheritance/#single-table-inheritance","text":"TypeORM also supports single table inheritance. Single table inheritance is a pattern when you have multiple classes with their own properties, but in the database they are stored in the same table. @Entity() @TableInheritance({ column: { type: \"varchar\", name: \"type\" } }) export class Content { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } @ChildEntity() export class Photo extends Content { @Column() size: string; } @ChildEntity() export class Question extends Content { @Column() answersCount: number; } @ChildEntity() export class Post extends Content { @Column() viewCount: number; } This will create a single table called content and all instances of photos, questions and posts will be saved into this table.","title":"Single Table Inheritance"},{"location":"entity-inheritance/#using-embeddeds","text":"There is an amazing way to reduce duplication in your app (using composition over inheritance) by using embedded columns . Read more about embedded entities here .","title":"Using embeddeds"},{"location":"entity-manager-api/","text":"EntityManager API connection - The connection used by EntityManager . const connection = manager.connection; queryRunner - The query runner used by EntityManager . Used only in transactional instances of EntityManager. const queryRunner = manager.queryRunner; transaction - Provides a transaction where multiple database requests will be executed in a single database transaction. Learn more Transactions . await manager.transaction(async manager => { // NOTE: you must perform all database operations using the given manager instance // it's a special instance of EntityManager working with this transaction // and don't forget to await things here }); query - Executes a raw SQL query. const rawData = await manager.query(`SELECT * FROM USERS`); createQueryBuilder - Creates a query builder use to build SQL queries. Learn more about QueryBuilder . const users = await manager.createQueryBuilder() .select() .from(User, \"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); hasId - Checks if given entity has its primary column property defined. if (manager.hasId(user)) { // ... do something } getId - Gets given entity's primary column property value. If the entity has composite primary keys then the returned value will be an object with names and values of primary columns. const userId = manager.getId(user); // userId === 1 create - Creates a new instance of User . Optionally accepts an object literal with user properties which will be written into newly created user object. const user = manager.create(User); // same as const user = new User(); const user = manager.create(User, { id: 1, firstName: \"Timber\", lastName: \"Saw\" }); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; merge - Merges multiple entities into a single entity. const user = new User(); manager.merge(User, user, { firstName: \"Timber\" }, { lastName: \"Saw\" }); // same as user.firstName = \"Timber\"; user.lastName = \"Saw\"; preload - Creates a new entity from the given plain javascript object. If the entity already exist in the database, then it loads it (and everything related to it), replaces all values with the new ones from the given object, and returns the new entity. The new entity is actually loaded from the database entity with all properties replaced from the new object. const partialUser = { id: 1, firstName: \"Rizzrak\", profile: { id: 1 } }; const user = await manager.preload(User, partialUser); // user will contain all missing data from partialUser with partialUser property values: // { id: 1, firstName: \"Rizzrak\", lastName: \"Saw\", profile: { id: 1, ... } } save - Saves a given entity or array of entities. If the entity already exists in the database, then it's updated. If the entity does not exist in the database yet, it's inserted. It saves all given entities in a single transaction (in the case of entity manager is not transactional). Also supports partial updating since all undefined properties are skipped. In order to make a value NULL , you must manually set the property to equal null . await manager.save(user); await manager.save([ category1, category2, category3 ]); remove - Removes a given entity or array of entities. It removes all given entities in a single transaction (in the case of entity, manager is not transactional). await manager.remove(user); await manager.remove([ category1, category2, category3 ]); insert - Inserts a new entity, or array of entities. await manager.insert(User, { firstName: \"Timber\", lastName: \"Timber\" }); await manager.insert(User, [{ firstName: \"Foo\", lastName: \"Bar\" }, { firstName: \"Rizz\", lastName: \"Rak\" }]); update - Partially updates entity by a given update options or entity id. await manager.update(User, { firstName: \"Timber\" }, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE firstName = Timber await manager.update(User, 1, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE id = 1 delete - Deletes entities by entity id, ids or given conditions: await manager.delete(User, 1); await manager.delete(User, [1, 2, 3]); await manager.delete(User, { firstName: \"Timber\" }); count - Counts entities that match given options. Useful for pagination. const count = await manager.count(User, { firstName: \"Timber\" }); increment - Increments some column by provided value of entities that match given options. await manager.increment(User, { firstName: \"Timber\" }, \"age\", 3); decrement - Decrements some column by provided value that match given options. await manager.decrement(User, { firstName: \"Timber\" }, \"age\", 3); find - Finds entities that match given options. const timbers = await manager.find(User, { firstName: \"Timber\" }); findAndCount - Finds entities that match given find options. Also counts all entities that match given conditions, but ignores pagination settings (from and take options). const [timbers, timbersCount] = await manager.findAndCount(User, { firstName: \"Timber\" }); findByIds - Finds multiple entities by id. const users = await manager.findByIds(User, [1, 2, 3]); findOne - Finds the first entity that matches some id or find options. const user = await manager.findOne(User, 1); const timber = await manager.findOne(User, { firstName: \"Timber\" }); findOneOrFail - Finds the first entity that matches some id or find options. Rejects the returned promise if nothing matches. const user = await manager.findOneOrFail(User, 1); const timber = await manager.findOneOrFail(User, { firstName: \"Timber\" }); clear - Clears all the data from the given table (truncates/drops it). await manager.clear(User); getRepository - Gets Repository to perform operations on a specific entity. Learn more about Repositories . const userRepository = manager.getRepository(User); getTreeRepository - Gets TreeRepository to perform operations on a specific entity. Learn more about Repositories . const categoryRepository = manager.getTreeRepository(Category); getMongoRepository - Gets MongoRepository to perform operations on a specific entity. Learn more about MongoDB . const userRepository = manager.getMongoRepository(User); getCustomRepository - Gets custom entity repository. Learn more about Custom repositories . const myUserRepository = manager.getCustomRepository(UserRepository); release - Releases query runner of an entity manager. Used only when query runner was created and managed manually. await manager.release();","title":"`EntityManager` API"},{"location":"entity-manager-api/#entitymanager-api","text":"connection - The connection used by EntityManager . const connection = manager.connection; queryRunner - The query runner used by EntityManager . Used only in transactional instances of EntityManager. const queryRunner = manager.queryRunner; transaction - Provides a transaction where multiple database requests will be executed in a single database transaction. Learn more Transactions . await manager.transaction(async manager => { // NOTE: you must perform all database operations using the given manager instance // it's a special instance of EntityManager working with this transaction // and don't forget to await things here }); query - Executes a raw SQL query. const rawData = await manager.query(`SELECT * FROM USERS`); createQueryBuilder - Creates a query builder use to build SQL queries. Learn more about QueryBuilder . const users = await manager.createQueryBuilder() .select() .from(User, \"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); hasId - Checks if given entity has its primary column property defined. if (manager.hasId(user)) { // ... do something } getId - Gets given entity's primary column property value. If the entity has composite primary keys then the returned value will be an object with names and values of primary columns. const userId = manager.getId(user); // userId === 1 create - Creates a new instance of User . Optionally accepts an object literal with user properties which will be written into newly created user object. const user = manager.create(User); // same as const user = new User(); const user = manager.create(User, { id: 1, firstName: \"Timber\", lastName: \"Saw\" }); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; merge - Merges multiple entities into a single entity. const user = new User(); manager.merge(User, user, { firstName: \"Timber\" }, { lastName: \"Saw\" }); // same as user.firstName = \"Timber\"; user.lastName = \"Saw\"; preload - Creates a new entity from the given plain javascript object. If the entity already exist in the database, then it loads it (and everything related to it), replaces all values with the new ones from the given object, and returns the new entity. The new entity is actually loaded from the database entity with all properties replaced from the new object. const partialUser = { id: 1, firstName: \"Rizzrak\", profile: { id: 1 } }; const user = await manager.preload(User, partialUser); // user will contain all missing data from partialUser with partialUser property values: // { id: 1, firstName: \"Rizzrak\", lastName: \"Saw\", profile: { id: 1, ... } } save - Saves a given entity or array of entities. If the entity already exists in the database, then it's updated. If the entity does not exist in the database yet, it's inserted. It saves all given entities in a single transaction (in the case of entity manager is not transactional). Also supports partial updating since all undefined properties are skipped. In order to make a value NULL , you must manually set the property to equal null . await manager.save(user); await manager.save([ category1, category2, category3 ]); remove - Removes a given entity or array of entities. It removes all given entities in a single transaction (in the case of entity, manager is not transactional). await manager.remove(user); await manager.remove([ category1, category2, category3 ]); insert - Inserts a new entity, or array of entities. await manager.insert(User, { firstName: \"Timber\", lastName: \"Timber\" }); await manager.insert(User, [{ firstName: \"Foo\", lastName: \"Bar\" }, { firstName: \"Rizz\", lastName: \"Rak\" }]); update - Partially updates entity by a given update options or entity id. await manager.update(User, { firstName: \"Timber\" }, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE firstName = Timber await manager.update(User, 1, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE id = 1 delete - Deletes entities by entity id, ids or given conditions: await manager.delete(User, 1); await manager.delete(User, [1, 2, 3]); await manager.delete(User, { firstName: \"Timber\" }); count - Counts entities that match given options. Useful for pagination. const count = await manager.count(User, { firstName: \"Timber\" }); increment - Increments some column by provided value of entities that match given options. await manager.increment(User, { firstName: \"Timber\" }, \"age\", 3); decrement - Decrements some column by provided value that match given options. await manager.decrement(User, { firstName: \"Timber\" }, \"age\", 3); find - Finds entities that match given options. const timbers = await manager.find(User, { firstName: \"Timber\" }); findAndCount - Finds entities that match given find options. Also counts all entities that match given conditions, but ignores pagination settings (from and take options). const [timbers, timbersCount] = await manager.findAndCount(User, { firstName: \"Timber\" }); findByIds - Finds multiple entities by id. const users = await manager.findByIds(User, [1, 2, 3]); findOne - Finds the first entity that matches some id or find options. const user = await manager.findOne(User, 1); const timber = await manager.findOne(User, { firstName: \"Timber\" }); findOneOrFail - Finds the first entity that matches some id or find options. Rejects the returned promise if nothing matches. const user = await manager.findOneOrFail(User, 1); const timber = await manager.findOneOrFail(User, { firstName: \"Timber\" }); clear - Clears all the data from the given table (truncates/drops it). await manager.clear(User); getRepository - Gets Repository to perform operations on a specific entity. Learn more about Repositories . const userRepository = manager.getRepository(User); getTreeRepository - Gets TreeRepository to perform operations on a specific entity. Learn more about Repositories . const categoryRepository = manager.getTreeRepository(Category); getMongoRepository - Gets MongoRepository to perform operations on a specific entity. Learn more about MongoDB . const userRepository = manager.getMongoRepository(User); getCustomRepository - Gets custom entity repository. Learn more about Custom repositories . const myUserRepository = manager.getCustomRepository(UserRepository); release - Releases query runner of an entity manager. Used only when query runner was created and managed manually. await manager.release();","title":"EntityManager API"},{"location":"entity-metadata/","text":"Entity Metadata Entity metadata and all related metadata classes contain information about entities, their columns, indices, relations and other entity-related information you can use to create more complex applications or extensions for TypeORM. TBD.","title":"Entity Metadata"},{"location":"entity-metadata/#entity-metadata","text":"Entity metadata and all related metadata classes contain information about entities, their columns, indices, relations and other entity-related information you can use to create more complex applications or extensions for TypeORM. TBD.","title":"Entity Metadata"},{"location":"example-with-express/","text":"Example using TypeORM with Express Initial setup Adding Express to the application Adding TypeORM to the application Initial setup Let's create a simple application called \"user\" which stores users in the database and allows us to create, update, remove, and get a list of all users, as well as a single user by id within web api. First, create a directory called \"user\": mkdir user Then switch to the directory and create a new project: cd user npm init Finish the init process by filling in all required application information. Now we need to install and setup a TypeScript compiler. Lets install it first: npm i typescript --save-dev Then let's create a tsconfig.json file which contains the configuration required for the application to compile and run. Create it using your favorite editor and put the following configuration: { \"compilerOptions\": { \"lib\": [\"es5\", \"es6\", \"dom\"], \"target\": \"es5\", \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true } } Now let's create a main application endpoint - app.ts inside the src directory: mkdir src cd src touch app.ts Let's add a simple console.log inside it: console.log(\"Application is up and running\"); Now it's time to run our application. To run it, you need to compile your typescript project first: tsc Once you compile it, you should have a src/app.js file generated. You can run it using: node src/app.js You should see the, \"Application is up and running\" message in your console right after you run the application. You must compile your files each time you make a change. Alternatively, you can setup watcher or install ts-node to avoid manual compilation each time. Adding Express to the application Let's add Express to our application. First, let's install the packages we need: npm i express @types/express --save express is the express engine itself. It allows us to create a web api @types/express is used to have a type information when using express Let's edit the src/app.ts file and add express-related logic: import * as express from \"express\"; import {Request, Response} from \"express\"; // create and setup express app const app = express(); app.use(express.json()); // register routes app.get(\"/users\", function(req: Request, res: Response) { // here we will have logic to return all users }); app.get(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to return user by id }); app.post(\"/users\", function(req: Request, res: Response) { // here we will have logic to save a user }); app.put(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to update a user by a given user id }); app.delete(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to delete a user by a given user id }); // start express server app.listen(3000); Now you can compile and run your project. You should have an express server running now with working routes. However, those routes do not return any content yet. Adding TypeORM to the application Finally, let's add TypeORM to the application. In this example, we will use mysql driver. Setup process for other drivers is similar. Let's install the required packages first: npm i typeorm mysql reflect-metadata --save typeorm is the typeorm package itself mysql is the underlying database driver. If you are using a different database system, you must install the appropriate package reflect-metadata is required to make decorators to work properly Now let's create ormconfig.json with the database connection configuration we will use. { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\", \"entities\": [\"src/entity/*.js\"], \"logging\": true, \"synchronize\": true } Configure each option as you need. Learn more about connection options . Let's create a User entity inside src/entity : import {Entity, Column, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } Let's change src/app.ts : import * as express from \"express\"; import {Request, Response} from \"express\"; import {createConnection} from \"typeorm\"; import {User} from \"./entity/User\"; // create typeorm connection createConnection().then(connection => { const userRepository = connection.getRepository(User); // create and setup express app const app = express(); app.use(express.json()); // register routes app.get(\"/users\", async function(req: Request, res: Response) { const users = await userRepository.find(); res.json(users); }); app.get(\"/users/:id\", async function(req: Request, res: Response) { const results = await userRepository.findOne(req.params.id); return res.send(results); }); app.post(\"/users\", async function(req: Request, res: Response) { const user = await userRepository.create(req.body); const results = await userRepository.save(user); return res.send(results); }); app.put(\"/users/:id\", async function(req: Request, res: Response) { const user = await userRepository.findOne(req.params.id); userRepository.merge(user, req.body); const results = await userRepository.save(user); return res.send(results); }); app.delete(\"/users/:id\", async function(req: Request, res: Response) { const results = await userRepository.delete(req.params.id); return res.send(results); }); // start express server app.listen(3000); }); If you want to extract action callbacks into separate files and you need the connection instance, you can simply use getConnection : import {getConnection} from \"typeorm\"; import {User} from \"./entity/User\"; export function UsersListAction(req: Request, res: Response) { return getConnection().getRepository(User).find(); } You don't even need getConnection in this example - you can directly use the getRepository function: import {getRepository} from \"typeorm\"; import {User} from \"./entity/User\"; export function UsersListAction(req: Request, res: Response) { return getRepository(User).find(); }","title":"Example using TypeORM with Express"},{"location":"example-with-express/#example-using-typeorm-with-express","text":"Initial setup Adding Express to the application Adding TypeORM to the application","title":"Example using TypeORM with Express"},{"location":"example-with-express/#initial-setup","text":"Let's create a simple application called \"user\" which stores users in the database and allows us to create, update, remove, and get a list of all users, as well as a single user by id within web api. First, create a directory called \"user\": mkdir user Then switch to the directory and create a new project: cd user npm init Finish the init process by filling in all required application information. Now we need to install and setup a TypeScript compiler. Lets install it first: npm i typescript --save-dev Then let's create a tsconfig.json file which contains the configuration required for the application to compile and run. Create it using your favorite editor and put the following configuration: { \"compilerOptions\": { \"lib\": [\"es5\", \"es6\", \"dom\"], \"target\": \"es5\", \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true } } Now let's create a main application endpoint - app.ts inside the src directory: mkdir src cd src touch app.ts Let's add a simple console.log inside it: console.log(\"Application is up and running\"); Now it's time to run our application. To run it, you need to compile your typescript project first: tsc Once you compile it, you should have a src/app.js file generated. You can run it using: node src/app.js You should see the, \"Application is up and running\" message in your console right after you run the application. You must compile your files each time you make a change. Alternatively, you can setup watcher or install ts-node to avoid manual compilation each time.","title":"Initial setup"},{"location":"example-with-express/#adding-express-to-the-application","text":"Let's add Express to our application. First, let's install the packages we need: npm i express @types/express --save express is the express engine itself. It allows us to create a web api @types/express is used to have a type information when using express Let's edit the src/app.ts file and add express-related logic: import * as express from \"express\"; import {Request, Response} from \"express\"; // create and setup express app const app = express(); app.use(express.json()); // register routes app.get(\"/users\", function(req: Request, res: Response) { // here we will have logic to return all users }); app.get(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to return user by id }); app.post(\"/users\", function(req: Request, res: Response) { // here we will have logic to save a user }); app.put(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to update a user by a given user id }); app.delete(\"/users/:id\", function(req: Request, res: Response) { // here we will have logic to delete a user by a given user id }); // start express server app.listen(3000); Now you can compile and run your project. You should have an express server running now with working routes. However, those routes do not return any content yet.","title":"Adding Express to the application"},{"location":"example-with-express/#adding-typeorm-to-the-application","text":"Finally, let's add TypeORM to the application. In this example, we will use mysql driver. Setup process for other drivers is similar. Let's install the required packages first: npm i typeorm mysql reflect-metadata --save typeorm is the typeorm package itself mysql is the underlying database driver. If you are using a different database system, you must install the appropriate package reflect-metadata is required to make decorators to work properly Now let's create ormconfig.json with the database connection configuration we will use. { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\", \"entities\": [\"src/entity/*.js\"], \"logging\": true, \"synchronize\": true } Configure each option as you need. Learn more about connection options . Let's create a User entity inside src/entity : import {Entity, Column, PrimaryGeneratedColumn} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } Let's change src/app.ts : import * as express from \"express\"; import {Request, Response} from \"express\"; import {createConnection} from \"typeorm\"; import {User} from \"./entity/User\"; // create typeorm connection createConnection().then(connection => { const userRepository = connection.getRepository(User); // create and setup express app const app = express(); app.use(express.json()); // register routes app.get(\"/users\", async function(req: Request, res: Response) { const users = await userRepository.find(); res.json(users); }); app.get(\"/users/:id\", async function(req: Request, res: Response) { const results = await userRepository.findOne(req.params.id); return res.send(results); }); app.post(\"/users\", async function(req: Request, res: Response) { const user = await userRepository.create(req.body); const results = await userRepository.save(user); return res.send(results); }); app.put(\"/users/:id\", async function(req: Request, res: Response) { const user = await userRepository.findOne(req.params.id); userRepository.merge(user, req.body); const results = await userRepository.save(user); return res.send(results); }); app.delete(\"/users/:id\", async function(req: Request, res: Response) { const results = await userRepository.delete(req.params.id); return res.send(results); }); // start express server app.listen(3000); }); If you want to extract action callbacks into separate files and you need the connection instance, you can simply use getConnection : import {getConnection} from \"typeorm\"; import {User} from \"./entity/User\"; export function UsersListAction(req: Request, res: Response) { return getConnection().getRepository(User).find(); } You don't even need getConnection in this example - you can directly use the getRepository function: import {getRepository} from \"typeorm\"; import {User} from \"./entity/User\"; export function UsersListAction(req: Request, res: Response) { return getRepository(User).find(); }","title":"Adding TypeORM to the application"},{"location":"faq/","text":"FAQ How do I change a column name in the database? How can I set value of default some function, for example NOW() ? How to do validation? What does \"owner side\" in relations mean or why we need to put @JoinColumn and @JoinTable decorators? How do I add extra columns into many-to-many (junction) table? How to use TypeORM with dependency injection tool? How to handle outDir TypeScript compiler option? How to use TypeORM with ts-node? How to use Webpack for the backend How do I update a database schema? One of the main responsibilities of TypeORM is to keep your database tables in sync with your entities. There are two ways that help you achieve this: Use synchronize: true in your connection options: ```typescript import {createConnection} from \"typeorm\"; createConnection({ synchronize: true }); ``` This option automatically syncs your database tables with the given entities each time you run this code. This option is perfect during development, but in production you may not want this option to be enabled. Use command line tools and run schema sync manually in the command line: typeorm schema:sync This command will execute schema synchronization. Note, to make command line tools work, you must create an ormconfig.json file. Schema sync is extremely fast. If you are considering the disable synchronize option during development because of performance issues, first check how fast it is. How do I change a column name in the database? By default, column names are generated from property names. You can simply change it by specifying a name column option: @Column({ name: \"is_active\" }) isActive: boolean; How can I set the default value to some function, for example NOW() ? default column option supports a function. If you are passing a function which returns a string, it will use that string as a default value without escaping it. For example: @Column({ default: () => \"NOW()\" }) date: Date; How to do validation? Validation is not part of TypeORM because validation is a separate process not really related to what TypeORM does. If you want to use validation use class-validator - it works perfectly with TypeORM. What does \"owner side\" in a relations mean or why we need to use @JoinColumn and @JoinTable ? Let's start with one-to-one relation. Let's say we have two entities: User and Photo : @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne() photo: Photo; } @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @OneToOne() user: User; } This example does not have a @JoinColumn which is incorrect. Why? Because to make a real relation, we need to create a column in the database. We need to create a column userId in photo or photoId in user . But which column should be created - userId or photoId ? TypeORM cannot decide for you. To make a decision, you must use @JoinColumn on one of the sides. If you put @JoinColumn in Photo then a column called userId will be created in the photo table. If you put @JoinColumn in User then a column called photoId will be created in the user table. The side with @JoinColumn will be called the \"owner side of the relationship\". The other side of the relation, without @JoinColumn , is called the \"inverse (non-owner) side of relationship\". It is the same in a @ManyToMany relation. You use @JoinTable to show the owner side of the relation. In @ManyToOne or @OneToMany relations, @JoinColumn is not necessary because both decorators are different, and the table where you put the @ManyToOne decorator will have the relational column. @JoinColumn and @JoinTable decorators can also be used to specify additional join column / junction table settings, like join column name or junction table name. How do I add extra columns into many-to-many (junction) table? It's not possible to add extra columns into a table created by a many-to-many relation. You'll need to create a separate entity and bind it using two many-to-one relations with the target entities (the effect will be same as creating a many-to-many table), and add extra columns in there. You can read more about this in Many-to-Many relations . How to use TypeORM with a dependency injection tool? In TypeORM you can use service containers. Service containers allow you to inject custom services in some places, like in subscribers or custom naming strategies. For example, you can get access to ConnectionManager from any place using a service container. Here is an example for how you can set up typedi service containers with TypeORM. Note: you can setup any service container with TypeORM. import {useContainer, createConnection} from \"typeorm\"; import {Container} from \"typedi\"; // its important to setup container before you start to work with TypeORM useContainer(Container); createConnection({/* ... */}); How to handle outDir TypeScript compiler option? When you are using the outDir compiler option, don't forget to copy assets and resources your app is using into the output directory. Otherwise, make sure to setup correct paths to those assets. One important thing to know is that when you remove or move entities, the old entities are left untouched inside the output directory. For example, you create a Post entity and rename it to Blog , you no longer have Post.ts in your project. However, Post.js is left inside the output directory. Now, when TypeORM reads entities from your output directory, it sees two entities - Post and Blog . This may be a source of bugs. That's why when you remove and move entities with outDir enabled, it's strongly recommended to remove your output directory and recompile the project again. How to use TypeORM with ts-node? You can prevent compiling files each time using ts-node . If you are using ts-node, you can specify ts entities inside your connection options: { entities: [\"src/entity/*.ts\"], subscribers: [\"src/subscriber/*.ts\"] } Also, if you are compiling js files into the same folder where your typescript files are, make sure to use the outDir compiler option to prevent this issue . Also, if you want to use the ts-node CLI, you can execute TypeORM the following way: ts-node ./node_modules/.bin/typeorm schema:sync How to use Webpack for the backend? Webpack produces warnings due to what it views as missing require statements -- require statements for all drivers supported by TypeORM. To suppress these warnings for unused drivers, you will need to edit your webpack config file. const FilterWarningsPlugin = require('webpack-filter-warnings-plugin'); module.exports = { ... plugins: [ //ignore the drivers you don't want. This is the complete list of all drivers -- remove the suppressions for drivers you want to use. new FilterWarningsPlugin({ exclude: [/mongodb/, /mssql/, /mysql/, /mysql2/, /oracledb/, /pg/, /pg-native/, /pg-query-stream/, /react-native-sqlite-storage/, /redis/, /sqlite3/, /sql.js/, /typeorm-aurora-data-api-driver/] }) ] }; Bundling Migration Files By default Webpack tries to bundle everything into one file. This can be problematic when your project has migration files which are meant to be executed after bundled code is deployed to production. To make sure all your migrations can be recognized and executed by TypeORM, you may need to use \"Object Syntax\" for the entry configuration for the migration files only. const glob = require('glob'); const path = require('path'); module.exports = { // ... your webpack configurations here... // Dynamically generate a `{ [name]: sourceFileName }` map for the `entry` option // change `src/db/migrations` to the relative path to your migration folder entry: glob.sync(path.resolve('src/db/migrations/*.ts')).reduce((entries, filename) => { const migrationName = path.basename(filename, '.ts'); return Object.assign({}, entries, { [migrationName]: filename, }); }, {}), resolve: { // assuming all your migration files are written in TypeScript extensions: ['.ts'] }, output: { // change `path` to where you want to put transpiled migration files. path: __dirname + '/dist/db/migrations', // this is important - we want UMD (Universal Module Definition) for migration files. libraryTarget: 'umd', filename: '[name].js', }, }; Also, since Webpack 4, when using mode: 'production' , files are optimized by default which includes mangling your code in order to minimize file sizes. This breaks the migrations because TypeORM relies on their names to determine which has already been executed. You may disable minimization completely by adding: module.exports = { // ... other Webpack configurations here optimization: { minimize: false, }, }; Alternatively, if you are using the UglifyJsPlugin , you can tell it to not change class or function names like so: const UglifyJsPlugin = require('uglifyjs-webpack-plugin'); module.exports = { // ... other Webpack configurations here optimization: { minimizer: [ new UglifyJsPlugin({ uglifyOptions: { keep_classnames: true, keep_fnames: true } }) ], }, }; Lastly, make sure in your ormconfig file, the transpiled migration files are included: // TypeORM Configurations module.exports = { // ... migrations: [ // this is the relative path to the transpiled migration files in production 'db/migrations/**/*.js', // your source migration files, used in development mode 'src/db/migrations/**/*.ts', ], };","title":"FAQ"},{"location":"faq/#faq","text":"How do I change a column name in the database? How can I set value of default some function, for example NOW() ? How to do validation? What does \"owner side\" in relations mean or why we need to put @JoinColumn and @JoinTable decorators? How do I add extra columns into many-to-many (junction) table? How to use TypeORM with dependency injection tool? How to handle outDir TypeScript compiler option? How to use TypeORM with ts-node? How to use Webpack for the backend","title":"FAQ"},{"location":"faq/#how-do-i-update-a-database-schema","text":"One of the main responsibilities of TypeORM is to keep your database tables in sync with your entities. There are two ways that help you achieve this: Use synchronize: true in your connection options: ```typescript import {createConnection} from \"typeorm\"; createConnection({ synchronize: true }); ``` This option automatically syncs your database tables with the given entities each time you run this code. This option is perfect during development, but in production you may not want this option to be enabled. Use command line tools and run schema sync manually in the command line: typeorm schema:sync This command will execute schema synchronization. Note, to make command line tools work, you must create an ormconfig.json file. Schema sync is extremely fast. If you are considering the disable synchronize option during development because of performance issues, first check how fast it is.","title":"How do I update a database schema?"},{"location":"faq/#how-do-i-change-a-column-name-in-the-database","text":"By default, column names are generated from property names. You can simply change it by specifying a name column option: @Column({ name: \"is_active\" }) isActive: boolean;","title":"How do I change a column name in the database?"},{"location":"faq/#how-can-i-set-the-default-value-to-some-function-for-example-now","text":"default column option supports a function. If you are passing a function which returns a string, it will use that string as a default value without escaping it. For example: @Column({ default: () => \"NOW()\" }) date: Date;","title":"How can I set the default value to some function, for example NOW()?"},{"location":"faq/#how-to-do-validation","text":"Validation is not part of TypeORM because validation is a separate process not really related to what TypeORM does. If you want to use validation use class-validator - it works perfectly with TypeORM.","title":"How to do validation?"},{"location":"faq/#what-does-owner-side-in-a-relations-mean-or-why-we-need-to-use-joincolumn-and-jointable","text":"Let's start with one-to-one relation. Let's say we have two entities: User and Photo : @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne() photo: Photo; } @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @OneToOne() user: User; } This example does not have a @JoinColumn which is incorrect. Why? Because to make a real relation, we need to create a column in the database. We need to create a column userId in photo or photoId in user . But which column should be created - userId or photoId ? TypeORM cannot decide for you. To make a decision, you must use @JoinColumn on one of the sides. If you put @JoinColumn in Photo then a column called userId will be created in the photo table. If you put @JoinColumn in User then a column called photoId will be created in the user table. The side with @JoinColumn will be called the \"owner side of the relationship\". The other side of the relation, without @JoinColumn , is called the \"inverse (non-owner) side of relationship\". It is the same in a @ManyToMany relation. You use @JoinTable to show the owner side of the relation. In @ManyToOne or @OneToMany relations, @JoinColumn is not necessary because both decorators are different, and the table where you put the @ManyToOne decorator will have the relational column. @JoinColumn and @JoinTable decorators can also be used to specify additional join column / junction table settings, like join column name or junction table name.","title":"What does \"owner side\" in a relations mean or why we need to use @JoinColumn and @JoinTable?"},{"location":"faq/#how-do-i-add-extra-columns-into-many-to-many-junction-table","text":"It's not possible to add extra columns into a table created by a many-to-many relation. You'll need to create a separate entity and bind it using two many-to-one relations with the target entities (the effect will be same as creating a many-to-many table), and add extra columns in there. You can read more about this in Many-to-Many relations .","title":"How do I add extra columns into many-to-many (junction) table?"},{"location":"faq/#how-to-use-typeorm-with-a-dependency-injection-tool","text":"In TypeORM you can use service containers. Service containers allow you to inject custom services in some places, like in subscribers or custom naming strategies. For example, you can get access to ConnectionManager from any place using a service container. Here is an example for how you can set up typedi service containers with TypeORM. Note: you can setup any service container with TypeORM. import {useContainer, createConnection} from \"typeorm\"; import {Container} from \"typedi\"; // its important to setup container before you start to work with TypeORM useContainer(Container); createConnection({/* ... */});","title":"How to use TypeORM with a dependency injection tool?"},{"location":"faq/#how-to-handle-outdir-typescript-compiler-option","text":"When you are using the outDir compiler option, don't forget to copy assets and resources your app is using into the output directory. Otherwise, make sure to setup correct paths to those assets. One important thing to know is that when you remove or move entities, the old entities are left untouched inside the output directory. For example, you create a Post entity and rename it to Blog , you no longer have Post.ts in your project. However, Post.js is left inside the output directory. Now, when TypeORM reads entities from your output directory, it sees two entities - Post and Blog . This may be a source of bugs. That's why when you remove and move entities with outDir enabled, it's strongly recommended to remove your output directory and recompile the project again.","title":"How to handle outDir TypeScript compiler option?"},{"location":"faq/#how-to-use-typeorm-with-ts-node","text":"You can prevent compiling files each time using ts-node . If you are using ts-node, you can specify ts entities inside your connection options: { entities: [\"src/entity/*.ts\"], subscribers: [\"src/subscriber/*.ts\"] } Also, if you are compiling js files into the same folder where your typescript files are, make sure to use the outDir compiler option to prevent this issue . Also, if you want to use the ts-node CLI, you can execute TypeORM the following way: ts-node ./node_modules/.bin/typeorm schema:sync","title":"How to use TypeORM with ts-node?"},{"location":"faq/#how-to-use-webpack-for-the-backend","text":"Webpack produces warnings due to what it views as missing require statements -- require statements for all drivers supported by TypeORM. To suppress these warnings for unused drivers, you will need to edit your webpack config file. const FilterWarningsPlugin = require('webpack-filter-warnings-plugin'); module.exports = { ... plugins: [ //ignore the drivers you don't want. This is the complete list of all drivers -- remove the suppressions for drivers you want to use. new FilterWarningsPlugin({ exclude: [/mongodb/, /mssql/, /mysql/, /mysql2/, /oracledb/, /pg/, /pg-native/, /pg-query-stream/, /react-native-sqlite-storage/, /redis/, /sqlite3/, /sql.js/, /typeorm-aurora-data-api-driver/] }) ] };","title":"How to use Webpack for the backend?"},{"location":"faq/#bundling-migration-files","text":"By default Webpack tries to bundle everything into one file. This can be problematic when your project has migration files which are meant to be executed after bundled code is deployed to production. To make sure all your migrations can be recognized and executed by TypeORM, you may need to use \"Object Syntax\" for the entry configuration for the migration files only. const glob = require('glob'); const path = require('path'); module.exports = { // ... your webpack configurations here... // Dynamically generate a `{ [name]: sourceFileName }` map for the `entry` option // change `src/db/migrations` to the relative path to your migration folder entry: glob.sync(path.resolve('src/db/migrations/*.ts')).reduce((entries, filename) => { const migrationName = path.basename(filename, '.ts'); return Object.assign({}, entries, { [migrationName]: filename, }); }, {}), resolve: { // assuming all your migration files are written in TypeScript extensions: ['.ts'] }, output: { // change `path` to where you want to put transpiled migration files. path: __dirname + '/dist/db/migrations', // this is important - we want UMD (Universal Module Definition) for migration files. libraryTarget: 'umd', filename: '[name].js', }, }; Also, since Webpack 4, when using mode: 'production' , files are optimized by default which includes mangling your code in order to minimize file sizes. This breaks the migrations because TypeORM relies on their names to determine which has already been executed. You may disable minimization completely by adding: module.exports = { // ... other Webpack configurations here optimization: { minimize: false, }, }; Alternatively, if you are using the UglifyJsPlugin , you can tell it to not change class or function names like so: const UglifyJsPlugin = require('uglifyjs-webpack-plugin'); module.exports = { // ... other Webpack configurations here optimization: { minimizer: [ new UglifyJsPlugin({ uglifyOptions: { keep_classnames: true, keep_fnames: true } }) ], }, }; Lastly, make sure in your ormconfig file, the transpiled migration files are included: // TypeORM Configurations module.exports = { // ... migrations: [ // this is the relative path to the transpiled migration files in production 'db/migrations/**/*.js', // your source migration files, used in development mode 'src/db/migrations/**/*.ts', ], };","title":"Bundling Migration Files"},{"location":"find-options/","text":"Find Options Basic options Advanced options Basic options All repository and manager find methods accept special options you can use to query data you need without using QueryBuilder : select - indicates which properties of the main object must be selected userRepository.find({ select: [\"firstName\", \"lastName\"] }); will execute following query: SELECT \"firstName\", \"lastName\" FROM \"user\" relations - relations needs to be loaded with the main entity. Sub-relations can also be loaded (shorthand for join and leftJoinAndSelect) userRepository.find({ relations: [\"profile\", \"photos\", \"videos\"] }); userRepository.find({ relations: [\"profile\", \"photos\", \"videos\", \"videos.video_attributes\"], }); will execute following queries: SELECT * FROM \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profileId\" LEFT JOIN \"photos\" ON \"photos\".\"id\" = \"user\".\"photoId\" LEFT JOIN \"videos\" ON \"videos\".\"id\" = \"user\".\"videoId\" SELECT * FROM \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profileId\" LEFT JOIN \"photos\" ON \"photos\".\"id\" = \"user\".\"photoId\" LEFT JOIN \"videos\" ON \"videos\".\"id\" = \"user\".\"videoId\" LEFT JOIN \"video_attributes\" ON \"video_attributes\".\"id\" = \"videos\".\"video_attributesId\" join - joins needs to be performed for the entity. Extended version of \"relations\". userRepository.find({ join: { alias: \"user\", leftJoinAndSelect: { profile: \"user.profile\", photo: \"user.photos\", video: \"user.videos\", }, }, }); will execute following query: SELECT * FROM \"user\" \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profile\" LEFT JOIN \"photo\" ON \"photo\".\"id\" = \"user\".\"photos\" LEFT JOIN \"video\" ON \"video\".\"id\" = \"user\".\"videos\" where - simple conditions by which entity should be queried. userRepository.find({ where: { firstName: \"Timber\", lastName: \"Saw\" } }); will execute following query: SELECT * FROM \"user\" WHERE \"firstName\" = 'Timber' AND \"lastName\" = 'Saw' Querying a column from an embedded entity should be done with respect to the hierarchy in which it was defined. Example: userRepository.find({ where: { project: { name: \"TypeORM\", initials: \"TORM\" }, }, relations: [\"project\"], }); will execute following query: SELECT * FROM \"user\" WHERE \"project\".\"name\" = 'TypeORM' AND \"project\".\"initials\" = 'TORM' LEFT JOIN \"project\" ON \"project\".\"id\" = \"user\".\"projectId\" Querying with OR operator: userRepository.find({ where: [ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Stan\", lastName: \"Lee\" }, ], }); will execute following query: SELECT * FROM \"user\" WHERE (\"firstName\" = 'Timber' AND \"lastName\" = 'Saw') OR (\"firstName\" = 'Stan' AND \"lastName\" = 'Lee') order - selection order. userRepository.find({ order: { name: \"ASC\", id: \"DESC\", }, }); will execute following query: SELECT * FROM \"user\" ORDER BY \"name\" ASC, \"id\" DESC withDeleted - include entities which have been soft deleted with softDelete or softRemove , e.g. have their @DeleteDateColumn column set. By default, soft deleted entities are not included. userRepository.find({ withDeleted: true, }); find methods which return multiple entities ( find , findAndCount , findByIds ) also accept following options: skip - offset (paginated) from where entities should be taken. userRepository.find({ skip: 5, }); SELECT * FROM \"user\" OFFSET 5 take - limit (paginated) - max number of entities that should be taken. userRepository.find({ take: 10, }); will execute following query: SELECT * FROM \"user\" LIMIT 10 ** skip and take should be used together ** If you are using typeorm with MSSQL, and want to use take or limit , you need to use order as well or you will receive the following error: 'Invalid usage of the option NEXT in the FETCH statement.' userRepository.find({ order: { columnName: \"ASC\", }, skip: 0, take: 10, }); will execute following query: SELECT * FROM \"user\" ORDER BY \"columnName\" ASC LIMIT 10 OFFSET 0 cache - Enables or disables query result caching. See caching for more information and options. userRepository.find({ cache: true, }); lock - Enables locking mechanism for query. Can be used only in findOne method. lock is an object which can be defined as: { mode: \"optimistic\", version: number|Date } or { mode: \"pessimistic_read\" | \"pessimistic_write\" | \"dirty_read\" | \"pessimistic_partial_write\" | \"pessimistic_write_or_fail\" | \"for_no_key_update\"; } for example: userRepository.findOne(1, { lock: { mode: \"optimistic\", version: 1 }, }); Support of lock modes, and SQL statements they translate to, are listed in the table below (blank cell denotes unsupported). When specified lock mode is not supported, a LockNotSupportedOnGivenDriverError error will be thrown. | | pessimistic_read | pessimistic_write | dirty_read | pessimistic_partial_write | pessimistic_write_or_fail | for_no_key_update | | --------------- | -------------------- | ----------------------- | ------------- | --------------------------- | --------------------------- | ------------------- | | MySQL | LOCK IN SHARE MODE | FOR UPDATE | (nothing) | FOR UPDATE SKIP LOCKED | FOR UPDATE NOWAIT | | | Postgres | FOR SHARE | FOR UPDATE | (nothing) | FOR UPDATE SKIP LOCKED | FOR UPDATE NOWAIT | FOR NO KEY UPDATE | | Oracle | FOR UPDATE | FOR UPDATE | (nothing) | | | | | SQL Server | WITH (HOLDLOCK, ROWLOCK) | WITH (UPDLOCK, ROWLOCK) | WITH (NOLOCK) | | | | | AuroraDataApi | LOCK IN SHARE MODE | FOR UPDATE | (nothing) | | | | Complete example of find options: userRepository.find({ select: [\"firstName\", \"lastName\"], relations: [\"profile\", \"photos\", \"videos\"], where: { firstName: \"Timber\", lastName: \"Saw\", profile: { userName: \"tshaw\", }, }, order: { name: \"ASC\", id: \"DESC\", }, skip: 5, take: 10, cache: true, }); Advanced options TypeORM provides a lot of built-in operators that can be used to create more complex comparisons: Not import { Not } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Not(\"About #1\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" != 'About #1' LessThan import { LessThan } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: LessThan(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" < 10 LessThanOrEqual import { LessThanOrEqual } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: LessThanOrEqual(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" <= 10 MoreThan import { MoreThan } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: MoreThan(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" > 10 MoreThanOrEqual import { MoreThanOrEqual } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: MoreThanOrEqual(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" >= 10 Equal import { Equal } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Equal(\"About #2\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" = 'About #2' Like import { Like } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Like(\"%out #%\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" LIKE '%out #%' ILike import { ILike } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: ILike(\"%out #%\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" ILIKE '%out #%' Between import { Between } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Between(1, 10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" BETWEEN 1 AND 10 In import { In } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: In([\"About #2\", \"About #3\"]), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" IN ('About #2','About #3') Any import { Any } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Any([\"About #2\", \"About #3\"]), }); will execute following query (Postgres notation): SELECT * FROM \"post\" WHERE \"title\" = ANY(['About #2','About #3']) IsNull import { IsNull } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: IsNull(), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" IS NULL Raw import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Raw(\"dislikes - 4\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" = \"dislikes\" - 4 In the simplest case, a raw query is inserted immediately after the equal symbol. But you can also completely rewrite the comparison logic using the function. import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ currentDate: Raw((alias) => `${alias} > NOW()`), }); will execute following query: SELECT * FROM \"post\" WHERE \"currentDate\" > NOW() If you need to provide user input, you should not include the user input directly in your query as this may create a SQL injection vulnerability. Instead, you can use the second argument of the Raw function to provide a list of parameters to bind to the query. import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ currentDate: Raw((alias) => `${alias} > :date`, { date: \"2020-10-06\" }), }); will execute following query: SELECT * FROM \"post\" WHERE \"currentDate\" > '2020-10-06' If you need to provide user input that is an array, you can bind them as a list of values in the SQL statement by using the special expression syntax: import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Raw((alias) => `${alias} IN (:...titles)`, { titles: [ \"Go To Statement Considered Harmful\", \"Structured Programming\", ], }), }); will execute following query: SELECT * FROM \"post\" WHERE \"titles\" IN ('Go To Statement Considered Harmful', 'Structured Programming') Combining Advanced Options Also you can combine these operators with Not operator: import { Not, MoreThan, Equal } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Not(MoreThan(10)), title: Not(Equal(\"About #2\")), }); will execute following query: SELECT * FROM \"post\" WHERE NOT(\"likes\" > 10) AND NOT(\"title\" = 'About #2')","title":"Find Options"},{"location":"find-options/#find-options","text":"Basic options Advanced options","title":"Find Options"},{"location":"find-options/#basic-options","text":"All repository and manager find methods accept special options you can use to query data you need without using QueryBuilder : select - indicates which properties of the main object must be selected userRepository.find({ select: [\"firstName\", \"lastName\"] }); will execute following query: SELECT \"firstName\", \"lastName\" FROM \"user\" relations - relations needs to be loaded with the main entity. Sub-relations can also be loaded (shorthand for join and leftJoinAndSelect) userRepository.find({ relations: [\"profile\", \"photos\", \"videos\"] }); userRepository.find({ relations: [\"profile\", \"photos\", \"videos\", \"videos.video_attributes\"], }); will execute following queries: SELECT * FROM \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profileId\" LEFT JOIN \"photos\" ON \"photos\".\"id\" = \"user\".\"photoId\" LEFT JOIN \"videos\" ON \"videos\".\"id\" = \"user\".\"videoId\" SELECT * FROM \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profileId\" LEFT JOIN \"photos\" ON \"photos\".\"id\" = \"user\".\"photoId\" LEFT JOIN \"videos\" ON \"videos\".\"id\" = \"user\".\"videoId\" LEFT JOIN \"video_attributes\" ON \"video_attributes\".\"id\" = \"videos\".\"video_attributesId\" join - joins needs to be performed for the entity. Extended version of \"relations\". userRepository.find({ join: { alias: \"user\", leftJoinAndSelect: { profile: \"user.profile\", photo: \"user.photos\", video: \"user.videos\", }, }, }); will execute following query: SELECT * FROM \"user\" \"user\" LEFT JOIN \"profile\" ON \"profile\".\"id\" = \"user\".\"profile\" LEFT JOIN \"photo\" ON \"photo\".\"id\" = \"user\".\"photos\" LEFT JOIN \"video\" ON \"video\".\"id\" = \"user\".\"videos\" where - simple conditions by which entity should be queried. userRepository.find({ where: { firstName: \"Timber\", lastName: \"Saw\" } }); will execute following query: SELECT * FROM \"user\" WHERE \"firstName\" = 'Timber' AND \"lastName\" = 'Saw' Querying a column from an embedded entity should be done with respect to the hierarchy in which it was defined. Example: userRepository.find({ where: { project: { name: \"TypeORM\", initials: \"TORM\" }, }, relations: [\"project\"], }); will execute following query: SELECT * FROM \"user\" WHERE \"project\".\"name\" = 'TypeORM' AND \"project\".\"initials\" = 'TORM' LEFT JOIN \"project\" ON \"project\".\"id\" = \"user\".\"projectId\" Querying with OR operator: userRepository.find({ where: [ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Stan\", lastName: \"Lee\" }, ], }); will execute following query: SELECT * FROM \"user\" WHERE (\"firstName\" = 'Timber' AND \"lastName\" = 'Saw') OR (\"firstName\" = 'Stan' AND \"lastName\" = 'Lee') order - selection order. userRepository.find({ order: { name: \"ASC\", id: \"DESC\", }, }); will execute following query: SELECT * FROM \"user\" ORDER BY \"name\" ASC, \"id\" DESC withDeleted - include entities which have been soft deleted with softDelete or softRemove , e.g. have their @DeleteDateColumn column set. By default, soft deleted entities are not included. userRepository.find({ withDeleted: true, }); find methods which return multiple entities ( find , findAndCount , findByIds ) also accept following options: skip - offset (paginated) from where entities should be taken. userRepository.find({ skip: 5, }); SELECT * FROM \"user\" OFFSET 5 take - limit (paginated) - max number of entities that should be taken. userRepository.find({ take: 10, }); will execute following query: SELECT * FROM \"user\" LIMIT 10 ** skip and take should be used together ** If you are using typeorm with MSSQL, and want to use take or limit , you need to use order as well or you will receive the following error: 'Invalid usage of the option NEXT in the FETCH statement.' userRepository.find({ order: { columnName: \"ASC\", }, skip: 0, take: 10, }); will execute following query: SELECT * FROM \"user\" ORDER BY \"columnName\" ASC LIMIT 10 OFFSET 0 cache - Enables or disables query result caching. See caching for more information and options. userRepository.find({ cache: true, }); lock - Enables locking mechanism for query. Can be used only in findOne method. lock is an object which can be defined as: { mode: \"optimistic\", version: number|Date } or { mode: \"pessimistic_read\" | \"pessimistic_write\" | \"dirty_read\" | \"pessimistic_partial_write\" | \"pessimistic_write_or_fail\" | \"for_no_key_update\"; } for example: userRepository.findOne(1, { lock: { mode: \"optimistic\", version: 1 }, }); Support of lock modes, and SQL statements they translate to, are listed in the table below (blank cell denotes unsupported). When specified lock mode is not supported, a LockNotSupportedOnGivenDriverError error will be thrown. | | pessimistic_read | pessimistic_write | dirty_read | pessimistic_partial_write | pessimistic_write_or_fail | for_no_key_update | | --------------- | -------------------- | ----------------------- | ------------- | --------------------------- | --------------------------- | ------------------- | | MySQL | LOCK IN SHARE MODE | FOR UPDATE | (nothing) | FOR UPDATE SKIP LOCKED | FOR UPDATE NOWAIT | | | Postgres | FOR SHARE | FOR UPDATE | (nothing) | FOR UPDATE SKIP LOCKED | FOR UPDATE NOWAIT | FOR NO KEY UPDATE | | Oracle | FOR UPDATE | FOR UPDATE | (nothing) | | | | | SQL Server | WITH (HOLDLOCK, ROWLOCK) | WITH (UPDLOCK, ROWLOCK) | WITH (NOLOCK) | | | | | AuroraDataApi | LOCK IN SHARE MODE | FOR UPDATE | (nothing) | | | | Complete example of find options: userRepository.find({ select: [\"firstName\", \"lastName\"], relations: [\"profile\", \"photos\", \"videos\"], where: { firstName: \"Timber\", lastName: \"Saw\", profile: { userName: \"tshaw\", }, }, order: { name: \"ASC\", id: \"DESC\", }, skip: 5, take: 10, cache: true, });","title":"Basic options"},{"location":"find-options/#advanced-options","text":"TypeORM provides a lot of built-in operators that can be used to create more complex comparisons: Not import { Not } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Not(\"About #1\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" != 'About #1' LessThan import { LessThan } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: LessThan(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" < 10 LessThanOrEqual import { LessThanOrEqual } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: LessThanOrEqual(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" <= 10 MoreThan import { MoreThan } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: MoreThan(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" > 10 MoreThanOrEqual import { MoreThanOrEqual } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: MoreThanOrEqual(10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" >= 10 Equal import { Equal } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Equal(\"About #2\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" = 'About #2' Like import { Like } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Like(\"%out #%\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" LIKE '%out #%' ILike import { ILike } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: ILike(\"%out #%\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" ILIKE '%out #%' Between import { Between } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Between(1, 10), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" BETWEEN 1 AND 10 In import { In } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: In([\"About #2\", \"About #3\"]), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" IN ('About #2','About #3') Any import { Any } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Any([\"About #2\", \"About #3\"]), }); will execute following query (Postgres notation): SELECT * FROM \"post\" WHERE \"title\" = ANY(['About #2','About #3']) IsNull import { IsNull } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: IsNull(), }); will execute following query: SELECT * FROM \"post\" WHERE \"title\" IS NULL Raw import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Raw(\"dislikes - 4\"), }); will execute following query: SELECT * FROM \"post\" WHERE \"likes\" = \"dislikes\" - 4 In the simplest case, a raw query is inserted immediately after the equal symbol. But you can also completely rewrite the comparison logic using the function. import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ currentDate: Raw((alias) => `${alias} > NOW()`), }); will execute following query: SELECT * FROM \"post\" WHERE \"currentDate\" > NOW() If you need to provide user input, you should not include the user input directly in your query as this may create a SQL injection vulnerability. Instead, you can use the second argument of the Raw function to provide a list of parameters to bind to the query. import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ currentDate: Raw((alias) => `${alias} > :date`, { date: \"2020-10-06\" }), }); will execute following query: SELECT * FROM \"post\" WHERE \"currentDate\" > '2020-10-06' If you need to provide user input that is an array, you can bind them as a list of values in the SQL statement by using the special expression syntax: import { Raw } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ title: Raw((alias) => `${alias} IN (:...titles)`, { titles: [ \"Go To Statement Considered Harmful\", \"Structured Programming\", ], }), }); will execute following query: SELECT * FROM \"post\" WHERE \"titles\" IN ('Go To Statement Considered Harmful', 'Structured Programming')","title":"Advanced options"},{"location":"find-options/#combining-advanced-options","text":"Also you can combine these operators with Not operator: import { Not, MoreThan, Equal } from \"typeorm\"; const loadedPosts = await connection.getRepository(Post).find({ likes: Not(MoreThan(10)), title: Not(Equal(\"About #2\")), }); will execute following query: SELECT * FROM \"post\" WHERE NOT(\"likes\" > 10) AND NOT(\"title\" = 'About #2')","title":"Combining Advanced Options"},{"location":"indices/","text":"Indices Column indices Unique indices Indices with multiple columns Spatial Indices Disabling synchronization Column indices You can create a database index for a specific column by using @Index on a column you want to make an index. You can create indices for any columns of your entity. Example: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index() @Column() firstName: string; @Column() @Index() lastName: string; } You can also specify an index name: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index(\"name1-idx\") @Column() firstName: string; @Column() @Index(\"name2-idx\") lastName: string; } Unique indices To create an unique index you need to specify { unique: true } in the index options: Note: CockroachDB stores unique indices as UNIQUE constraints import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index({ unique: true }) @Column() firstName: string; @Column() @Index({ unique: true }) lastName: string; } Indices with multiple columns To create an index with multiple columns you need to put @Index on the entity itself and specify all column property names which should be included in the index. Example: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() @Index([\"firstName\", \"lastName\"]) @Index([\"firstName\", \"middleName\", \"lastName\"], { unique: true }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() middleName: string; @Column() lastName: string; } Spatial Indices MySQL and PostgreSQL (when PostGIS is available) both support spatial indices. To create a spatial index on a column in MySQL, add an Index with spatial: true on a column that uses a spatial type ( geometry , point , linestring , polygon , multipoint , multilinestring , multipolygon , geometrycollection ): @Entity() export class Thing { @Column(\"point\") @Index({ spatial: true }) point: string; } To create a spatial index on a column in PostgreSQL, add an Index with spatial: true on a column that uses a spatial type ( geometry , geography ): export interface Geometry { type: \"Point\"; coordinates: [Number, Number]; } @Entity() export class Thing { @Column(\"geometry\", { spatialFeatureType: \"Point\", srid: 4326 }) @Index({ spatial: true }) point: Geometry; } Disabling synchronization TypeORM does not support some index options and definitions (e.g. lower , pg_trgm ) because of lot of different database specifics and multiple issues with getting information about exist database indices and synchronizing them automatically. In such cases you should create index manually (for example in the migrations) with any index signature you want. To make TypeORM ignore these indices during synchronization use synchronize: false option on @Index decorator. For example, you create an index with case-insensitive comparison: CREATE INDEX \"POST_NAME_INDEX\" ON \"post\" (lower(\"name\")) after that, you should disable synchronization for this index to avoid deletion on next schema sync: @Entity() @Index(\"POST_NAME_INDEX\", { synchronize: false }) export class Post { @PrimaryGeneratedColumn() id: number; @Column() name: string; }","title":"Indices"},{"location":"indices/#indices","text":"Column indices Unique indices Indices with multiple columns Spatial Indices Disabling synchronization","title":"Indices"},{"location":"indices/#column-indices","text":"You can create a database index for a specific column by using @Index on a column you want to make an index. You can create indices for any columns of your entity. Example: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index() @Column() firstName: string; @Column() @Index() lastName: string; } You can also specify an index name: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index(\"name1-idx\") @Column() firstName: string; @Column() @Index(\"name2-idx\") lastName: string; }","title":"Column indices"},{"location":"indices/#unique-indices","text":"To create an unique index you need to specify { unique: true } in the index options: Note: CockroachDB stores unique indices as UNIQUE constraints import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Index({ unique: true }) @Column() firstName: string; @Column() @Index({ unique: true }) lastName: string; }","title":"Unique indices"},{"location":"indices/#indices-with-multiple-columns","text":"To create an index with multiple columns you need to put @Index on the entity itself and specify all column property names which should be included in the index. Example: import {Entity, PrimaryGeneratedColumn, Column, Index} from \"typeorm\"; @Entity() @Index([\"firstName\", \"lastName\"]) @Index([\"firstName\", \"middleName\", \"lastName\"], { unique: true }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() middleName: string; @Column() lastName: string; }","title":"Indices with multiple columns"},{"location":"indices/#spatial-indices","text":"MySQL and PostgreSQL (when PostGIS is available) both support spatial indices. To create a spatial index on a column in MySQL, add an Index with spatial: true on a column that uses a spatial type ( geometry , point , linestring , polygon , multipoint , multilinestring , multipolygon , geometrycollection ): @Entity() export class Thing { @Column(\"point\") @Index({ spatial: true }) point: string; } To create a spatial index on a column in PostgreSQL, add an Index with spatial: true on a column that uses a spatial type ( geometry , geography ): export interface Geometry { type: \"Point\"; coordinates: [Number, Number]; } @Entity() export class Thing { @Column(\"geometry\", { spatialFeatureType: \"Point\", srid: 4326 }) @Index({ spatial: true }) point: Geometry; }","title":"Spatial Indices"},{"location":"indices/#disabling-synchronization","text":"TypeORM does not support some index options and definitions (e.g. lower , pg_trgm ) because of lot of different database specifics and multiple issues with getting information about exist database indices and synchronizing them automatically. In such cases you should create index manually (for example in the migrations) with any index signature you want. To make TypeORM ignore these indices during synchronization use synchronize: false option on @Index decorator. For example, you create an index with case-insensitive comparison: CREATE INDEX \"POST_NAME_INDEX\" ON \"post\" (lower(\"name\")) after that, you should disable synchronization for this index to avoid deletion on next schema sync: @Entity() @Index(\"POST_NAME_INDEX\", { synchronize: false }) export class Post { @PrimaryGeneratedColumn() id: number; @Column() name: string; }","title":"Disabling synchronization"},{"location":"insert-query-builder/","text":"Insert using Query Builder You can create INSERT queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values([ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Phantom\", lastName: \"Lancer\" } ]) .execute(); This is the most efficient way in terms of performance to insert rows into your database. You can also perform bulk insertions this way. Raw SQL support In some cases when you need to execute SQL queries you need to use function style value: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values({ firstName: \"Timber\", lastName: () => \"CONCAT('S', 'A', 'W')\" }) .execute(); This syntax doesn't escape your values, you need to handle escape on your own.","title":"Insert using Query Builder"},{"location":"insert-query-builder/#insert-using-query-builder","text":"You can create INSERT queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values([ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Phantom\", lastName: \"Lancer\" } ]) .execute(); This is the most efficient way in terms of performance to insert rows into your database. You can also perform bulk insertions this way.","title":"Insert using Query Builder"},{"location":"insert-query-builder/#raw-sql-support","text":"In some cases when you need to execute SQL queries you need to use function style value: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values({ firstName: \"Timber\", lastName: () => \"CONCAT('S', 'A', 'W')\" }) .execute(); This syntax doesn't escape your values, you need to handle escape on your own.","title":"Raw SQL support"},{"location":"internals/","text":"Internals This guide explains how things are working in TypeORM. It will be useful for our contributors. TBD.","title":"Internals"},{"location":"internals/#internals","text":"This guide explains how things are working in TypeORM. It will be useful for our contributors. TBD.","title":"Internals"},{"location":"listeners-and-subscribers/","text":"Entity Listeners and Subscribers What is an Entity Listener @AfterLoad @BeforeInsert @AfterInsert @BeforeUpdate @AfterUpdate @BeforeRemove @AfterRemove What is a Subscriber What is an Entity Listener Any of your entities can have methods with custom logic that listen to specific entity events. You must mark those methods with special decorators depending on what event you want to listen to. @AfterLoad You can define a method with any name in entity and mark it with @AfterLoad and TypeORM will call it each time the entity is loaded using QueryBuilder or repository/manager find methods. Example: @Entity() export class Post { @AfterLoad() updateCounters() { if (this.likesCount === undefined) this.likesCount = 0; } } @BeforeInsert You can define a method with any name in entity and mark it with @BeforeInsert and TypeORM will call it before the entity is inserted using repository/manager save . Example: @Entity() export class Post { @BeforeInsert() updateDates() { this.createdDate = new Date(); } } @AfterInsert You can define a method with any name in entity and mark it with @AfterInsert and TypeORM will call it after the entity is inserted using repository/manager save . Example: @Entity() export class Post { @AfterInsert() resetCounters() { this.counters = 0; } } @BeforeUpdate You can define a method with any name in the entity and mark it with @BeforeUpdate and TypeORM will call it before an existing entity is updated using repository/manager save . Keep in mind, however, that this will occur only when information is changed in the model. If you run save without modifying anything from the model, @BeforeUpdate and @AfterUpdate will not run. Example: @Entity() export class Post { @BeforeUpdate() updateDates() { this.updatedDate = new Date(); } } @AfterUpdate You can define a method with any name in the entity and mark it with @AfterUpdate and TypeORM will call it after an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @AfterUpdate() updateCounters() { this.counter = 0; } } @BeforeRemove You can define a method with any name in the entity and mark it with @BeforeRemove and TypeORM will call it before a entity is removed using repository/manager remove . Example: @Entity() export class Post { @BeforeRemove() updateStatus() { this.status = \"removed\"; } } @AfterRemove You can define a method with any name in the entity and mark it with @AfterRemove and TypeORM will call it after the entity is removed using repository/manager remove . Example: @Entity() export class Post { @AfterRemove() updateStatus() { this.status = \"removed\"; } } What is a Subscriber Marks a class as an event subscriber which can listen to specific entity events or any entity events. Events are firing using QueryBuilder and repository/manager methods. Example: @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface<Post> { /** * Indicates that this subscriber only listen to Post events. */ listenTo() { return Post; } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<Post>) { console.log(`BEFORE POST INSERTED: `, event.entity); } } You can implement any method from EntitySubscriberInterface . To listen to any entity you just omit listenTo method and use any : @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface { /** * Called after entity is loaded. */ afterLoad(entity: any) { console.log(`AFTER ENTITY LOADED: `, entity); } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<any>) { console.log(`BEFORE POST INSERTED: `, event.entity); } /** * Called after entity insertion. */ afterInsert(event: InsertEvent<any>) { console.log(`AFTER ENTITY INSERTED: `, event.entity); } /** * Called before entity update. */ beforeUpdate(event: UpdateEvent<any>) { console.log(`BEFORE ENTITY UPDATED: `, event.entity); } /** * Called after entity update. */ afterUpdate(event: UpdateEvent<any>) { console.log(`AFTER ENTITY UPDATED: `, event.entity); } /** * Called before entity removal. */ beforeRemove(event: RemoveEvent<any>) { console.log(`BEFORE ENTITY WITH ID ${event.entityId} REMOVED: `, event.entity); } /** * Called after entity removal. */ afterRemove(event: RemoveEvent<any>) { console.log(`AFTER ENTITY WITH ID ${event.entityId} REMOVED: `, event.entity); } /** * Called before transaction start. */ beforeTransactionStart(event: TransactionStartEvent) { console.log(`BEFORE TRANSACTION STARTED: `, event); } /** * Called after transaction start. */ afterTransactionStart(event: TransactionStartEvent) { console.log(`AFTER TRANSACTION STARTED: `, event); } /** * Called before transaction commit. */ beforeTransactionCommit(event: TransactionCommitEvent) { console.log(`BEFORE TRANSACTION COMMITTED: `, event); } /** * Called after transaction commit. */ afterTransactionCommit(event: TransactionCommitEvent) { console.log(`AFTER TRANSACTION COMMITTED: `, event); } /** * Called before transaction rollback. */ beforeTransactionRollback(event: TransactionRollbackEvent) { console.log(`BEFORE TRANSACTION ROLLBACK: `, event); } /** * Called after transaction rollback. */ afterTransactionRollback(event: TransactionRollbackEvent) { console.log(`AFTER TRANSACTION ROLLBACK: `, event); } } Make sure your subscribers property is set in your Connection Options so TypeORM loads your subscriber.","title":"Entity Listeners and Subscribers"},{"location":"listeners-and-subscribers/#entity-listeners-and-subscribers","text":"What is an Entity Listener @AfterLoad @BeforeInsert @AfterInsert @BeforeUpdate @AfterUpdate @BeforeRemove @AfterRemove What is a Subscriber","title":"Entity Listeners and Subscribers"},{"location":"listeners-and-subscribers/#what-is-an-entity-listener","text":"Any of your entities can have methods with custom logic that listen to specific entity events. You must mark those methods with special decorators depending on what event you want to listen to.","title":"What is an Entity Listener"},{"location":"listeners-and-subscribers/#afterload","text":"You can define a method with any name in entity and mark it with @AfterLoad and TypeORM will call it each time the entity is loaded using QueryBuilder or repository/manager find methods. Example: @Entity() export class Post { @AfterLoad() updateCounters() { if (this.likesCount === undefined) this.likesCount = 0; } }","title":"@AfterLoad"},{"location":"listeners-and-subscribers/#beforeinsert","text":"You can define a method with any name in entity and mark it with @BeforeInsert and TypeORM will call it before the entity is inserted using repository/manager save . Example: @Entity() export class Post { @BeforeInsert() updateDates() { this.createdDate = new Date(); } }","title":"@BeforeInsert"},{"location":"listeners-and-subscribers/#afterinsert","text":"You can define a method with any name in entity and mark it with @AfterInsert and TypeORM will call it after the entity is inserted using repository/manager save . Example: @Entity() export class Post { @AfterInsert() resetCounters() { this.counters = 0; } }","title":"@AfterInsert"},{"location":"listeners-and-subscribers/#beforeupdate","text":"You can define a method with any name in the entity and mark it with @BeforeUpdate and TypeORM will call it before an existing entity is updated using repository/manager save . Keep in mind, however, that this will occur only when information is changed in the model. If you run save without modifying anything from the model, @BeforeUpdate and @AfterUpdate will not run. Example: @Entity() export class Post { @BeforeUpdate() updateDates() { this.updatedDate = new Date(); } }","title":"@BeforeUpdate"},{"location":"listeners-and-subscribers/#afterupdate","text":"You can define a method with any name in the entity and mark it with @AfterUpdate and TypeORM will call it after an existing entity is updated using repository/manager save . Example: @Entity() export class Post { @AfterUpdate() updateCounters() { this.counter = 0; } }","title":"@AfterUpdate"},{"location":"listeners-and-subscribers/#beforeremove","text":"You can define a method with any name in the entity and mark it with @BeforeRemove and TypeORM will call it before a entity is removed using repository/manager remove . Example: @Entity() export class Post { @BeforeRemove() updateStatus() { this.status = \"removed\"; } }","title":"@BeforeRemove"},{"location":"listeners-and-subscribers/#afterremove","text":"You can define a method with any name in the entity and mark it with @AfterRemove and TypeORM will call it after the entity is removed using repository/manager remove . Example: @Entity() export class Post { @AfterRemove() updateStatus() { this.status = \"removed\"; } }","title":"@AfterRemove"},{"location":"listeners-and-subscribers/#what-is-a-subscriber","text":"Marks a class as an event subscriber which can listen to specific entity events or any entity events. Events are firing using QueryBuilder and repository/manager methods. Example: @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface<Post> { /** * Indicates that this subscriber only listen to Post events. */ listenTo() { return Post; } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<Post>) { console.log(`BEFORE POST INSERTED: `, event.entity); } } You can implement any method from EntitySubscriberInterface . To listen to any entity you just omit listenTo method and use any : @EventSubscriber() export class PostSubscriber implements EntitySubscriberInterface { /** * Called after entity is loaded. */ afterLoad(entity: any) { console.log(`AFTER ENTITY LOADED: `, entity); } /** * Called before post insertion. */ beforeInsert(event: InsertEvent<any>) { console.log(`BEFORE POST INSERTED: `, event.entity); } /** * Called after entity insertion. */ afterInsert(event: InsertEvent<any>) { console.log(`AFTER ENTITY INSERTED: `, event.entity); } /** * Called before entity update. */ beforeUpdate(event: UpdateEvent<any>) { console.log(`BEFORE ENTITY UPDATED: `, event.entity); } /** * Called after entity update. */ afterUpdate(event: UpdateEvent<any>) { console.log(`AFTER ENTITY UPDATED: `, event.entity); } /** * Called before entity removal. */ beforeRemove(event: RemoveEvent<any>) { console.log(`BEFORE ENTITY WITH ID ${event.entityId} REMOVED: `, event.entity); } /** * Called after entity removal. */ afterRemove(event: RemoveEvent<any>) { console.log(`AFTER ENTITY WITH ID ${event.entityId} REMOVED: `, event.entity); } /** * Called before transaction start. */ beforeTransactionStart(event: TransactionStartEvent) { console.log(`BEFORE TRANSACTION STARTED: `, event); } /** * Called after transaction start. */ afterTransactionStart(event: TransactionStartEvent) { console.log(`AFTER TRANSACTION STARTED: `, event); } /** * Called before transaction commit. */ beforeTransactionCommit(event: TransactionCommitEvent) { console.log(`BEFORE TRANSACTION COMMITTED: `, event); } /** * Called after transaction commit. */ afterTransactionCommit(event: TransactionCommitEvent) { console.log(`AFTER TRANSACTION COMMITTED: `, event); } /** * Called before transaction rollback. */ beforeTransactionRollback(event: TransactionRollbackEvent) { console.log(`BEFORE TRANSACTION ROLLBACK: `, event); } /** * Called after transaction rollback. */ afterTransactionRollback(event: TransactionRollbackEvent) { console.log(`AFTER TRANSACTION ROLLBACK: `, event); } } Make sure your subscribers property is set in your Connection Options so TypeORM loads your subscriber.","title":"What is a Subscriber"},{"location":"logging/","text":"Logging Enabling logging Logging options Log long-running queries Changing default logger Using custom logger Enabling logging You can enable logging of all queries and errors by simply setting logging: true in your connection options: { name: \"mysql\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", ... logging: true } Logging options You can enable different types of logging in connection options: { host: \"localhost\", ... logging: [\"query\", \"error\"] } If you want to enable logging of failed queries only then only add error : { host: \"localhost\", ... logging: [\"error\"] } There are other options you can use: query - logs all queries. error - logs all failed queries and errors. schema - logs the schema build process. warn - logs internal orm warnings. info - logs internal orm informative messages. log - logs internal orm log messages. You can specify as many options as needed. If you want to enable all logging you can simply specify logging: \"all\" : { host: \"localhost\", ... logging: \"all\" } Log long-running queries If you have performance issues, you can log queries that take too much time to execute by setting maxQueryExecutionTime in connection options: { host: \"localhost\", ... maxQueryExecutionTime: 1000 } This code will log all queries which run more then 1 second . Changing default logger TypeORM ships with 4 different types of logger: advanced-console - this is the default logger which logs all messages into the console using color and sql syntax highlighting (using chalk ). simple-console - this is a simple console logger which is exactly the same as the advanced logger, but it does not use any color highlighting. This logger can be used if you have problems / or don't like colorized logs. file - this logger writes all logs into ormlogs.log in the root folder of your project (near package.json and ormconfig.json ). debug - this logger uses debug package , to turn on logging set your env variable DEBUG=typeorm:* (note logging option has no effect on this logger). You can enable any of them in connection options: { host: \"localhost\", ... logging: true, logger: \"file\" } Using custom logger You can create your own logger class by implementing the Logger interface: import {Logger} from \"typeorm\"; export class MyCustomLogger implements Logger { // implement all methods from logger class } And specify it in connection options: import {createConnection} from \"typeorm\"; import {MyCustomLogger} from \"./logger/MyCustomLogger\"; createConnection({ name: \"mysql\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", logger: new MyCustomLogger() }); If you defined your connection options in the ormconfig file, then you can use it and override it in the following way: import {createConnection, getConnectionOptions} from \"typeorm\"; import {MyCustomLogger} from \"./logger/MyCustomLogger\"; // getConnectionOptions will read options from your ormconfig file // and return it in connectionOptions object // then you can simply append additional properties to it getConnectionOptions().then(connectionOptions => { return createConnection(Object.assign(connectionOptions, { logger: new MyCustomLogger() })) }); Logger methods can accept QueryRunner when it's available. It's helpful if you want to log additional data. Also, via query runner, you can get access to additional data passed during persist/remove. For example: // user sends request during entity save postRepository.save(post, { data: { request: request } }); // in logger you can access it this way: logQuery(query: string, parameters?: any[], queryRunner?: QueryRunner) { const requestUrl = queryRunner && queryRunner.data[\"request\"] ? \"(\" + queryRunner.data[\"request\"].url + \") \" : \"\"; console.log(requestUrl + \"executing query: \" + query); }","title":"Logging"},{"location":"logging/#logging","text":"Enabling logging Logging options Log long-running queries Changing default logger Using custom logger","title":"Logging"},{"location":"logging/#enabling-logging","text":"You can enable logging of all queries and errors by simply setting logging: true in your connection options: { name: \"mysql\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", ... logging: true }","title":"Enabling logging"},{"location":"logging/#logging-options","text":"You can enable different types of logging in connection options: { host: \"localhost\", ... logging: [\"query\", \"error\"] } If you want to enable logging of failed queries only then only add error : { host: \"localhost\", ... logging: [\"error\"] } There are other options you can use: query - logs all queries. error - logs all failed queries and errors. schema - logs the schema build process. warn - logs internal orm warnings. info - logs internal orm informative messages. log - logs internal orm log messages. You can specify as many options as needed. If you want to enable all logging you can simply specify logging: \"all\" : { host: \"localhost\", ... logging: \"all\" }","title":"Logging options"},{"location":"logging/#log-long-running-queries","text":"If you have performance issues, you can log queries that take too much time to execute by setting maxQueryExecutionTime in connection options: { host: \"localhost\", ... maxQueryExecutionTime: 1000 } This code will log all queries which run more then 1 second .","title":"Log long-running queries"},{"location":"logging/#changing-default-logger","text":"TypeORM ships with 4 different types of logger: advanced-console - this is the default logger which logs all messages into the console using color and sql syntax highlighting (using chalk ). simple-console - this is a simple console logger which is exactly the same as the advanced logger, but it does not use any color highlighting. This logger can be used if you have problems / or don't like colorized logs. file - this logger writes all logs into ormlogs.log in the root folder of your project (near package.json and ormconfig.json ). debug - this logger uses debug package , to turn on logging set your env variable DEBUG=typeorm:* (note logging option has no effect on this logger). You can enable any of them in connection options: { host: \"localhost\", ... logging: true, logger: \"file\" }","title":"Changing default logger"},{"location":"logging/#using-custom-logger","text":"You can create your own logger class by implementing the Logger interface: import {Logger} from \"typeorm\"; export class MyCustomLogger implements Logger { // implement all methods from logger class } And specify it in connection options: import {createConnection} from \"typeorm\"; import {MyCustomLogger} from \"./logger/MyCustomLogger\"; createConnection({ name: \"mysql\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", logger: new MyCustomLogger() }); If you defined your connection options in the ormconfig file, then you can use it and override it in the following way: import {createConnection, getConnectionOptions} from \"typeorm\"; import {MyCustomLogger} from \"./logger/MyCustomLogger\"; // getConnectionOptions will read options from your ormconfig file // and return it in connectionOptions object // then you can simply append additional properties to it getConnectionOptions().then(connectionOptions => { return createConnection(Object.assign(connectionOptions, { logger: new MyCustomLogger() })) }); Logger methods can accept QueryRunner when it's available. It's helpful if you want to log additional data. Also, via query runner, you can get access to additional data passed during persist/remove. For example: // user sends request during entity save postRepository.save(post, { data: { request: request } }); // in logger you can access it this way: logQuery(query: string, parameters?: any[], queryRunner?: QueryRunner) { const requestUrl = queryRunner && queryRunner.data[\"request\"] ? \"(\" + queryRunner.data[\"request\"].url + \") \" : \"\"; console.log(requestUrl + \"executing query: \" + query); }","title":"Using custom logger"},{"location":"many-to-many-relations/","text":"Many-to-many relations What are many-to-many relations Saving many-to-many relations Deleting many-to-many relations Loading many-to-many relations bi-directional relations many-to-many relations with custom properties What are many-to-many relations Many-to-many is a relation where A contains multiple instances of B, and B contain multiple instances of A. Let's take for example Question and Category entities. A question can have multiple categories, and each category can have multiple questions. import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(() => Category) @JoinTable() categories: Category[]; } @JoinTable() is required for @ManyToMany relations. You must put @JoinTable on one (owning) side of relation. This example will produce following tables: +-------------+--------------+----------------------------+ | category | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | question | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | title | varchar(255) | | | text | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | question_categories_category | +-------------+--------------+----------------------------+ | questionId | int(11) | PRIMARY KEY FOREIGN KEY | | categoryId | int(11) | PRIMARY KEY FOREIGN KEY | +-------------+--------------+----------------------------+ Saving many-to-many relations With cascades enabled, you can save this relation with only one save call. const category1 = new Category(); category1.name = \"animals\"; await connection.manager.save(category1); const category2 = new Category(); category2.name = \"zoo\"; await connection.manager.save(category2); const question = new Question(); question.title = \"dogs\"; question.text = \"who let the dogs out?\"; question.categories = [category1, category2]; await connection.manager.save(question); Deleting many-to-many relations With cascades enabled, you can delete this relation with only one save call. To delete a many-to-many relationship between two records, remove it from the corresponding field and save the record. const question = getRepository(Question); question.categories = question.categories.filter(category => { return category.id !== categoryToRemove.id }) await connection.manager.save(question) This will only remove the record in the join table. The question and categoryToRemove records will still exist. Soft Deleting a relationship with cascade This example shows how the cascading soft delete behaves: const category1 = new Category(); category1.name = \"animals\"; const category2 = new Category(); category2.name = \"zoo\"; const question = new Question(); question.categories = [category1, category2]; const newQuestion = await connection.manager.save(question); await connection.manager.softRemove(newQuestion); In this example we did not call save or softRemove for category1 and category2, but they will be automatically saved and soft-deleted when the cascade of relation options is set to true like this: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @ManyToMany(() => Category, category => category.questions, { cascade: true }) @JoinTable() categories: Category[]; } Loading many-to-many relations To load questions with categories inside you must specify the relation in FindOptions : const questionRepository = connection.getRepository(Question); const questions = await questionRepository.find({ relations: [\"categories\"] }); Or using QueryBuilder you can join them: const questions = await connection .getRepository(Question) .createQueryBuilder(\"question\") .leftJoinAndSelect(\"question.categories\", \"category\") .getMany(); When using FindOptions you don't need to specify eager relations - they are always automatically loaded. bi-directional relations Relations can be uni-directional and bi-directional. Uni-directional relations are relations with a relation decorator only on one side. Bi-directional relations are relations with decorators on both sides of a relation. We just created a uni-directional relation. Let's make it bi-directional: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(() => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(() => Category, category => category.questions) @JoinTable() categories: Category[]; } We just made our relation bi-directional. Note that the inverse relation does not have a @JoinTable . @JoinTable must be only on one side of the relation. Bi-directional relations allow you to join relations from both sides using QueryBuilder : const categoriesWithQuestions = await connection .getRepository(Category) .createQueryBuilder(\"category\") .leftJoinAndSelect(\"category.questions\", \"question\") .getMany(); many-to-many relations with custom properties In case you need to have additional properties in your many-to-many relationship, you have to create a new entity yourself. For example, if you would like entities Post and Category to have a many-to-many relationship with an additional order column, then you need to create an entity PostToCategory with two ManyToOne relations pointing in both directions and with custom columns in it: import { Entity, Column, ManyToOne, PrimaryGeneratedColumn } from \"typeorm\"; import { Post } from \"./post\"; import { Category } from \"./category\"; @Entity() export class PostToCategory { @PrimaryGeneratedColumn() public postToCategoryId!: number; @Column() public postId!: number; @Column() public categoryId!: number; @Column() public order!: number; @ManyToOne(() => Post, post => post.postToCategories) public post!: Post; @ManyToOne(() => Category, category => category.postToCategories) public category!: Category; } Additionally you will have to add a relationship like the following to Post and Category : // category.ts ... @OneToMany(() => PostToCategory, postToCategory => postToCategory.category) public postToCategories!: PostToCategory[]; // post.ts ... @OneToMany(() => PostToCategory, postToCategory => postToCategory.post) public postToCategories!: PostToCategory[];","title":"Many-to-many relations"},{"location":"many-to-many-relations/#many-to-many-relations","text":"What are many-to-many relations Saving many-to-many relations Deleting many-to-many relations Loading many-to-many relations bi-directional relations many-to-many relations with custom properties","title":"Many-to-many relations"},{"location":"many-to-many-relations/#what-are-many-to-many-relations","text":"Many-to-many is a relation where A contains multiple instances of B, and B contain multiple instances of A. Let's take for example Question and Category entities. A question can have multiple categories, and each category can have multiple questions. import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(() => Category) @JoinTable() categories: Category[]; } @JoinTable() is required for @ManyToMany relations. You must put @JoinTable on one (owning) side of relation. This example will produce following tables: +-------------+--------------+----------------------------+ | category | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | question | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | title | varchar(255) | | | text | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | question_categories_category | +-------------+--------------+----------------------------+ | questionId | int(11) | PRIMARY KEY FOREIGN KEY | | categoryId | int(11) | PRIMARY KEY FOREIGN KEY | +-------------+--------------+----------------------------+","title":"What are many-to-many relations"},{"location":"many-to-many-relations/#saving-many-to-many-relations","text":"With cascades enabled, you can save this relation with only one save call. const category1 = new Category(); category1.name = \"animals\"; await connection.manager.save(category1); const category2 = new Category(); category2.name = \"zoo\"; await connection.manager.save(category2); const question = new Question(); question.title = \"dogs\"; question.text = \"who let the dogs out?\"; question.categories = [category1, category2]; await connection.manager.save(question);","title":"Saving many-to-many relations"},{"location":"many-to-many-relations/#deleting-many-to-many-relations","text":"With cascades enabled, you can delete this relation with only one save call. To delete a many-to-many relationship between two records, remove it from the corresponding field and save the record. const question = getRepository(Question); question.categories = question.categories.filter(category => { return category.id !== categoryToRemove.id }) await connection.manager.save(question) This will only remove the record in the join table. The question and categoryToRemove records will still exist.","title":"Deleting many-to-many relations"},{"location":"many-to-many-relations/#soft-deleting-a-relationship-with-cascade","text":"This example shows how the cascading soft delete behaves: const category1 = new Category(); category1.name = \"animals\"; const category2 = new Category(); category2.name = \"zoo\"; const question = new Question(); question.categories = [category1, category2]; const newQuestion = await connection.manager.save(question); await connection.manager.softRemove(newQuestion); In this example we did not call save or softRemove for category1 and category2, but they will be automatically saved and soft-deleted when the cascade of relation options is set to true like this: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @ManyToMany(() => Category, category => category.questions, { cascade: true }) @JoinTable() categories: Category[]; }","title":"Soft Deleting a relationship with cascade"},{"location":"many-to-many-relations/#loading-many-to-many-relations","text":"To load questions with categories inside you must specify the relation in FindOptions : const questionRepository = connection.getRepository(Question); const questions = await questionRepository.find({ relations: [\"categories\"] }); Or using QueryBuilder you can join them: const questions = await connection .getRepository(Question) .createQueryBuilder(\"question\") .leftJoinAndSelect(\"question.categories\", \"category\") .getMany(); When using FindOptions you don't need to specify eager relations - they are always automatically loaded.","title":"Loading many-to-many relations"},{"location":"many-to-many-relations/#bi-directional-relations","text":"Relations can be uni-directional and bi-directional. Uni-directional relations are relations with a relation decorator only on one side. Bi-directional relations are relations with decorators on both sides of a relation. We just created a uni-directional relation. Let's make it bi-directional: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(() => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(() => Category, category => category.questions) @JoinTable() categories: Category[]; } We just made our relation bi-directional. Note that the inverse relation does not have a @JoinTable . @JoinTable must be only on one side of the relation. Bi-directional relations allow you to join relations from both sides using QueryBuilder : const categoriesWithQuestions = await connection .getRepository(Category) .createQueryBuilder(\"category\") .leftJoinAndSelect(\"category.questions\", \"question\") .getMany();","title":"bi-directional relations"},{"location":"many-to-many-relations/#many-to-many-relations-with-custom-properties","text":"In case you need to have additional properties in your many-to-many relationship, you have to create a new entity yourself. For example, if you would like entities Post and Category to have a many-to-many relationship with an additional order column, then you need to create an entity PostToCategory with two ManyToOne relations pointing in both directions and with custom columns in it: import { Entity, Column, ManyToOne, PrimaryGeneratedColumn } from \"typeorm\"; import { Post } from \"./post\"; import { Category } from \"./category\"; @Entity() export class PostToCategory { @PrimaryGeneratedColumn() public postToCategoryId!: number; @Column() public postId!: number; @Column() public categoryId!: number; @Column() public order!: number; @ManyToOne(() => Post, post => post.postToCategories) public post!: Post; @ManyToOne(() => Category, category => category.postToCategories) public category!: Category; } Additionally you will have to add a relationship like the following to Post and Category : // category.ts ... @OneToMany(() => PostToCategory, postToCategory => postToCategory.category) public postToCategories!: PostToCategory[]; // post.ts ... @OneToMany(() => PostToCategory, postToCategory => postToCategory.post) public postToCategories!: PostToCategory[];","title":"many-to-many relations with custom properties"},{"location":"many-to-one-one-to-many-relations/","text":"Many-to-one / one-to-many relations Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only one single user. import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(() => User, user => user.photos) user: User; } import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(() => Photo, photo => photo.user) photos: Photo[]; } Here we added @OneToMany to the photos property and specified the target relation type to be Photo . You can omit @JoinColumn in a @ManyToOne / @OneToMany relation. @OneToMany cannot exist without @ManyToOne . If you want to use @OneToMany , @ManyToOne is required. However, the inverse is not required: If you only care about the @ManyToOne relationship, you can define it without having @OneToMany on the related entity. Where you set @ManyToOne - its related entity will have \"relation id\" and foreign key. This example will produce following tables: +-------------+--------------+----------------------------+ | photo | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | url | varchar(255) | | | userId | int(11) | FOREIGN KEY | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | +-------------+--------------+----------------------------+ Example how to save such relation: const photo1 = new Photo(); photo1.url = \"me.jpg\"; await connection.manager.save(photo1); const photo2 = new Photo(); photo2.url = \"me-and-bears.jpg\"; await connection.manager.save(photo2); const user = new User(); user.name = \"John\"; user.photos = [photo1, photo2]; await connection.manager.save(user); or alternatively you can do: const user = new User(); user.name = \"Leo\"; await connection.manager.save(user); const photo1 = new Photo(); photo1.url = \"me.jpg\"; photo1.user = user; await connection.manager.save(photo1); const photo2 = new Photo(); photo2.url = \"me-and-bears.jpg\"; photo2.user = user; await connection.manager.save(photo2); With cascades enabled you can save this relation with only one save call. To load a user with photos inside you must specify the relation in FindOptions : const userRepository = connection.getRepository(User); const users = await userRepository.find({ relations: [\"photos\"] }); // or from inverse side const photoRepository = connection.getRepository(Photo); const photos = await photoRepository.find({ relations: [\"user\"] }); Or using QueryBuilder you can join them: const users = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .getMany(); // or from inverse side const photos = await connection .getRepository(Photo) .createQueryBuilder(\"photo\") .leftJoinAndSelect(\"photo.user\", \"user\") .getMany(); With eager loading enabled on a relation you don't have to specify relation or join it - it will ALWAYS be loaded automatically.","title":"Many-to-one / one-to-many relations"},{"location":"many-to-one-one-to-many-relations/#many-to-one-one-to-many-relations","text":"Many-to-one / one-to-many is a relation where A contains multiple instances of B, but B contains only one instance of A. Let's take for example User and Photo entities. User can have multiple photos, but each photo is owned by only one single user. import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(() => User, user => user.photos) user: User; } import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(() => Photo, photo => photo.user) photos: Photo[]; } Here we added @OneToMany to the photos property and specified the target relation type to be Photo . You can omit @JoinColumn in a @ManyToOne / @OneToMany relation. @OneToMany cannot exist without @ManyToOne . If you want to use @OneToMany , @ManyToOne is required. However, the inverse is not required: If you only care about the @ManyToOne relationship, you can define it without having @OneToMany on the related entity. Where you set @ManyToOne - its related entity will have \"relation id\" and foreign key. This example will produce following tables: +-------------+--------------+----------------------------+ | photo | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | url | varchar(255) | | | userId | int(11) | FOREIGN KEY | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | +-------------+--------------+----------------------------+ Example how to save such relation: const photo1 = new Photo(); photo1.url = \"me.jpg\"; await connection.manager.save(photo1); const photo2 = new Photo(); photo2.url = \"me-and-bears.jpg\"; await connection.manager.save(photo2); const user = new User(); user.name = \"John\"; user.photos = [photo1, photo2]; await connection.manager.save(user); or alternatively you can do: const user = new User(); user.name = \"Leo\"; await connection.manager.save(user); const photo1 = new Photo(); photo1.url = \"me.jpg\"; photo1.user = user; await connection.manager.save(photo1); const photo2 = new Photo(); photo2.url = \"me-and-bears.jpg\"; photo2.user = user; await connection.manager.save(photo2); With cascades enabled you can save this relation with only one save call. To load a user with photos inside you must specify the relation in FindOptions : const userRepository = connection.getRepository(User); const users = await userRepository.find({ relations: [\"photos\"] }); // or from inverse side const photoRepository = connection.getRepository(Photo); const photos = await photoRepository.find({ relations: [\"user\"] }); Or using QueryBuilder you can join them: const users = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .getMany(); // or from inverse side const photos = await connection .getRepository(Photo) .createQueryBuilder(\"photo\") .leftJoinAndSelect(\"photo.user\", \"user\") .getMany(); With eager loading enabled on a relation you don't have to specify relation or join it - it will ALWAYS be loaded automatically.","title":"Many-to-one / one-to-many relations"},{"location":"migrations/","text":"Migrations How migrations work Creating a new migration Running and reverting migrations Generating migrations Connection option Using migration API to write migrations How migrations work Once you get into production you'll need to synchronize model changes into the database. Typically it is unsafe to use synchronize: true for schema synchronization on production once you get data in your database. Here is where migrations come to help. A migration is just a single file with sql queries to update a database schema and apply new changes to an existing database. Let's say you already have a database and a post entity: import { Entity, Column, PrimaryGeneratedColumn } from 'typeorm'; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; } And your entity worked in production for months without any changes. You have thousands of posts in your database. Now you need to make a new release and rename title to name . What would you do? You need to create a new migration with the following sql query (postgres dialect): ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"; Once you run this sql query your database schema is ready to work with your new codebase. TypeORM provides a place where you can write such sql queries and run them when needed. This place is called \"migrations\". Creating a new migration Pre-requisites : Installing CLI Before creating a new migration you need to setup your connection options properly: { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\", \"entities\": [\"entity/*.js\"], \"migrationsTableName\": \"custom_migration_table\", \"migrations\": [\"migration/*.js\"], \"cli\": { \"migrationsDir\": \"migration\" } } Here we setup three options: * \"migrationsTableName\": \"migrations\" - Specify this option only if you need migration table name to be different from \"migrations\" . * \"migrations\": [\"migration/*.js\"] - indicates that typeorm must load migrations from the given \"migration\" directory. * \"cli\": { \"migrationsDir\": \"migration\" } - indicates that the CLI must create new migrations in the \"migration\" directory. Once you setup connection options you can create a new migration using CLI: typeorm migration:create -n PostRefactoring Here, PostRefactoring is the name of the migration - you can specify any name you want. After you run the command you can see a new file generated in the \"migration\" directory named {TIMESTAMP}-PostRefactoring.ts where {TIMESTAMP} is the current timestamp when the migration was generated. Now you can open the file and add your migration sql queries there. You should see the following content inside your migration: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { } async down(queryRunner: QueryRunner): Promise<void> { } } There are two methods you must fill with your migration code: up and down . up has to contain the code you need to perform the migration. down has to revert whatever up changed. down method is used to revert the last migration. Inside both up and down you have a QueryRunner object. All database operations are executed using this object. Learn more about query runner . Let's see what the migration looks like with our Post changes: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" RENAME COLUMN \"title\" TO \"name\"`); } async down(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" RENAME COLUMN \"name\" TO \"title\"`); // reverts things made in \"up\" method } } Running and reverting migrations Once you have a migration to run on production, you can run them using a CLI command: typeorm migration:run typeorm migration:create and typeorm migration:generate will create .ts files, unless you use the o flag (see more in Generating migrations ). The migration:run and migration:revert commands only work on .js files. Thus the typescript files need to be compiled before running the commands. Alternatively you can use ts-node in conjunction with typeorm to run .ts migration files. Example with ts-node : ts-node --transpile-only ./node_modules/typeorm/cli.js migration:run Example ts-node not using node_modules directly: ts-node $(yarn bin typeorm) migration:run This command will execute all pending migrations and run them in a sequence ordered by their timestamps. This means all sql queries written in the up methods of your created migrations will be executed. That's all! Now you have your database schema up-to-date. If for some reason you want to revert the changes, you can run: typeorm migration:revert This command will execute down in the latest executed migration. If you need to revert multiple migrations you must call this command multiple times. Generating migrations TypeORM is able to automatically generate migration files with schema changes you made. Let's say you have a Post entity with a title column, and you have changed the name title to name . You can run following command: typeorm migration:generate -n PostRefactoring And it will generate a new migration called {TIMESTAMP}-PostRefactoring.ts with the following content: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } async down(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"name\" RENAME TO \"title\"`); } } Alternatively you can also output your migrations as Javascript files using the o (alias for --outputJs ) flag. This is useful for Javascript only projects in which TypeScript additional packages are not installed. This command, will generate a new migration file {TIMESTAMP}-PostRefactoring.js with the following content: const { MigrationInterface, QueryRunner } = require(\"typeorm\"); module.exports = class PostRefactoringTIMESTAMP { async up(queryRunner) { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } async down(queryRunner) { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } } See, you don't need to write the queries on your own. The rule of thumb for generating migrations is that you generate them after each change you made to your models. To apply multi-line formatting to your generated migration queries, use the p (alias for --pretty ) flag. Connection option If you need to run/revert your migrations for another connection rather than the default, use the -c (alias for --connection ) and pass the config name as an argument typeorm -c <your-config-name> migration:{run|revert} Using migration API to write migrations In order to use an API to change a database schema you can use QueryRunner . Example: import {MigrationInterface, QueryRunner, Table, TableIndex, TableColumn, TableForeignKey } from \"typeorm\"; export class QuestionRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.createTable(new Table({ name: \"question\", columns: [ { name: \"id\", type: \"int\", isPrimary: true }, { name: \"name\", type: \"varchar\", } ] }), true) await queryRunner.createIndex(\"question\", new TableIndex({ name: \"IDX_QUESTION_NAME\", columnNames: [\"name\"] })); await queryRunner.createTable(new Table({ name: \"answer\", columns: [ { name: \"id\", type: \"int\", isPrimary: true }, { name: \"name\", type: \"varchar\", }, { name: 'created_at', type: 'timestamp', default: 'now()' } ] }), true); await queryRunner.addColumn(\"answer\", new TableColumn({ name: \"questionId\", type: \"int\" })); await queryRunner.createForeignKey(\"answer\", new TableForeignKey({ columnNames: [\"questionId\"], referencedColumnNames: [\"id\"], referencedTableName: \"question\", onDelete: \"CASCADE\" })); } async down(queryRunner: QueryRunner): Promise<void> { const table = await queryRunner.getTable(\"answer\"); const foreignKey = table.foreignKeys.find(fk => fk.columnNames.indexOf(\"questionId\") !== -1); await queryRunner.dropForeignKey(\"answer\", foreignKey); await queryRunner.dropColumn(\"answer\", \"questionId\"); await queryRunner.dropTable(\"answer\"); await queryRunner.dropIndex(\"question\", \"IDX_QUESTION_NAME\"); await queryRunner.dropTable(\"question\"); } } getDatabases(): Promise<string[]> Returns all available database names including system databases. getSchemas(database?: string): Promise<string[]> database - If database parameter specified, returns schemas of that database Returns all available schema names including system schemas. Useful for SQLServer and Postgres only. getTable(tableName: string): Promise<Table|undefined> tableName - name of a table to be loaded Loads a table by a given name from the database. getTables(tableNames: string[]): Promise<Table[]> tableNames - name of a tables to be loaded Loads a tables by a given names from the database. hasDatabase(database: string): Promise<boolean> database - name of a database to be checked Checks if database with the given name exist. hasSchema(schema: string): Promise<boolean> schema - name of a schema to be checked Checks if schema with the given name exist. Used only for SqlServer and Postgres. hasTable(table: Table|string): Promise<boolean> table - Table object or name Checks if table exist. hasColumn(table: Table|string, columnName: string): Promise<boolean> table - Table object or name columnName - name of a column to be checked Checks if column exist in the table. createDatabase(database: string, ifNotExist?: boolean): Promise<void> database - database name ifNotExist - skips creation if true , otherwise throws error if database already exist Creates a new database. dropDatabase(database: string, ifExist?: boolean): Promise<void> database - database name ifExist - skips deletion if true , otherwise throws error if database was not found Drops database. createSchema(schemaPath: string, ifNotExist?: boolean): Promise<void> schemaPath - schema name. For SqlServer can accept schema path (e.g. 'dbName.schemaName') as parameter. If schema path passed, it will create schema in specified database ifNotExist - skips creation if true , otherwise throws error if schema already exist Creates a new table schema. dropSchema(schemaPath: string, ifExist?: boolean, isCascade?: boolean): Promise<void> schemaPath - schema name. For SqlServer can accept schema path (e.g. 'dbName.schemaName') as parameter. If schema path passed, it will drop schema in specified database ifExist - skips deletion if true , otherwise throws error if schema was not found isCascade - If true , automatically drop objects (tables, functions, etc.) that are contained in the schema. Used only in Postgres. Drops a table schema. createTable(table: Table, ifNotExist?: boolean, createForeignKeys?: boolean, createIndices?: boolean): Promise<void> table - Table object. ifNotExist - skips creation if true , otherwise throws error if table already exist. Default false createForeignKeys - indicates whether foreign keys will be created on table creation. Default true createIndices - indicates whether indices will be created on table creation. Default true Creates a new table. dropTable(table: Table|string, ifExist?: boolean, dropForeignKeys?: boolean, dropIndices?: boolean): Promise<void> table - Table object or table name to be dropped ifExist - skips dropping if true , otherwise throws error if table does not exist dropForeignKeys - indicates whether foreign keys will be dropped on table deletion. Default true dropIndices - indicates whether indices will be dropped on table deletion. Default true Drops a table. renameTable(oldTableOrName: Table|string, newTableName: string): Promise<void> oldTableOrName - old Table object or name to be renamed newTableName - new table name Renames a table. addColumn(table: Table|string, column: TableColumn): Promise<void> table - Table object or name column - new column Adds a new column. addColumns(table: Table|string, columns: TableColumn[]): Promise<void> table - Table object or name columns - new columns Adds a new column. renameColumn(table: Table|string, oldColumnOrName: TableColumn|string, newColumnOrName: TableColumn|string): Promise<void> table - Table object or name oldColumnOrName - old column. Accepts TableColumn object or column name newColumnOrName - new column. Accepts TableColumn object or column name Renames a column. changeColumn(table: Table|string, oldColumn: TableColumn|string, newColumn: TableColumn): Promise<void> table - Table object or name oldColumn - old column. Accepts TableColumn object or column name newColumn - new column. Accepts TableColumn object Changes a column in the table. changeColumns(table: Table|string, changedColumns: { oldColumn: TableColumn, newColumn: TableColumn }[]): Promise<void> table - Table object or name changedColumns - array of changed columns. oldColumn - old TableColumn object newColumn - new TableColumn object Changes a columns in the table. dropColumn(table: Table|string, column: TableColumn|string): Promise<void> table - Table object or name column - TableColumn object or column name to be dropped Drops a column in the table. dropColumns(table: Table|string, columns: TableColumn[]|string[]): Promise<void> table - Table object or name columns - array of TableColumn objects or column names to be dropped Drops a columns in the table. createPrimaryKey(table: Table|string, columnNames: string[]): Promise<void> table - Table object or name columnNames - array of column names which will be primary Creates a new primary key. updatePrimaryKeys(table: Table|string, columns: TableColumn[]): Promise<void> table - Table object or name columns - array of TableColumn objects which will be updated Updates composite primary keys. dropPrimaryKey(table: Table|string): Promise<void> table - Table object or name Drops a primary key. createUniqueConstraint(table: Table|string, uniqueConstraint: TableUnique): Promise<void> table - Table object or name uniqueConstraint - TableUnique object to be created Creates new unique constraint. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use createIndex() method instead. createUniqueConstraints(table: Table|string, uniqueConstraints: TableUnique[]): Promise<void> table - Table object or name uniqueConstraints - array of TableUnique objects to be created Creates new unique constraints. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use createIndices() method instead. dropUniqueConstraint(table: Table|string, uniqueOrName: TableUnique|string): Promise<void> table - Table object or name uniqueOrName - TableUnique object or unique constraint name to be dropped Drops an unique constraint. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use dropIndex() method instead. dropUniqueConstraints(table: Table|string, uniqueConstraints: TableUnique[]): Promise<void> table - Table object or name uniqueConstraints - array of TableUnique objects to be dropped Drops an unique constraints. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use dropIndices() method instead. createCheckConstraint(table: Table|string, checkConstraint: TableCheck): Promise<void> table - Table object or name checkConstraint - TableCheck object Creates new check constraint. Note: MySQL does not support check constraints. createCheckConstraints(table: Table|string, checkConstraints: TableCheck[]): Promise<void> table - Table object or name checkConstraints - array of TableCheck objects Creates new check constraint. Note: MySQL does not support check constraints. dropCheckConstraint(table: Table|string, checkOrName: TableCheck|string): Promise<void> table - Table object or name checkOrName - TableCheck object or check constraint name Drops check constraint. Note: MySQL does not support check constraints. dropCheckConstraints(table: Table|string, checkConstraints: TableCheck[]): Promise<void> table - Table object or name checkConstraints - array of TableCheck objects Drops check constraints. Note: MySQL does not support check constraints. createForeignKey(table: Table|string, foreignKey: TableForeignKey): Promise<void> table - Table object or name foreignKey - TableForeignKey object Creates a new foreign key. createForeignKeys(table: Table|string, foreignKeys: TableForeignKey[]): Promise<void> table - Table object or name foreignKeys - array of TableForeignKey objects Creates a new foreign keys. dropForeignKey(table: Table|string, foreignKeyOrName: TableForeignKey|string): Promise<void> table - Table object or name foreignKeyOrName - TableForeignKey object or foreign key name Drops a foreign key. dropForeignKeys(table: Table|string, foreignKeys: TableForeignKey[]): Promise<void> table - Table object or name foreignKeys - array of TableForeignKey objects Drops a foreign keys. createIndex(table: Table|string, index: TableIndex): Promise<void> table - Table object or name index - TableIndex object Creates a new index. createIndices(table: Table|string, indices: TableIndex[]): Promise<void> table - Table object or name indices - array of TableIndex objects Creates a new indices. dropIndex(table: Table|string, index: TableIndex|string): Promise<void> table - Table object or name index - TableIndex object or index name Drops an index. dropIndices(table: Table|string, indices: TableIndex[]): Promise<void> table - Table object or name indices - array of TableIndex objects Drops an indices. clearTable(tableName: string): Promise<void> tableName - table name Clears all table contents. Note: this operation uses SQL's TRUNCATE query which cannot be reverted in transactions. enableSqlMemory(): void Enables special query runner mode in which sql queries won't be executed, instead they will be memorized into a special variable inside query runner. You can get memorized sql using getMemorySql() method. disableSqlMemory(): void Disables special query runner mode in which sql queries won't be executed. Previously memorized sql will be flushed. clearSqlMemory(): void Flushes all memorized sql statements. getMemorySql(): SqlInMemory returns SqlInMemory object with array of upQueries and downQueries sql statements Gets sql stored in the memory. Parameters in the sql are already replaced. executeMemoryUpSql(): Promise<void> Executes memorized up sql queries. executeMemoryDownSql(): Promise<void> Executes memorized down sql queries.","title":"Migrations"},{"location":"migrations/#migrations","text":"How migrations work Creating a new migration Running and reverting migrations Generating migrations Connection option Using migration API to write migrations","title":"Migrations"},{"location":"migrations/#how-migrations-work","text":"Once you get into production you'll need to synchronize model changes into the database. Typically it is unsafe to use synchronize: true for schema synchronization on production once you get data in your database. Here is where migrations come to help. A migration is just a single file with sql queries to update a database schema and apply new changes to an existing database. Let's say you already have a database and a post entity: import { Entity, Column, PrimaryGeneratedColumn } from 'typeorm'; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; } And your entity worked in production for months without any changes. You have thousands of posts in your database. Now you need to make a new release and rename title to name . What would you do? You need to create a new migration with the following sql query (postgres dialect): ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"; Once you run this sql query your database schema is ready to work with your new codebase. TypeORM provides a place where you can write such sql queries and run them when needed. This place is called \"migrations\".","title":"How migrations work"},{"location":"migrations/#creating-a-new-migration","text":"Pre-requisites : Installing CLI Before creating a new migration you need to setup your connection options properly: { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\", \"entities\": [\"entity/*.js\"], \"migrationsTableName\": \"custom_migration_table\", \"migrations\": [\"migration/*.js\"], \"cli\": { \"migrationsDir\": \"migration\" } } Here we setup three options: * \"migrationsTableName\": \"migrations\" - Specify this option only if you need migration table name to be different from \"migrations\" . * \"migrations\": [\"migration/*.js\"] - indicates that typeorm must load migrations from the given \"migration\" directory. * \"cli\": { \"migrationsDir\": \"migration\" } - indicates that the CLI must create new migrations in the \"migration\" directory. Once you setup connection options you can create a new migration using CLI: typeorm migration:create -n PostRefactoring Here, PostRefactoring is the name of the migration - you can specify any name you want. After you run the command you can see a new file generated in the \"migration\" directory named {TIMESTAMP}-PostRefactoring.ts where {TIMESTAMP} is the current timestamp when the migration was generated. Now you can open the file and add your migration sql queries there. You should see the following content inside your migration: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { } async down(queryRunner: QueryRunner): Promise<void> { } } There are two methods you must fill with your migration code: up and down . up has to contain the code you need to perform the migration. down has to revert whatever up changed. down method is used to revert the last migration. Inside both up and down you have a QueryRunner object. All database operations are executed using this object. Learn more about query runner . Let's see what the migration looks like with our Post changes: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" RENAME COLUMN \"title\" TO \"name\"`); } async down(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" RENAME COLUMN \"name\" TO \"title\"`); // reverts things made in \"up\" method } }","title":"Creating a new migration"},{"location":"migrations/#running-and-reverting-migrations","text":"Once you have a migration to run on production, you can run them using a CLI command: typeorm migration:run typeorm migration:create and typeorm migration:generate will create .ts files, unless you use the o flag (see more in Generating migrations ). The migration:run and migration:revert commands only work on .js files. Thus the typescript files need to be compiled before running the commands. Alternatively you can use ts-node in conjunction with typeorm to run .ts migration files. Example with ts-node : ts-node --transpile-only ./node_modules/typeorm/cli.js migration:run Example ts-node not using node_modules directly: ts-node $(yarn bin typeorm) migration:run This command will execute all pending migrations and run them in a sequence ordered by their timestamps. This means all sql queries written in the up methods of your created migrations will be executed. That's all! Now you have your database schema up-to-date. If for some reason you want to revert the changes, you can run: typeorm migration:revert This command will execute down in the latest executed migration. If you need to revert multiple migrations you must call this command multiple times.","title":"Running and reverting migrations"},{"location":"migrations/#generating-migrations","text":"TypeORM is able to automatically generate migration files with schema changes you made. Let's say you have a Post entity with a title column, and you have changed the name title to name . You can run following command: typeorm migration:generate -n PostRefactoring And it will generate a new migration called {TIMESTAMP}-PostRefactoring.ts with the following content: import {MigrationInterface, QueryRunner} from \"typeorm\"; export class PostRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } async down(queryRunner: QueryRunner): Promise<void> { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"name\" RENAME TO \"title\"`); } } Alternatively you can also output your migrations as Javascript files using the o (alias for --outputJs ) flag. This is useful for Javascript only projects in which TypeScript additional packages are not installed. This command, will generate a new migration file {TIMESTAMP}-PostRefactoring.js with the following content: const { MigrationInterface, QueryRunner } = require(\"typeorm\"); module.exports = class PostRefactoringTIMESTAMP { async up(queryRunner) { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } async down(queryRunner) { await queryRunner.query(`ALTER TABLE \"post\" ALTER COLUMN \"title\" RENAME TO \"name\"`); } } See, you don't need to write the queries on your own. The rule of thumb for generating migrations is that you generate them after each change you made to your models. To apply multi-line formatting to your generated migration queries, use the p (alias for --pretty ) flag.","title":"Generating migrations"},{"location":"migrations/#connection-option","text":"If you need to run/revert your migrations for another connection rather than the default, use the -c (alias for --connection ) and pass the config name as an argument typeorm -c <your-config-name> migration:{run|revert}","title":"Connection option"},{"location":"migrations/#using-migration-api-to-write-migrations","text":"In order to use an API to change a database schema you can use QueryRunner . Example: import {MigrationInterface, QueryRunner, Table, TableIndex, TableColumn, TableForeignKey } from \"typeorm\"; export class QuestionRefactoringTIMESTAMP implements MigrationInterface { async up(queryRunner: QueryRunner): Promise<void> { await queryRunner.createTable(new Table({ name: \"question\", columns: [ { name: \"id\", type: \"int\", isPrimary: true }, { name: \"name\", type: \"varchar\", } ] }), true) await queryRunner.createIndex(\"question\", new TableIndex({ name: \"IDX_QUESTION_NAME\", columnNames: [\"name\"] })); await queryRunner.createTable(new Table({ name: \"answer\", columns: [ { name: \"id\", type: \"int\", isPrimary: true }, { name: \"name\", type: \"varchar\", }, { name: 'created_at', type: 'timestamp', default: 'now()' } ] }), true); await queryRunner.addColumn(\"answer\", new TableColumn({ name: \"questionId\", type: \"int\" })); await queryRunner.createForeignKey(\"answer\", new TableForeignKey({ columnNames: [\"questionId\"], referencedColumnNames: [\"id\"], referencedTableName: \"question\", onDelete: \"CASCADE\" })); } async down(queryRunner: QueryRunner): Promise<void> { const table = await queryRunner.getTable(\"answer\"); const foreignKey = table.foreignKeys.find(fk => fk.columnNames.indexOf(\"questionId\") !== -1); await queryRunner.dropForeignKey(\"answer\", foreignKey); await queryRunner.dropColumn(\"answer\", \"questionId\"); await queryRunner.dropTable(\"answer\"); await queryRunner.dropIndex(\"question\", \"IDX_QUESTION_NAME\"); await queryRunner.dropTable(\"question\"); } } getDatabases(): Promise<string[]> Returns all available database names including system databases. getSchemas(database?: string): Promise<string[]> database - If database parameter specified, returns schemas of that database Returns all available schema names including system schemas. Useful for SQLServer and Postgres only. getTable(tableName: string): Promise<Table|undefined> tableName - name of a table to be loaded Loads a table by a given name from the database. getTables(tableNames: string[]): Promise<Table[]> tableNames - name of a tables to be loaded Loads a tables by a given names from the database. hasDatabase(database: string): Promise<boolean> database - name of a database to be checked Checks if database with the given name exist. hasSchema(schema: string): Promise<boolean> schema - name of a schema to be checked Checks if schema with the given name exist. Used only for SqlServer and Postgres. hasTable(table: Table|string): Promise<boolean> table - Table object or name Checks if table exist. hasColumn(table: Table|string, columnName: string): Promise<boolean> table - Table object or name columnName - name of a column to be checked Checks if column exist in the table. createDatabase(database: string, ifNotExist?: boolean): Promise<void> database - database name ifNotExist - skips creation if true , otherwise throws error if database already exist Creates a new database. dropDatabase(database: string, ifExist?: boolean): Promise<void> database - database name ifExist - skips deletion if true , otherwise throws error if database was not found Drops database. createSchema(schemaPath: string, ifNotExist?: boolean): Promise<void> schemaPath - schema name. For SqlServer can accept schema path (e.g. 'dbName.schemaName') as parameter. If schema path passed, it will create schema in specified database ifNotExist - skips creation if true , otherwise throws error if schema already exist Creates a new table schema. dropSchema(schemaPath: string, ifExist?: boolean, isCascade?: boolean): Promise<void> schemaPath - schema name. For SqlServer can accept schema path (e.g. 'dbName.schemaName') as parameter. If schema path passed, it will drop schema in specified database ifExist - skips deletion if true , otherwise throws error if schema was not found isCascade - If true , automatically drop objects (tables, functions, etc.) that are contained in the schema. Used only in Postgres. Drops a table schema. createTable(table: Table, ifNotExist?: boolean, createForeignKeys?: boolean, createIndices?: boolean): Promise<void> table - Table object. ifNotExist - skips creation if true , otherwise throws error if table already exist. Default false createForeignKeys - indicates whether foreign keys will be created on table creation. Default true createIndices - indicates whether indices will be created on table creation. Default true Creates a new table. dropTable(table: Table|string, ifExist?: boolean, dropForeignKeys?: boolean, dropIndices?: boolean): Promise<void> table - Table object or table name to be dropped ifExist - skips dropping if true , otherwise throws error if table does not exist dropForeignKeys - indicates whether foreign keys will be dropped on table deletion. Default true dropIndices - indicates whether indices will be dropped on table deletion. Default true Drops a table. renameTable(oldTableOrName: Table|string, newTableName: string): Promise<void> oldTableOrName - old Table object or name to be renamed newTableName - new table name Renames a table. addColumn(table: Table|string, column: TableColumn): Promise<void> table - Table object or name column - new column Adds a new column. addColumns(table: Table|string, columns: TableColumn[]): Promise<void> table - Table object or name columns - new columns Adds a new column. renameColumn(table: Table|string, oldColumnOrName: TableColumn|string, newColumnOrName: TableColumn|string): Promise<void> table - Table object or name oldColumnOrName - old column. Accepts TableColumn object or column name newColumnOrName - new column. Accepts TableColumn object or column name Renames a column. changeColumn(table: Table|string, oldColumn: TableColumn|string, newColumn: TableColumn): Promise<void> table - Table object or name oldColumn - old column. Accepts TableColumn object or column name newColumn - new column. Accepts TableColumn object Changes a column in the table. changeColumns(table: Table|string, changedColumns: { oldColumn: TableColumn, newColumn: TableColumn }[]): Promise<void> table - Table object or name changedColumns - array of changed columns. oldColumn - old TableColumn object newColumn - new TableColumn object Changes a columns in the table. dropColumn(table: Table|string, column: TableColumn|string): Promise<void> table - Table object or name column - TableColumn object or column name to be dropped Drops a column in the table. dropColumns(table: Table|string, columns: TableColumn[]|string[]): Promise<void> table - Table object or name columns - array of TableColumn objects or column names to be dropped Drops a columns in the table. createPrimaryKey(table: Table|string, columnNames: string[]): Promise<void> table - Table object or name columnNames - array of column names which will be primary Creates a new primary key. updatePrimaryKeys(table: Table|string, columns: TableColumn[]): Promise<void> table - Table object or name columns - array of TableColumn objects which will be updated Updates composite primary keys. dropPrimaryKey(table: Table|string): Promise<void> table - Table object or name Drops a primary key. createUniqueConstraint(table: Table|string, uniqueConstraint: TableUnique): Promise<void> table - Table object or name uniqueConstraint - TableUnique object to be created Creates new unique constraint. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use createIndex() method instead. createUniqueConstraints(table: Table|string, uniqueConstraints: TableUnique[]): Promise<void> table - Table object or name uniqueConstraints - array of TableUnique objects to be created Creates new unique constraints. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use createIndices() method instead. dropUniqueConstraint(table: Table|string, uniqueOrName: TableUnique|string): Promise<void> table - Table object or name uniqueOrName - TableUnique object or unique constraint name to be dropped Drops an unique constraint. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use dropIndex() method instead. dropUniqueConstraints(table: Table|string, uniqueConstraints: TableUnique[]): Promise<void> table - Table object or name uniqueConstraints - array of TableUnique objects to be dropped Drops an unique constraints. Note: does not work for MySQL, because MySQL stores unique constraints as unique indices. Use dropIndices() method instead. createCheckConstraint(table: Table|string, checkConstraint: TableCheck): Promise<void> table - Table object or name checkConstraint - TableCheck object Creates new check constraint. Note: MySQL does not support check constraints. createCheckConstraints(table: Table|string, checkConstraints: TableCheck[]): Promise<void> table - Table object or name checkConstraints - array of TableCheck objects Creates new check constraint. Note: MySQL does not support check constraints. dropCheckConstraint(table: Table|string, checkOrName: TableCheck|string): Promise<void> table - Table object or name checkOrName - TableCheck object or check constraint name Drops check constraint. Note: MySQL does not support check constraints. dropCheckConstraints(table: Table|string, checkConstraints: TableCheck[]): Promise<void> table - Table object or name checkConstraints - array of TableCheck objects Drops check constraints. Note: MySQL does not support check constraints. createForeignKey(table: Table|string, foreignKey: TableForeignKey): Promise<void> table - Table object or name foreignKey - TableForeignKey object Creates a new foreign key. createForeignKeys(table: Table|string, foreignKeys: TableForeignKey[]): Promise<void> table - Table object or name foreignKeys - array of TableForeignKey objects Creates a new foreign keys. dropForeignKey(table: Table|string, foreignKeyOrName: TableForeignKey|string): Promise<void> table - Table object or name foreignKeyOrName - TableForeignKey object or foreign key name Drops a foreign key. dropForeignKeys(table: Table|string, foreignKeys: TableForeignKey[]): Promise<void> table - Table object or name foreignKeys - array of TableForeignKey objects Drops a foreign keys. createIndex(table: Table|string, index: TableIndex): Promise<void> table - Table object or name index - TableIndex object Creates a new index. createIndices(table: Table|string, indices: TableIndex[]): Promise<void> table - Table object or name indices - array of TableIndex objects Creates a new indices. dropIndex(table: Table|string, index: TableIndex|string): Promise<void> table - Table object or name index - TableIndex object or index name Drops an index. dropIndices(table: Table|string, indices: TableIndex[]): Promise<void> table - Table object or name indices - array of TableIndex objects Drops an indices. clearTable(tableName: string): Promise<void> tableName - table name Clears all table contents. Note: this operation uses SQL's TRUNCATE query which cannot be reverted in transactions. enableSqlMemory(): void Enables special query runner mode in which sql queries won't be executed, instead they will be memorized into a special variable inside query runner. You can get memorized sql using getMemorySql() method. disableSqlMemory(): void Disables special query runner mode in which sql queries won't be executed. Previously memorized sql will be flushed. clearSqlMemory(): void Flushes all memorized sql statements. getMemorySql(): SqlInMemory returns SqlInMemory object with array of upQueries and downQueries sql statements Gets sql stored in the memory. Parameters in the sql are already replaced. executeMemoryUpSql(): Promise<void> Executes memorized up sql queries. executeMemoryDownSql(): Promise<void> Executes memorized down sql queries.","title":"Using migration API to write migrations"},{"location":"mongodb/","text":"MongoDB MongoDB support Defining entities and columns Defining subdocuments (embed documents) Using MongoEntityManager and MongoRepository MongoDB support TypeORM has basic MongoDB support. Most of TypeORM functionality is RDBMS-specific, this page contains all MongoDB-specific functionality documentation. Defining entities and columns Defining entities and columns is almost the same as in relational databases, the main difference is that you must use @ObjectIdColumn instead of @PrimaryColumn or @PrimaryGeneratedColumn . Simple entity example: import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; @Entity() export class User { @ObjectIdColumn() id: ObjectID; @Column() firstName: string; @Column() lastName: string; } And this is how you bootstrap the app: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mongodb\", host: \"localhost\", port: 27017, database: \"test\" }); Defining subdocuments (embed documents) Since MongoDB stores objects and objects inside objects (or documents inside documents) you can do the same in TypeORM: import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; export class Profile { @Column() about: string; @Column() education: string; @Column() career: string; } import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; export class Photo { @Column() url: string; @Column() description: string; @Column() size: number; constructor(url: string, description: string, size: number) { this.url = url; this.description = description; this.size = size; } } import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; @Entity() export class User { @ObjectIdColumn() id: ObjectID; @Column() firstName: string; @Column() lastName: string; @Column(type => Profile) profile: Profile; @Column(type => Photo) photos: Photo[]; } If you save this entity: import {getMongoManager} from \"typeorm\"; const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.profile = new Profile(); user.profile.about = \"About Trees and Me\"; user.profile.education = \"Tree School\"; user.profile.career = \"Lumberjack\"; user.photos = [ new Photo(\"me-and-trees.jpg\", \"Me and Trees\", 100), new Photo(\"me-and-chakram.jpg\", \"Me and Chakram\", 200), ]; const manager = getMongoManager(); await manager.save(user); Following document will be saved in the database: { \"firstName\": \"Timber\", \"lastName\": \"Saw\", \"profile\": { \"about\": \"About Trees and Me\", \"education\": \"Tree School\", \"career\": \"Lumberjack\" }, \"photos\": [ { \"url\": \"me-and-trees.jpg\", \"description\": \"Me and Trees\", \"size\": 100 }, { \"url\": \"me-and-chakram.jpg\", \"description\": \"Me and Chakram\", \"size\": 200 } ] } Using MongoEntityManager and MongoRepository You can use the majority of methods inside the EntityManager (except for RDBMS-specific, like query and transaction ). For example: import {getManager} from \"typeorm\"; const manager = getManager(); // or connection.manager const timber = await manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); For MongoDB there is also a separate MongoEntityManager which extends EntityManager . import {getMongoManager} from \"typeorm\"; const manager = getMongoManager(); // or connection.mongoManager const timber = await manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); Just like separate like MongoEntityManager there is a MongoRepository with extended Repository : import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // or connection.getMongoRepository const timber = await userRepository.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); Use Advanced options in find(): Equal: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$eq: \"Timber\"}, } }); LessThan: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { age: {$lt: 60}, } }); In: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$in: [\"Timber\",\"Zhang\"]}, } }); Not in: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$not: {$in: [\"Timber\",\"Zhang\"]}}, } }); Or: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { $or: [ {firstName:\"Timber\"}, {firstName:\"Zhang\"} ] } }); Querying subdocuments import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // Query users with education Tree School const users = await userRepository.find({ where: { 'profile.education': { $eq: \"Tree School\"} } }); Querying Array of subdocuments import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // Query users with photos of size less than 500 const users = await userRepository.find({ where: { 'photos.size': { $lt: 500} } }); Both MongoEntityManager and MongoRepository contain lot of useful MongoDB-specific methods: createCursor Creates a cursor for a query that can be used to iterate over results from MongoDB. createEntityCursor Creates a cursor for a query that can be used to iterate over results from MongoDB. This returns a modified version of the cursor that transforms each result into Entity models. aggregate Execute an aggregation framework pipeline against the collection. bulkWrite Perform a bulkWrite operation without a fluent API. count Count number of matching documents in the db to a query. createCollectionIndex Creates an index on the db and collection. createCollectionIndexes Creates multiple indexes in the collection, this method is only supported in MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported error. Index specifications are defined at http://docs.mongodb.org/manual/reference/command/createIndexes/. deleteMany Delete multiple documents on MongoDB. deleteOne Delete a document on MongoDB. distinct The distinct command returns a list of distinct values for the given key across a collection. dropCollectionIndex Drops an index from this collection. dropCollectionIndexes Drops all indexes from the collection. findOneAndDelete Find a document and delete it in one atomic operation, requires a write lock for the duration of the operation. findOneAndReplace Find a document and replace it in one atomic operation, requires a write lock for the duration of the operation. findOneAndUpdate Find a document and update it in one atomic operation, requires a write lock for the duration of the operation. geoHaystackSearch Execute a geo search using a geo haystack index on a collection. geoNear Execute the geoNear command to search for items in the collection. group Run a group command across a collection. collectionIndexes Retrieve all the indexes on the collection. collectionIndexExists Retrieve if an index exists on the collection collectionIndexInformation Retrieves this collections index info. initializeOrderedBulkOp Initiate an In order bulk write operation, operations will be serially executed in the order they are added, creating a new operation for each switch in types. initializeUnorderedBulkOp Initiate a Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order. insertMany Inserts an array of documents into MongoDB. insertOne Inserts a single document into MongoDB. isCapped Returns if the collection is a capped collection. listCollectionIndexes Get the list of all indexes information for the collection. mapReduce Run Map Reduce across a collection. Be aware that the inline option for out will return an array of results not a collection. parallelCollectionScan Return N number of parallel cursors for a collection allowing parallel reading of entire collection. There are no ordering guarantees for returned results reIndex Reindex all indexes on the collection Warning: reIndex is a blocking operation (indexes are rebuilt in the foreground) and will be slow for large collections. rename Changes the name of an existing collection. replaceOne Replace a document on MongoDB. stats Get all the collection statistics. updateMany Updates multiple documents within the collection based on the filter. updateOne Updates a single document within the collection based on the filter.","title":"MongoDB"},{"location":"mongodb/#mongodb","text":"MongoDB support Defining entities and columns Defining subdocuments (embed documents) Using MongoEntityManager and MongoRepository","title":"MongoDB"},{"location":"mongodb/#mongodb-support","text":"TypeORM has basic MongoDB support. Most of TypeORM functionality is RDBMS-specific, this page contains all MongoDB-specific functionality documentation.","title":"MongoDB support"},{"location":"mongodb/#defining-entities-and-columns","text":"Defining entities and columns is almost the same as in relational databases, the main difference is that you must use @ObjectIdColumn instead of @PrimaryColumn or @PrimaryGeneratedColumn . Simple entity example: import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; @Entity() export class User { @ObjectIdColumn() id: ObjectID; @Column() firstName: string; @Column() lastName: string; } And this is how you bootstrap the app: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mongodb\", host: \"localhost\", port: 27017, database: \"test\" });","title":"Defining entities and columns"},{"location":"mongodb/#defining-subdocuments-embed-documents","text":"Since MongoDB stores objects and objects inside objects (or documents inside documents) you can do the same in TypeORM: import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; export class Profile { @Column() about: string; @Column() education: string; @Column() career: string; } import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; export class Photo { @Column() url: string; @Column() description: string; @Column() size: number; constructor(url: string, description: string, size: number) { this.url = url; this.description = description; this.size = size; } } import {Entity, ObjectID, ObjectIdColumn, Column} from \"typeorm\"; @Entity() export class User { @ObjectIdColumn() id: ObjectID; @Column() firstName: string; @Column() lastName: string; @Column(type => Profile) profile: Profile; @Column(type => Photo) photos: Photo[]; } If you save this entity: import {getMongoManager} from \"typeorm\"; const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; user.profile = new Profile(); user.profile.about = \"About Trees and Me\"; user.profile.education = \"Tree School\"; user.profile.career = \"Lumberjack\"; user.photos = [ new Photo(\"me-and-trees.jpg\", \"Me and Trees\", 100), new Photo(\"me-and-chakram.jpg\", \"Me and Chakram\", 200), ]; const manager = getMongoManager(); await manager.save(user); Following document will be saved in the database: { \"firstName\": \"Timber\", \"lastName\": \"Saw\", \"profile\": { \"about\": \"About Trees and Me\", \"education\": \"Tree School\", \"career\": \"Lumberjack\" }, \"photos\": [ { \"url\": \"me-and-trees.jpg\", \"description\": \"Me and Trees\", \"size\": 100 }, { \"url\": \"me-and-chakram.jpg\", \"description\": \"Me and Chakram\", \"size\": 200 } ] }","title":"Defining subdocuments (embed documents)"},{"location":"mongodb/#using-mongoentitymanager-and-mongorepository","text":"You can use the majority of methods inside the EntityManager (except for RDBMS-specific, like query and transaction ). For example: import {getManager} from \"typeorm\"; const manager = getManager(); // or connection.manager const timber = await manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); For MongoDB there is also a separate MongoEntityManager which extends EntityManager . import {getMongoManager} from \"typeorm\"; const manager = getMongoManager(); // or connection.mongoManager const timber = await manager.findOne(User, { firstName: \"Timber\", lastName: \"Saw\" }); Just like separate like MongoEntityManager there is a MongoRepository with extended Repository : import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // or connection.getMongoRepository const timber = await userRepository.findOne({ firstName: \"Timber\", lastName: \"Saw\" }); Use Advanced options in find(): Equal: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$eq: \"Timber\"}, } }); LessThan: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { age: {$lt: 60}, } }); In: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$in: [\"Timber\",\"Zhang\"]}, } }); Not in: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { firstName: {$not: {$in: [\"Timber\",\"Zhang\"]}}, } }); Or: import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); const timber = await userRepository.find({ where: { $or: [ {firstName:\"Timber\"}, {firstName:\"Zhang\"} ] } }); Querying subdocuments import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // Query users with education Tree School const users = await userRepository.find({ where: { 'profile.education': { $eq: \"Tree School\"} } }); Querying Array of subdocuments import {getMongoRepository} from \"typeorm\"; const userRepository = getMongoRepository(User); // Query users with photos of size less than 500 const users = await userRepository.find({ where: { 'photos.size': { $lt: 500} } }); Both MongoEntityManager and MongoRepository contain lot of useful MongoDB-specific methods:","title":"Using MongoEntityManager and MongoRepository"},{"location":"mongodb/#createcursor","text":"Creates a cursor for a query that can be used to iterate over results from MongoDB.","title":"createCursor"},{"location":"mongodb/#createentitycursor","text":"Creates a cursor for a query that can be used to iterate over results from MongoDB. This returns a modified version of the cursor that transforms each result into Entity models.","title":"createEntityCursor"},{"location":"mongodb/#aggregate","text":"Execute an aggregation framework pipeline against the collection.","title":"aggregate"},{"location":"mongodb/#bulkwrite","text":"Perform a bulkWrite operation without a fluent API.","title":"bulkWrite"},{"location":"mongodb/#count","text":"Count number of matching documents in the db to a query.","title":"count"},{"location":"mongodb/#createcollectionindex","text":"Creates an index on the db and collection.","title":"createCollectionIndex"},{"location":"mongodb/#createcollectionindexes","text":"Creates multiple indexes in the collection, this method is only supported in MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported error. Index specifications are defined at http://docs.mongodb.org/manual/reference/command/createIndexes/.","title":"createCollectionIndexes"},{"location":"mongodb/#deletemany","text":"Delete multiple documents on MongoDB.","title":"deleteMany"},{"location":"mongodb/#deleteone","text":"Delete a document on MongoDB.","title":"deleteOne"},{"location":"mongodb/#distinct","text":"The distinct command returns a list of distinct values for the given key across a collection.","title":"distinct"},{"location":"mongodb/#dropcollectionindex","text":"Drops an index from this collection.","title":"dropCollectionIndex"},{"location":"mongodb/#dropcollectionindexes","text":"Drops all indexes from the collection.","title":"dropCollectionIndexes"},{"location":"mongodb/#findoneanddelete","text":"Find a document and delete it in one atomic operation, requires a write lock for the duration of the operation.","title":"findOneAndDelete"},{"location":"mongodb/#findoneandreplace","text":"Find a document and replace it in one atomic operation, requires a write lock for the duration of the operation.","title":"findOneAndReplace"},{"location":"mongodb/#findoneandupdate","text":"Find a document and update it in one atomic operation, requires a write lock for the duration of the operation.","title":"findOneAndUpdate"},{"location":"mongodb/#geohaystacksearch","text":"Execute a geo search using a geo haystack index on a collection.","title":"geoHaystackSearch"},{"location":"mongodb/#geonear","text":"Execute the geoNear command to search for items in the collection.","title":"geoNear"},{"location":"mongodb/#group","text":"Run a group command across a collection.","title":"group"},{"location":"mongodb/#collectionindexes","text":"Retrieve all the indexes on the collection.","title":"collectionIndexes"},{"location":"mongodb/#collectionindexexists","text":"Retrieve if an index exists on the collection","title":"collectionIndexExists"},{"location":"mongodb/#collectionindexinformation","text":"Retrieves this collections index info.","title":"collectionIndexInformation"},{"location":"mongodb/#initializeorderedbulkop","text":"Initiate an In order bulk write operation, operations will be serially executed in the order they are added, creating a new operation for each switch in types.","title":"initializeOrderedBulkOp"},{"location":"mongodb/#initializeunorderedbulkop","text":"Initiate a Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.","title":"initializeUnorderedBulkOp"},{"location":"mongodb/#insertmany","text":"Inserts an array of documents into MongoDB.","title":"insertMany"},{"location":"mongodb/#insertone","text":"Inserts a single document into MongoDB.","title":"insertOne"},{"location":"mongodb/#iscapped","text":"Returns if the collection is a capped collection.","title":"isCapped"},{"location":"mongodb/#listcollectionindexes","text":"Get the list of all indexes information for the collection.","title":"listCollectionIndexes"},{"location":"mongodb/#mapreduce","text":"Run Map Reduce across a collection. Be aware that the inline option for out will return an array of results not a collection.","title":"mapReduce"},{"location":"mongodb/#parallelcollectionscan","text":"Return N number of parallel cursors for a collection allowing parallel reading of entire collection. There are no ordering guarantees for returned results","title":"parallelCollectionScan"},{"location":"mongodb/#reindex","text":"Reindex all indexes on the collection Warning: reIndex is a blocking operation (indexes are rebuilt in the foreground) and will be slow for large collections.","title":"reIndex"},{"location":"mongodb/#rename","text":"Changes the name of an existing collection.","title":"rename"},{"location":"mongodb/#replaceone","text":"Replace a document on MongoDB.","title":"replaceOne"},{"location":"mongodb/#stats","text":"Get all the collection statistics.","title":"stats"},{"location":"mongodb/#updatemany","text":"Updates multiple documents within the collection based on the filter.","title":"updateMany"},{"location":"mongodb/#updateone","text":"Updates a single document within the collection based on the filter.","title":"updateOne"},{"location":"multiple-connections/","text":"Multiple connections, databases, schemas and replication setup Using multiple connections Using multiple databases in a single connection Using multiple schemas in a single connection Replication Using multiple connections The simplest way to use multiple databases is to create different connections: import {createConnections} from \"typeorm\"; const connections = await createConnections([{ name: \"db1Connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"root\", password: \"admin\", database: \"db1\", entities: [__dirname + \"/entity/*{.js,.ts}\"], synchronize: true }, { name: \"db2Connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"root\", password: \"admin\", database: \"db2\", entities: [__dirname + \"/entity/*{.js,.ts}\"], synchronize: true }]); This approach allows you to connect to any number of databases you have and each database will have its own configuration, own entities and overall ORM scope and settings. For each connection a new Connection instance will be created. You must specify a unique name for each connection you create. The connection options can also be loaded from an ormconfig file. You can load all connections from the ormconfig file: import {createConnections} from \"typeorm\"; const connections = await createConnections(); or you can specify which connection to create by name: import {createConnection} from \"typeorm\"; const connection = await createConnection(\"db2Connection\"); When working with connections you must specify a connection name to get a specific connection: import {getConnection} from \"typeorm\"; const db1Connection = getConnection(\"db1Connection\"); // you can work with \"db1\" database now... const db2Connection = getConnection(\"db2Connection\"); // you can work with \"db2\" database now... Benefit of using this approach is that you can configure multiple connections with different login credentials, host, port and even database type itself. Downside for might be that you'll need to manage and work with multiple connection instances. Using multiple databases in a single connection If you don't want to create multiple connections, but want to use multiple databases in a single connection, you can specify database name per-entity you use: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"secondDB\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"thirdDB\" }) export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; } User entity will be created inside secondDB database and Photo entity inside thirdDB database. All other entities will be created in default connection database. If you want to select data from a different database you only need to provide an entity: const users = await connection .createQueryBuilder() .select() .from(User, \"user\") .addFrom(Photo, \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This code will produce following sql query (depend on database type): SELECT * FROM \"secondDB\".\"user\" \"user\", \"thirdDB\".\"photo\" \"photo\" WHERE \"photo\".\"userId\" = \"user\".\"id\" You can also specify a table path instead of the entity: const users = await connection .createQueryBuilder() .select() .from(\"secondDB.user\", \"user\") .addFrom(\"thirdDB.photo\", \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This feature is supported only in mysql and mssql databases. Using multiple schemas in a single connection You can use multiple schemas in your applications, just set schema on each entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ schema: \"secondSchema\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ schema: \"thirdSchema\" }) export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; } User entity will be created inside secondSchema schema and Photo entity inside thirdSchema schema. All other entities will be created in default connection schema. If you want to select data from a different schema you only need to provide an entity: const users = await connection .createQueryBuilder() .select() .from(User, \"user\") .addFrom(Photo, \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This code will produce following sql query (depend on database type): SELECT * FROM \"secondSchema\".\"question\" \"question\", \"thirdSchema\".\"photo\" \"photo\" WHERE \"photo\".\"userId\" = \"user\".\"id\" You can also specify a table path instead of the entity: const users = await connection .createQueryBuilder() .select() .from(\"secondSchema.user\", \"user\") // in mssql you can even specify a database: secondDB.secondSchema.user .addFrom(\"thirdSchema.photo\", \"photo\") // in mssql you can even specify a database: thirdDB.thirdSchema.photo .andWhere(\"photo.userId = user.id\") .getMany(); This feature is supported only in postgres and mssql databases. In mssql you can also combine schemas and databases, for example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"secondDB\", schema: \"public\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } Replication You can setup read/write replication using TypeORM. Example of replication connection settings: { type: \"mysql\", logging: true, replication: { master: { host: \"server1\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, slaves: [{ host: \"server2\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { host: \"server3\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }] } } All schema update and write operations are performed using master server. All simple queries performed by find methods or select query builder are using a random slave instance. All queries performed by query method are performed using the master instance. If you want to explicitly use master in SELECT created by query builder, you can use the following code: const masterQueryRunner = connection.createQueryRunner(\"master\"); try { const postsFromMaster = await connection.createQueryBuilder(Post, \"post\") .setQueryRunner(masterQueryRunner) .getMany(); } finally { await masterQueryRunner.release(); } If you want to use slave in raw queries, you also need to explicitly specify the query runner. const slaveQueryRunner = connection.createQueryRunner(\"slave\"); try { const userFromSlave = await slaveQueryRunner.query('SELECT * FROM users WHERE id = $1', [userId], slaveQueryRunner); } finally { return slaveQueryRunner.release(); } Note that connection created by a QueryRunner need to be explicitly released. Replication is supported by mysql, postgres and sql server databases. Mysql supports deep configuration: { replication: { master: { host: \"server1\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, slaves: [{ host: \"server2\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { host: \"server3\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }], /** * If true, PoolCluster will attempt to reconnect when connection fails. (Default: true) */ canRetry: true, /** * If connection fails, node's errorCount increases. * When errorCount is greater than removeNodeErrorCount, remove a node in the PoolCluster. (Default: 5) */ removeNodeErrorCount: 5, /** * If connection fails, specifies the number of milliseconds before another connection attempt will be made. * If set to 0, then node will be removed instead and never re-used. (Default: 0) */ restoreNodeTimeout: 0, /** * Determines how slaves are selected: * RR: Select one alternately (Round-Robin). * RANDOM: Select the node by random function. * ORDER: Select the first node available unconditionally. */ selector: \"RR\" } }","title":"Multiple connections, databases, schemas and replication setup"},{"location":"multiple-connections/#multiple-connections-databases-schemas-and-replication-setup","text":"Using multiple connections Using multiple databases in a single connection Using multiple schemas in a single connection Replication","title":"Multiple connections, databases, schemas and replication setup"},{"location":"multiple-connections/#using-multiple-connections","text":"The simplest way to use multiple databases is to create different connections: import {createConnections} from \"typeorm\"; const connections = await createConnections([{ name: \"db1Connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"root\", password: \"admin\", database: \"db1\", entities: [__dirname + \"/entity/*{.js,.ts}\"], synchronize: true }, { name: \"db2Connection\", type: \"mysql\", host: \"localhost\", port: 3306, username: \"root\", password: \"admin\", database: \"db2\", entities: [__dirname + \"/entity/*{.js,.ts}\"], synchronize: true }]); This approach allows you to connect to any number of databases you have and each database will have its own configuration, own entities and overall ORM scope and settings. For each connection a new Connection instance will be created. You must specify a unique name for each connection you create. The connection options can also be loaded from an ormconfig file. You can load all connections from the ormconfig file: import {createConnections} from \"typeorm\"; const connections = await createConnections(); or you can specify which connection to create by name: import {createConnection} from \"typeorm\"; const connection = await createConnection(\"db2Connection\"); When working with connections you must specify a connection name to get a specific connection: import {getConnection} from \"typeorm\"; const db1Connection = getConnection(\"db1Connection\"); // you can work with \"db1\" database now... const db2Connection = getConnection(\"db2Connection\"); // you can work with \"db2\" database now... Benefit of using this approach is that you can configure multiple connections with different login credentials, host, port and even database type itself. Downside for might be that you'll need to manage and work with multiple connection instances.","title":"Using multiple connections"},{"location":"multiple-connections/#using-multiple-databases-in-a-single-connection","text":"If you don't want to create multiple connections, but want to use multiple databases in a single connection, you can specify database name per-entity you use: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"secondDB\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"thirdDB\" }) export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; } User entity will be created inside secondDB database and Photo entity inside thirdDB database. All other entities will be created in default connection database. If you want to select data from a different database you only need to provide an entity: const users = await connection .createQueryBuilder() .select() .from(User, \"user\") .addFrom(Photo, \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This code will produce following sql query (depend on database type): SELECT * FROM \"secondDB\".\"user\" \"user\", \"thirdDB\".\"photo\" \"photo\" WHERE \"photo\".\"userId\" = \"user\".\"id\" You can also specify a table path instead of the entity: const users = await connection .createQueryBuilder() .select() .from(\"secondDB.user\", \"user\") .addFrom(\"thirdDB.photo\", \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This feature is supported only in mysql and mssql databases.","title":"Using multiple databases in a single connection"},{"location":"multiple-connections/#using-multiple-schemas-in-a-single-connection","text":"You can use multiple schemas in your applications, just set schema on each entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ schema: \"secondSchema\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ schema: \"thirdSchema\" }) export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; } User entity will be created inside secondSchema schema and Photo entity inside thirdSchema schema. All other entities will be created in default connection schema. If you want to select data from a different schema you only need to provide an entity: const users = await connection .createQueryBuilder() .select() .from(User, \"user\") .addFrom(Photo, \"photo\") .andWhere(\"photo.userId = user.id\") .getMany(); // userId is not a foreign key since its cross-database request This code will produce following sql query (depend on database type): SELECT * FROM \"secondSchema\".\"question\" \"question\", \"thirdSchema\".\"photo\" \"photo\" WHERE \"photo\".\"userId\" = \"user\".\"id\" You can also specify a table path instead of the entity: const users = await connection .createQueryBuilder() .select() .from(\"secondSchema.user\", \"user\") // in mssql you can even specify a database: secondDB.secondSchema.user .addFrom(\"thirdSchema.photo\", \"photo\") // in mssql you can even specify a database: thirdDB.thirdSchema.photo .andWhere(\"photo.userId = user.id\") .getMany(); This feature is supported only in postgres and mssql databases. In mssql you can also combine schemas and databases, for example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity({ database: \"secondDB\", schema: \"public\" }) export class User { @PrimaryGeneratedColumn() id: number; @Column() firstName: string; @Column() lastName: string; }","title":"Using multiple schemas in a single connection"},{"location":"multiple-connections/#replication","text":"You can setup read/write replication using TypeORM. Example of replication connection settings: { type: \"mysql\", logging: true, replication: { master: { host: \"server1\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, slaves: [{ host: \"server2\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { host: \"server3\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }] } } All schema update and write operations are performed using master server. All simple queries performed by find methods or select query builder are using a random slave instance. All queries performed by query method are performed using the master instance. If you want to explicitly use master in SELECT created by query builder, you can use the following code: const masterQueryRunner = connection.createQueryRunner(\"master\"); try { const postsFromMaster = await connection.createQueryBuilder(Post, \"post\") .setQueryRunner(masterQueryRunner) .getMany(); } finally { await masterQueryRunner.release(); } If you want to use slave in raw queries, you also need to explicitly specify the query runner. const slaveQueryRunner = connection.createQueryRunner(\"slave\"); try { const userFromSlave = await slaveQueryRunner.query('SELECT * FROM users WHERE id = $1', [userId], slaveQueryRunner); } finally { return slaveQueryRunner.release(); } Note that connection created by a QueryRunner need to be explicitly released. Replication is supported by mysql, postgres and sql server databases. Mysql supports deep configuration: { replication: { master: { host: \"server1\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, slaves: [{ host: \"server2\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }, { host: \"server3\", port: 3306, username: \"test\", password: \"test\", database: \"test\" }], /** * If true, PoolCluster will attempt to reconnect when connection fails. (Default: true) */ canRetry: true, /** * If connection fails, node's errorCount increases. * When errorCount is greater than removeNodeErrorCount, remove a node in the PoolCluster. (Default: 5) */ removeNodeErrorCount: 5, /** * If connection fails, specifies the number of milliseconds before another connection attempt will be made. * If set to 0, then node will be removed instead and never re-used. (Default: 0) */ restoreNodeTimeout: 0, /** * Determines how slaves are selected: * RR: Select one alternately (Round-Robin). * RANDOM: Select the node by random function. * ORDER: Select the first node available unconditionally. */ selector: \"RR\" } }","title":"Replication"},{"location":"naming-strategy/","text":"Naming strategy Specify custom table name Specify custom column name Specify custom foreign column name Specify custom many-to-many junction table name Creating your own NamingStrategy Creating your own NamingStrategy If you defined your connection options in the ormconfig file, then you can simply use it and override it following way: import {createConnection, getConnectionOptions} from \"typeorm\"; import {MyNamingStrategy} from \"./logger/MyNamingStrategy\"; // getConnectionOptions will read options from your ormconfig file // and return it in connectionOptions object // then you can simply append additional properties to it getConnectionOptions().then(connectionOptions => { return createConnection(Object.assign(connectionOptions, { namingStrategy: new MyNamingStrategy() })) }); Naming Strategy is a subject to change. Expect detailed documentation once its API gets stabilized.","title":"Naming strategy"},{"location":"naming-strategy/#naming-strategy","text":"Specify custom table name Specify custom column name Specify custom foreign column name Specify custom many-to-many junction table name Creating your own NamingStrategy","title":"Naming strategy"},{"location":"naming-strategy/#creating-your-own-namingstrategy","text":"If you defined your connection options in the ormconfig file, then you can simply use it and override it following way: import {createConnection, getConnectionOptions} from \"typeorm\"; import {MyNamingStrategy} from \"./logger/MyNamingStrategy\"; // getConnectionOptions will read options from your ormconfig file // and return it in connectionOptions object // then you can simply append additional properties to it getConnectionOptions().then(connectionOptions => { return createConnection(Object.assign(connectionOptions, { namingStrategy: new MyNamingStrategy() })) }); Naming Strategy is a subject to change. Expect detailed documentation once its API gets stabilized.","title":"Creating your own NamingStrategy"},{"location":"one-to-one-relations/","text":"One-to-one relations One-to-one is a relation where A contains only one instance of B, and B contains only one instance of A. Let's take for example User and Profile entities. User can have only a single profile, and a single profile is owned by only a single user. import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(() => Profile) @JoinColumn() profile: Profile; } Here we added @OneToOne to the profile and specify the target relation type to be Profile . We also added @JoinColumn which is required and must be set only on one side of the relation. The side you set @JoinColumn on, that side's table will contain a \"relation id\" and foreign keys to target entity table. This example will produce following tables: +-------------+--------------+----------------------------+ | profile | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | gender | varchar(255) | | | photo | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | | profileId | int(11) | FOREIGN KEY | +-------------+--------------+----------------------------+ Again, @JoinColumn must be set only on one side of relation - the side that must have the foreign key in the database table. Example how to save such a relation: const profile = new Profile(); profile.gender = \"male\"; profile.photo = \"me.jpg\"; await connection.manager.save(profile); const user = new User(); user.name = 'Joe Smith'; user.profile = profile; await connection.manager.save(user); With cascades enabled you can save this relation with only one save call. To load user with profile inside you must specify relation in FindOptions : const userRepository = connection.getRepository(User); const users = await userRepository.find({ relations: [\"profile\"] }); Or using QueryBuilder you can join them: const users = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.profile\", \"profile\") .getMany(); With eager loading enabled on a relation you don't have to specify relation or join it - it will ALWAYS be loaded automatically. Relations can be uni-directional and bi-directional. Uni-directional are relations with a relation decorator only on one side. Bi-directional are relations with decorators on both sides of a relation. We just created a uni-directional relation. Let's make it bi-directional: import {Entity, PrimaryGeneratedColumn, Column, OneToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; @OneToOne(() => User, user => user.profile) // specify inverse side as a second parameter user: User; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(() => Profile, profile => profile.user) // specify inverse side as a second parameter @JoinColumn() profile: Profile; } We just made our relation bi-directional. Note, inverse relation does not have a @JoinColumn . @JoinColumn must only be on one side of the relation - on the table that will own the foreign key. Bi-directional relations allow you to join relations from both sides using QueryBuilder : const profiles = await connection .getRepository(Profile) .createQueryBuilder(\"profile\") .leftJoinAndSelect(\"profile.user\", \"user\") .getMany();","title":"One-to-one relations"},{"location":"one-to-one-relations/#one-to-one-relations","text":"One-to-one is a relation where A contains only one instance of B, and B contains only one instance of A. Let's take for example User and Profile entities. User can have only a single profile, and a single profile is owned by only a single user. import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(() => Profile) @JoinColumn() profile: Profile; } Here we added @OneToOne to the profile and specify the target relation type to be Profile . We also added @JoinColumn which is required and must be set only on one side of the relation. The side you set @JoinColumn on, that side's table will contain a \"relation id\" and foreign keys to target entity table. This example will produce following tables: +-------------+--------------+----------------------------+ | profile | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | gender | varchar(255) | | | photo | varchar(255) | | +-------------+--------------+----------------------------+ +-------------+--------------+----------------------------+ | user | +-------------+--------------+----------------------------+ | id | int(11) | PRIMARY KEY AUTO_INCREMENT | | name | varchar(255) | | | profileId | int(11) | FOREIGN KEY | +-------------+--------------+----------------------------+ Again, @JoinColumn must be set only on one side of relation - the side that must have the foreign key in the database table. Example how to save such a relation: const profile = new Profile(); profile.gender = \"male\"; profile.photo = \"me.jpg\"; await connection.manager.save(profile); const user = new User(); user.name = 'Joe Smith'; user.profile = profile; await connection.manager.save(user); With cascades enabled you can save this relation with only one save call. To load user with profile inside you must specify relation in FindOptions : const userRepository = connection.getRepository(User); const users = await userRepository.find({ relations: [\"profile\"] }); Or using QueryBuilder you can join them: const users = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.profile\", \"profile\") .getMany(); With eager loading enabled on a relation you don't have to specify relation or join it - it will ALWAYS be loaded automatically. Relations can be uni-directional and bi-directional. Uni-directional are relations with a relation decorator only on one side. Bi-directional are relations with decorators on both sides of a relation. We just created a uni-directional relation. Let's make it bi-directional: import {Entity, PrimaryGeneratedColumn, Column, OneToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; @OneToOne(() => User, user => user.profile) // specify inverse side as a second parameter user: User; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(() => Profile, profile => profile.user) // specify inverse side as a second parameter @JoinColumn() profile: Profile; } We just made our relation bi-directional. Note, inverse relation does not have a @JoinColumn . @JoinColumn must only be on one side of the relation - on the table that will own the foreign key. Bi-directional relations allow you to join relations from both sides using QueryBuilder : const profiles = await connection .getRepository(Profile) .createQueryBuilder(\"profile\") .leftJoinAndSelect(\"profile.user\", \"user\") .getMany();","title":"One-to-one relations"},{"location":"query-runner/","text":"Working with Query Runner What is QueryRunner Creating a queryRunner Using queryRunner Working with QueryRunner What is QueryRunner Your interaction with the database is only possible once you setup a connection. TypeORM's Connection does not setup a database connection as it might seem, instead it sets up a connection pool. If you are interested in a real database connection, you should use QueryRunner . Each instance of QueryRunner is a separate isolated database connection. Using query runners you can control your queries to execute using single database connection and manually control your database transaction. Creating a new queryRunner To create a new instance of QueryRunner you should first create a connection pool, in any of the ways described on the Connection documentation. Once a connection has established, use the createQueryRunner function to create an isolated connection. createQueryRunner Creates a query runner used to perform queries on a single database connection. import { getConnection, QueryRunner } from 'typeorm'; // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner(); Using queryRunner After creating an instance of QueryRunner use connect to activate the connection. import { getConnection, QueryRunner } from 'typeorm'; // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner(); await queryRunner.connect(); // performs connection Since the QueryRunner is used to manage an isolated database connection, make sure to release it when it is not needed anymore to make it available to the connection pool again. After connection is released it is not possible to use the query runner methods. Working with QueryRunner Once you set your queryRunner up, you can use it with an interface similar to the Connection interface: import { getConnection, QueryRunner } from 'typeorm'; import { User } from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll(): Promise<User[]> { // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner(); await queryRunner.connect(); // performs connection const users = await queryRunner.manager.find(User); await queryRunner.release(); // release connection return users; } }","title":"Working with Query Runner"},{"location":"query-runner/#working-with-query-runner","text":"What is QueryRunner Creating a queryRunner Using queryRunner Working with QueryRunner","title":"Working with Query Runner"},{"location":"query-runner/#what-is-queryrunner","text":"Your interaction with the database is only possible once you setup a connection. TypeORM's Connection does not setup a database connection as it might seem, instead it sets up a connection pool. If you are interested in a real database connection, you should use QueryRunner . Each instance of QueryRunner is a separate isolated database connection. Using query runners you can control your queries to execute using single database connection and manually control your database transaction.","title":"What is QueryRunner"},{"location":"query-runner/#creating-a-new-queryrunner","text":"To create a new instance of QueryRunner you should first create a connection pool, in any of the ways described on the Connection documentation. Once a connection has established, use the createQueryRunner function to create an isolated connection. createQueryRunner Creates a query runner used to perform queries on a single database connection. import { getConnection, QueryRunner } from 'typeorm'; // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner();","title":"Creating a new queryRunner"},{"location":"query-runner/#using-queryrunner","text":"After creating an instance of QueryRunner use connect to activate the connection. import { getConnection, QueryRunner } from 'typeorm'; // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner(); await queryRunner.connect(); // performs connection Since the QueryRunner is used to manage an isolated database connection, make sure to release it when it is not needed anymore to make it available to the connection pool again. After connection is released it is not possible to use the query runner methods.","title":"Using queryRunner"},{"location":"query-runner/#working-with-queryrunner","text":"Once you set your queryRunner up, you can use it with an interface similar to the Connection interface: import { getConnection, QueryRunner } from 'typeorm'; import { User } from \"../entity/User\"; export class UserController { @Get(\"/users\") getAll(): Promise<User[]> { // can be used once createConnection is called and is resolved const connection: Connection = getConnection(); const queryRunner: QueryRunner = connection.createQueryRunner(); await queryRunner.connect(); // performs connection const users = await queryRunner.manager.find(User); await queryRunner.release(); // release connection return users; } }","title":"Working with QueryRunner"},{"location":"relational-query-builder/","text":"Working with Relations RelationQueryBuilder is a special type of QueryBuilder which allows you to work with your relations. Using it, you can bind entities to each other in the database without the need to load any entities, or you can load related entities easily. For example, we have a Post entity and it has a many-to-many relation to Category called categories . Let's add a new category to this many-to-many relation: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) .add(category); This code is equivalent to doing this: import {getRepository} from \"typeorm\"; const postRepository = getRepository(Post); const post = await postRepository.findOne(1, { relations: [\"categories\"] }); post.categories.push(category); await postRepository.save(post); But more efficient, because it does a minimal number of operations, and binds entities in the database, unlike calling a bulky save method call. Also, another benefit of such an approach is that you don't need to load every related entity before pushing into it. For example, if you have ten thousand categories inside a single post, adding new posts to this list may become problematic for you, because the standard way of doing this is to load the post with all ten thousand categories, push a new category, and save it. This results in very heavy performance costs and is basically inapplicable in production results. However, using RelationQueryBuilder solves this problem. Also, there is no real need to use entities when you \"bind\" things, since you can use entity ids instead. For example, let's add a category with id = 3 into post with id = 1: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(1) .add(3); If you are using composite primary keys, you have to pass them as an id map, for example: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of({ firstPostId: 1, secondPostId: 3 }) .add({ firstCategoryId: 2, secondCategoryId: 4 }); You can remove entities the same way you add them: import {getConnection} from \"typeorm\"; // this code removes a category from a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .remove(category); // you can use just category id as well Adding and removing related entities works in many-to-many and one-to-many relations. For one-to-one and many-to-one relations use set instead: import {getConnection} from \"typeorm\"; // this code sets category of a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .set(category); // you can use just category id as well If you want to unset a relation (set it to null), simply pass null to a set method: import {getConnection} from \"typeorm\"; // this code unsets category of a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .set(null); Besides updating relations, the relational query builder also allows you to load relational entities. For example, lets say inside a Post entity we have a many-to-many categories relation and a many-to-one user relation, to load those relations you can use following code: import {getConnection} from \"typeorm\"; const post = await getConnection().manager.findOne(Post, 1); post.categories = await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .loadMany(); post.author = await getConnection() .createQueryBuilder() .relation(Post, \"user\") .of(post) // you can use just post id as well .loadOne();","title":"Working with Relations"},{"location":"relational-query-builder/#working-with-relations","text":"RelationQueryBuilder is a special type of QueryBuilder which allows you to work with your relations. Using it, you can bind entities to each other in the database without the need to load any entities, or you can load related entities easily. For example, we have a Post entity and it has a many-to-many relation to Category called categories . Let's add a new category to this many-to-many relation: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) .add(category); This code is equivalent to doing this: import {getRepository} from \"typeorm\"; const postRepository = getRepository(Post); const post = await postRepository.findOne(1, { relations: [\"categories\"] }); post.categories.push(category); await postRepository.save(post); But more efficient, because it does a minimal number of operations, and binds entities in the database, unlike calling a bulky save method call. Also, another benefit of such an approach is that you don't need to load every related entity before pushing into it. For example, if you have ten thousand categories inside a single post, adding new posts to this list may become problematic for you, because the standard way of doing this is to load the post with all ten thousand categories, push a new category, and save it. This results in very heavy performance costs and is basically inapplicable in production results. However, using RelationQueryBuilder solves this problem. Also, there is no real need to use entities when you \"bind\" things, since you can use entity ids instead. For example, let's add a category with id = 3 into post with id = 1: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(1) .add(3); If you are using composite primary keys, you have to pass them as an id map, for example: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of({ firstPostId: 1, secondPostId: 3 }) .add({ firstCategoryId: 2, secondCategoryId: 4 }); You can remove entities the same way you add them: import {getConnection} from \"typeorm\"; // this code removes a category from a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .remove(category); // you can use just category id as well Adding and removing related entities works in many-to-many and one-to-many relations. For one-to-one and many-to-one relations use set instead: import {getConnection} from \"typeorm\"; // this code sets category of a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .set(category); // you can use just category id as well If you want to unset a relation (set it to null), simply pass null to a set method: import {getConnection} from \"typeorm\"; // this code unsets category of a given post await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .set(null); Besides updating relations, the relational query builder also allows you to load relational entities. For example, lets say inside a Post entity we have a many-to-many categories relation and a many-to-one user relation, to load those relations you can use following code: import {getConnection} from \"typeorm\"; const post = await getConnection().manager.findOne(Post, 1); post.categories = await getConnection() .createQueryBuilder() .relation(Post, \"categories\") .of(post) // you can use just post id as well .loadMany(); post.author = await getConnection() .createQueryBuilder() .relation(Post, \"user\") .of(post) // you can use just post id as well .loadOne();","title":"Working with Relations"},{"location":"relations-faq/","text":"Relations FAQ How to create self referencing relation How to use relation id without joining relation How to load relations in entities Avoid relation property initializers Avoid foreign key constraint creation How to create self referencing relation Self-referencing relations are relations which have a relation to themself. This is useful when you are storing entities in a tree-like structures. Also \"adjacency list\" pattern is implemented using self-referenced relations. For example, you want to create categories tree in your application. Categories can nest categories, nested categories can nest other categories, etc. Self-referencing relations come handy here. Basically self-referencing relations are just regular relations that targets entity itself. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToOne(type => Category, category => category.childCategories) parentCategory: Category; @OneToMany(type => Category, category => category.parentCategory) childCategories: Category[]; } How to use relation id without joining relation Sometimes you want to have in your object id of the related object without loading it. For example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(type => Profile) @JoinColumn() profile: Profile; } When you load a user without profile joined you won't have any information about profile in your user object, even profile id: User { id: 1, name: \"Umed\" } But sometimes you want to know what is the \"profile id\" of this user without loading the whole profile for this user. To do this you just need to add another property to your entity with @Column named exactly as the column created by your relation. Example: import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column({ nullable: true }) profileId: number; @OneToOne(type => Profile) @JoinColumn() profile: Profile; } That's all. Next time you load a user object it will contain a profile id: User { id: 1, name: \"Umed\", profileId: 1 } How to load relations in entities The easiest way to load your entity relations is to use relations option in FindOptions : const users = await connection.getRepository(User).find({ relations: [\"profile\", \"photos\", \"videos\"] }); Alternative and more flexible way is to use QueryBuilder : const user = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.profile\", \"profile\") .leftJoinAndSelect(\"user.photos\", \"photo\") .leftJoinAndSelect(\"user.videos\", \"video\") .getMany(); Using QueryBuilder you can do innerJoinAndSelect instead of leftJoinAndSelect (to learn the difference between LEFT JOIN and INNER JOIN refer to your SQL documentation), you can join relation data by a condition, make ordering, etc. Learn more about QueryBuilder . Avoid relation property initializers Sometimes it is useful to initialize your relation properties, for example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions) @JoinTable() categories: Category[] = []; // see = [] initialization here } However in TypeORM entities it may cause problems. To understand the problem, let's first try to load a Question entity WITHOUT the initializer set. When you load a question it will return an object like this: Question { id: 1, title: \"Question about ...\" } Now when you save this object categories inside it won't be touched - because it is unset. But if you have initializer, the loaded object will look like as follow: Question { id: 1, title: \"Question about ...\", categories: [] } When you save the object it will check if there are any categories in the database bind to the question - and it will detach all of them. Why? Because relation equal to [] or any items inside it will be considered like something was removed from it, there is no other way to check if an object was removed from entity or not. Therefore, saving an object like this will bring you problems - it will remove all previously set categories. How to avoid this behaviour? Simply don't initialize arrays in your entities. Same rule applies to a constructor - don't initialize it in a constructor as well. Avoid foreign key constraint creation Sometimes for performance reasons you might want to have a relation between entities, but without foreign key constraint. You can define if foreign key constraint should be created with createForeignKeyConstraints option (default: true). import {Entity, PrimaryColumn, Column, ManyToOne} from \"typeorm\"; import {Person} from \"./Person\"; @Entity() export class ActionLog { @PrimaryColumn() id: number; @Column() date: Date; @Column() action: string; @ManyToOne(type => Person, { createForeignKeyConstraints: false }) person: Person; }","title":"Relations FAQ"},{"location":"relations-faq/#relations-faq","text":"How to create self referencing relation How to use relation id without joining relation How to load relations in entities Avoid relation property initializers Avoid foreign key constraint creation","title":"Relations FAQ"},{"location":"relations-faq/#how-to-create-self-referencing-relation","text":"Self-referencing relations are relations which have a relation to themself. This is useful when you are storing entities in a tree-like structures. Also \"adjacency list\" pattern is implemented using self-referenced relations. For example, you want to create categories tree in your application. Categories can nest categories, nested categories can nest other categories, etc. Self-referencing relations come handy here. Basically self-referencing relations are just regular relations that targets entity itself. Example: import {Entity, PrimaryGeneratedColumn, Column, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToOne(type => Category, category => category.childCategories) parentCategory: Category; @OneToMany(type => Category, category => category.parentCategory) childCategories: Category[]; }","title":"How to create self referencing relation"},{"location":"relations-faq/#how-to-use-relation-id-without-joining-relation","text":"Sometimes you want to have in your object id of the related object without loading it. For example: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Profile { @PrimaryGeneratedColumn() id: number; @Column() gender: string; @Column() photo: string; } import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToOne(type => Profile) @JoinColumn() profile: Profile; } When you load a user without profile joined you won't have any information about profile in your user object, even profile id: User { id: 1, name: \"Umed\" } But sometimes you want to know what is the \"profile id\" of this user without loading the whole profile for this user. To do this you just need to add another property to your entity with @Column named exactly as the column created by your relation. Example: import {Entity, PrimaryGeneratedColumn, Column, OneToOne, JoinColumn} from \"typeorm\"; import {Profile} from \"./Profile\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column({ nullable: true }) profileId: number; @OneToOne(type => Profile) @JoinColumn() profile: Profile; } That's all. Next time you load a user object it will contain a profile id: User { id: 1, name: \"Umed\", profileId: 1 }","title":"How to use relation id without joining relation"},{"location":"relations-faq/#how-to-load-relations-in-entities","text":"The easiest way to load your entity relations is to use relations option in FindOptions : const users = await connection.getRepository(User).find({ relations: [\"profile\", \"photos\", \"videos\"] }); Alternative and more flexible way is to use QueryBuilder : const user = await connection .getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.profile\", \"profile\") .leftJoinAndSelect(\"user.photos\", \"photo\") .leftJoinAndSelect(\"user.videos\", \"video\") .getMany(); Using QueryBuilder you can do innerJoinAndSelect instead of leftJoinAndSelect (to learn the difference between LEFT JOIN and INNER JOIN refer to your SQL documentation), you can join relation data by a condition, make ordering, etc. Learn more about QueryBuilder .","title":"How to load relations in entities"},{"location":"relations-faq/#avoid-relation-property-initializers","text":"Sometimes it is useful to initialize your relation properties, for example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions) @JoinTable() categories: Category[] = []; // see = [] initialization here } However in TypeORM entities it may cause problems. To understand the problem, let's first try to load a Question entity WITHOUT the initializer set. When you load a question it will return an object like this: Question { id: 1, title: \"Question about ...\" } Now when you save this object categories inside it won't be touched - because it is unset. But if you have initializer, the loaded object will look like as follow: Question { id: 1, title: \"Question about ...\", categories: [] } When you save the object it will check if there are any categories in the database bind to the question - and it will detach all of them. Why? Because relation equal to [] or any items inside it will be considered like something was removed from it, there is no other way to check if an object was removed from entity or not. Therefore, saving an object like this will bring you problems - it will remove all previously set categories. How to avoid this behaviour? Simply don't initialize arrays in your entities. Same rule applies to a constructor - don't initialize it in a constructor as well.","title":"Avoid relation property initializers"},{"location":"relations-faq/#avoid-foreign-key-constraint-creation","text":"Sometimes for performance reasons you might want to have a relation between entities, but without foreign key constraint. You can define if foreign key constraint should be created with createForeignKeyConstraints option (default: true). import {Entity, PrimaryColumn, Column, ManyToOne} from \"typeorm\"; import {Person} from \"./Person\"; @Entity() export class ActionLog { @PrimaryColumn() id: number; @Column() date: Date; @Column() action: string; @ManyToOne(type => Person, { createForeignKeyConstraints: false }) person: Person; }","title":"Avoid foreign key constraint creation"},{"location":"relations/","text":"Relations What are relations Relation options Cascades @JoinColumn options @JoinTable options What are relations Relations helps you to work with related entities easily. There are several types of relations: one-to-one using @OneToOne many-to-one using @ManyToOne one-to-many using @OneToMany many-to-many using @ManyToMany Relation options There are several options you can specify for relations: eager: boolean - If set to true, the relation will always be loaded with the main entity when using find* methods or QueryBuilder on this entity cascade: boolean | (\"insert\" | \"update\")[] - If set to true, the related object will be inserted and updated in the database. You can also specify an array of cascade options . onDelete: \"RESTRICT\"|\"CASCADE\"|\"SET NULL\" - specifies how foreign key should behave when referenced object is deleted primary: boolean - Indicates whether this relation's column will be a primary column or not. nullable: boolean - Indicates whether this relation's column is nullable or not. By default it is nullable. orphanedRowAction: \"nullify\" | \"delete\" - When a child row is removed from its parent, determines if the child row should be orphaned (default) or deleted. Cascades Cascades example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions, { cascade: true }) @JoinTable() categories: Category[]; } const category1 = new Category(); category1.name = \"ORMs\"; const category2 = new Category(); category2.name = \"Programming\"; const question = new Question(); question.title = \"How to ask questions?\"; question.text = \"Where can I ask TypeORM-related questions?\"; question.categories = [category1, category2]; await connection.manager.save(question); As you can see in this example we did not call save for category1 and category2 . They will be automatically inserted, because we set cascade to true. Keep in mind - great power comes with great responsibility. Cascades may seem like a good and easy way to work with relations, but they may also bring bugs and security issues when some undesired object is being saved into the database. Also, they provide a less explicit way of saving new objects into the database. Cascade Options The cascade option can be set as a boolean or an array of cascade options (\"insert\" | \"update\" | \"remove\" | \"soft-remove\" | \"recover\")[] . It will default to false , meaning no cascades. Setting cascade: true will enable full cascades. You can also specify options by providing an array. For example: @Entity(Post) export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; // Full cascades on categories. @ManyToMany(type => PostCategory, { cascade: true }) @JoinTable() categories: PostCategory[]; // Cascade insert here means if there is a new PostDetails instance set // on this relation, it will be inserted automatically to the db when you save this Post entity @ManyToMany(type => PostDetails, details => details.posts, { cascade: [\"insert\"] }) @JoinTable() details: PostDetails[]; // Cascade update here means if there are changes to an existing PostImage, it // will be updated automatically to the db when you save this Post entity @ManyToMany(type => PostImage, image => image.posts, { cascade: [\"update\"] }) @JoinTable() images: PostImage[]; // Cascade insert & update here means if there are new PostInformation instances // or an update to an existing one, they will be automatically inserted or updated // when you save this Post entity @ManyToMany(type => PostInformation, information => information.posts, { cascade: [\"insert\", \"update\"] }) @JoinTable() informations: PostInformation[]; } @JoinColumn options @JoinColumn not only defines which side of the relation contains the join column with a foreign key, but also allows you to customize join column name and referenced column name. When we set @JoinColumn , it automatically creates a column in the database named propertyName + referencedColumnName . For example: @ManyToOne(type => Category) @JoinColumn() // this decorator is optional for @ManyToOne, but required for @OneToOne category: Category; This code will create a categoryId column in the database. If you want to change this name in the database you can specify a custom join column name: @ManyToOne(type => Category) @JoinColumn({ name: \"cat_id\" }) category: Category; Join columns are always a reference to some other columns (using a foreign key). By default your relation always refers to the primary column of the related entity. If you want to create relation with other columns of the related entity - you can specify them in @JoinColumn as well: @ManyToOne(type => Category) @JoinColumn({ referencedColumnName: \"name\" }) category: Category; The relation now refers to name of the Category entity, instead of id . Column name for that relation will become categoryName . You can also join multiple columns. Note that they do not reference the primary column of the related entity by default: you must provide the referenced column name. @ManyToOne(type => Category) @JoinColumn([ { name: \"category_id\", referencedColumnName: \"id\" }, { name: \"locale_id\", referencedColumnName: \"locale_id\" } ]) category: Category; @JoinTable options @JoinTable is used for many-to-many relations and describes join columns of the \"junction\" table. A junction table is a special separate table created automatically by TypeORM with columns that refer to the related entities. You can change column names inside junction tables and their referenced columns with @JoinColumn : You can also change the name of the generated \"junction\" table. @ManyToMany(type => Category) @JoinTable({ name: \"question_categories\", // table name for the junction table of this relation joinColumn: { name: \"question\", referencedColumnName: \"id\" }, inverseJoinColumn: { name: \"category\", referencedColumnName: \"id\" } }) categories: Category[]; If the destination table has composite primary keys, then an array of properties must be sent to @JoinTable .","title":"Relations"},{"location":"relations/#relations","text":"What are relations Relation options Cascades @JoinColumn options @JoinTable options","title":"Relations"},{"location":"relations/#what-are-relations","text":"Relations helps you to work with related entities easily. There are several types of relations: one-to-one using @OneToOne many-to-one using @ManyToOne one-to-many using @OneToMany many-to-many using @ManyToMany","title":"What are relations"},{"location":"relations/#relation-options","text":"There are several options you can specify for relations: eager: boolean - If set to true, the relation will always be loaded with the main entity when using find* methods or QueryBuilder on this entity cascade: boolean | (\"insert\" | \"update\")[] - If set to true, the related object will be inserted and updated in the database. You can also specify an array of cascade options . onDelete: \"RESTRICT\"|\"CASCADE\"|\"SET NULL\" - specifies how foreign key should behave when referenced object is deleted primary: boolean - Indicates whether this relation's column will be a primary column or not. nullable: boolean - Indicates whether this relation's column is nullable or not. By default it is nullable. orphanedRowAction: \"nullify\" | \"delete\" - When a child row is removed from its parent, determines if the child row should be orphaned (default) or deleted.","title":"Relation options"},{"location":"relations/#cascades","text":"Cascades example: import {Entity, PrimaryGeneratedColumn, Column, ManyToMany} from \"typeorm\"; import {Question} from \"./Question\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(type => Question, question => question.categories) questions: Question[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToMany, JoinTable} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Question { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; @ManyToMany(type => Category, category => category.questions, { cascade: true }) @JoinTable() categories: Category[]; } const category1 = new Category(); category1.name = \"ORMs\"; const category2 = new Category(); category2.name = \"Programming\"; const question = new Question(); question.title = \"How to ask questions?\"; question.text = \"Where can I ask TypeORM-related questions?\"; question.categories = [category1, category2]; await connection.manager.save(question); As you can see in this example we did not call save for category1 and category2 . They will be automatically inserted, because we set cascade to true. Keep in mind - great power comes with great responsibility. Cascades may seem like a good and easy way to work with relations, but they may also bring bugs and security issues when some undesired object is being saved into the database. Also, they provide a less explicit way of saving new objects into the database.","title":"Cascades"},{"location":"relations/#cascade-options","text":"The cascade option can be set as a boolean or an array of cascade options (\"insert\" | \"update\" | \"remove\" | \"soft-remove\" | \"recover\")[] . It will default to false , meaning no cascades. Setting cascade: true will enable full cascades. You can also specify options by providing an array. For example: @Entity(Post) export class Post { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() text: string; // Full cascades on categories. @ManyToMany(type => PostCategory, { cascade: true }) @JoinTable() categories: PostCategory[]; // Cascade insert here means if there is a new PostDetails instance set // on this relation, it will be inserted automatically to the db when you save this Post entity @ManyToMany(type => PostDetails, details => details.posts, { cascade: [\"insert\"] }) @JoinTable() details: PostDetails[]; // Cascade update here means if there are changes to an existing PostImage, it // will be updated automatically to the db when you save this Post entity @ManyToMany(type => PostImage, image => image.posts, { cascade: [\"update\"] }) @JoinTable() images: PostImage[]; // Cascade insert & update here means if there are new PostInformation instances // or an update to an existing one, they will be automatically inserted or updated // when you save this Post entity @ManyToMany(type => PostInformation, information => information.posts, { cascade: [\"insert\", \"update\"] }) @JoinTable() informations: PostInformation[]; }","title":"Cascade Options"},{"location":"relations/#joincolumn-options","text":"@JoinColumn not only defines which side of the relation contains the join column with a foreign key, but also allows you to customize join column name and referenced column name. When we set @JoinColumn , it automatically creates a column in the database named propertyName + referencedColumnName . For example: @ManyToOne(type => Category) @JoinColumn() // this decorator is optional for @ManyToOne, but required for @OneToOne category: Category; This code will create a categoryId column in the database. If you want to change this name in the database you can specify a custom join column name: @ManyToOne(type => Category) @JoinColumn({ name: \"cat_id\" }) category: Category; Join columns are always a reference to some other columns (using a foreign key). By default your relation always refers to the primary column of the related entity. If you want to create relation with other columns of the related entity - you can specify them in @JoinColumn as well: @ManyToOne(type => Category) @JoinColumn({ referencedColumnName: \"name\" }) category: Category; The relation now refers to name of the Category entity, instead of id . Column name for that relation will become categoryName . You can also join multiple columns. Note that they do not reference the primary column of the related entity by default: you must provide the referenced column name. @ManyToOne(type => Category) @JoinColumn([ { name: \"category_id\", referencedColumnName: \"id\" }, { name: \"locale_id\", referencedColumnName: \"locale_id\" } ]) category: Category;","title":"@JoinColumn options"},{"location":"relations/#jointable-options","text":"@JoinTable is used for many-to-many relations and describes join columns of the \"junction\" table. A junction table is a special separate table created automatically by TypeORM with columns that refer to the related entities. You can change column names inside junction tables and their referenced columns with @JoinColumn : You can also change the name of the generated \"junction\" table. @ManyToMany(type => Category) @JoinTable({ name: \"question_categories\", // table name for the junction table of this relation joinColumn: { name: \"question\", referencedColumnName: \"id\" }, inverseJoinColumn: { name: \"category\", referencedColumnName: \"id\" } }) categories: Category[]; If the destination table has composite primary keys, then an array of properties must be sent to @JoinTable .","title":"@JoinTable options"},{"location":"repository-api/","text":"Repository APIs Repository API TreeRepository API MongoRepository API Repository API manager - The EntityManager used by this repository. const manager = repository.manager; metadata - The EntityMetadata of the entity managed by this repository. Learn more about transactions in Entity Metadata . const metadata = repository.metadata; queryRunner - The query runner used by EntityManager . Used only in transactional instances of EntityManager. const queryRunner = repository.queryRunner; target - The target entity class managed by this repository. Used only in transactional instances of EntityManager. const target = repository.target; createQueryBuilder - Creates a query builder use to build SQL queries. Learn more about QueryBuilder . const users = await repository .createQueryBuilder(\"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); hasId - Checks if the given entity's primary column property is defined. if (repository.hasId(user)) { // ... do something } getId - Gets the primary column property values of the given entity. If entity has composite primary keys then the returned value will be an object with names and values of primary columns. const userId = repository.getId(user); // userId === 1 create - Creates a new instance of User . Optionally accepts an object literal with user properties which will be written into newly created user object const user = repository.create(); // same as const user = new User(); const user = repository.create({ id: 1, firstName: \"Timber\", lastName: \"Saw\" }); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; merge - Merges multiple entities into a single entity. const user = new User(); repository.merge(user, { firstName: \"Timber\" }, { lastName: \"Saw\" }); // same as user.firstName = \"Timber\"; user.lastName = \"Saw\"; preload - Creates a new entity from the given plain javascript object. If the entity already exists in the database, then it loads it (and everything related to it), replaces all values with the new ones from the given object, and returns the new entity. The new entity is actually an entity loaded from the database with all properties replaced from the new object. Note that given entity-like object must have an entity id / primary key to find entity by. Returns undefined if entity with given id was not found. const partialUser = { id: 1, firstName: \"Rizzrak\", profile: { id: 1 } }; const user = await repository.preload(partialUser); // user will contain all missing data from partialUser with partialUser property values: // { id: 1, firstName: \"Rizzrak\", lastName: \"Saw\", profile: { id: 1, ... } } save - Saves a given entity or array of entities. If the entity already exist in the database, it is updated. If the entity does not exist in the database, it is inserted. It saves all given entities in a single transaction (in the case of entity, manager is not transactional). Also supports partial updating since all undefined properties are skipped. Returns the saved entity/entities. await repository.save(user); await repository.save([ category1, category2, category3 ]); remove - Removes a given entity or array of entities. It removes all given entities in a single transaction (in the case of entity, manager is not transactional). Returns the removed entity/entities. await repository.remove(user); await repository.remove([ category1, category2, category3 ]); insert - Inserts a new entity, or array of entities. await repository.insert({ firstName: \"Timber\", lastName: \"Timber\" }); await manager.insert(User, [{ firstName: \"Foo\", lastName: \"Bar\" }, { firstName: \"Rizz\", lastName: \"Rak\" }]); update - Partially updates entity by a given update options or entity id. await repository.update({ firstName: \"Timber\" }, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE firstName = Timber await repository.update(1, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE id = 1 delete - Deletes entities by entity id, ids or given conditions: await repository.delete(1); await repository.delete([1, 2, 3]); await repository.delete({ firstName: \"Timber\" }); softDelete and restore - Soft deleting and restoring a row by id const repository = connection.getRepository(Entity); // Delete a entity await repository.softDelete(1); // And You can restore it using restore; await repository.restore(1); softRemove and recover - This is alternative to softDelete and restore . // You can soft-delete them using softRemove const entities = await repository.find(); const entitiesAfterSoftRemove = await repository.softRemove(entities); // And You can recover them using recover; await repository.recover(entitiesAfterSoftRemove); count - Counts entities that match given options. Useful for pagination. const count = await repository.count({ firstName: \"Timber\" }); increment - Increments some column by provided value of entities that match given options. await manager.increment(User, { firstName: \"Timber\" }, \"age\", 3); decrement - Decrements some column by provided value that match given options. await manager.decrement(User, { firstName: \"Timber\" }, \"age\", 3); find - Finds entities that match given options. const timbers = await repository.find({ firstName: \"Timber\" }); findAndCount - Finds entities that match given find options. Also counts all entities that match given conditions, but ignores pagination settings ( skip and take options). const [timbers, timbersCount] = await repository.findAndCount({ firstName: \"Timber\" }); findByIds - Finds multiple entities by id. const users = await repository.findByIds([1, 2, 3]); findOne - Finds first entity that matches some id or find options. const user = await repository.findOne(1); const timber = await repository.findOne({ firstName: \"Timber\" }); findOneOrFail - Finds the first entity that matches the some id or find options. Rejects the returned promise if nothing matches. const user = await repository.findOneOrFail(1); const timber = await repository.findOneOrFail({ firstName: \"Timber\" }); Note: It is strongly recommended to ensure that your id or FindOptions value is not null or undefined before calling findOne and findOneOrFail . When passed null or undefined , the query will match with every entity in the repository and return the first record. query - Executes a raw SQL query. const rawData = await repository.query(`SELECT * FROM USERS`); clear - Clears all the data from the given table (truncates/drops it). await repository.clear(); Additional Options Optional SaveOptions can be passed as parameter for save . data - Additional data to be passed with persist method. This data can be used in subscribers then. listeners : boolean - Indicates if listeners and subscribers are called for this operation. By default they are enabled, you can disable them by setting { listeners: false } in save/remove options. transaction : boolean - By default transactions are enabled and all queries in persistence operation are wrapped into the transaction. You can disable this behaviour by setting { transaction: false } in the persistence options. chunk : number - Breaks save execution into multiple groups of chunks. For example, if you want to save 100.000 objects but you have issues with saving them, you can break them into 10 groups of 10.000 objects (by setting { chunk: 10000 } ) and save each group separately. This option is needed to perform very big insertions when you have issues with underlying driver parameter number limitation. reload : boolean - Flag to determine whether the entity that is being persisted should be reloaded during the persistence operation. It will work only on databases which does not support RETURNING / OUTPUT statement. Enabled by default. Example: // users contains array of User Entities userRepository.save(users, {chunk: users.length / 1000}); Optional RemoveOptions can be passed as parameter for remove and delete . data - Additional data to be passed with remove method. This data can be used in subscribers then. listener : boolean - Indicates if listeners and subscribers are called for this operation. By default they are enabled, you can disable them by setting { listeners: false } in save/remove options. transaction : boolean - By default transactions are enabled and all queries in persistence operation are wrapped into the transaction. You can disable this behaviour by setting { transaction: false } in the persistence options. chunk : number - Breaks save execution into multiple groups of chunks. For example, if you want to save 100.000 objects but you have issues saving them, you can break them into 10 groups of 10.000 objects, by setting { chunk: 10000 } , and save each group separately. This option is needed to perform very big insertions when you have issues with underlying driver parameter number limitation. Example: // users contains array of User Entities userRepository.remove(users, {chunk: entities.length / 1000}); TreeRepository API For TreeRepository API refer to the Tree Entities documentation . MongoRepository API For MongoRepository API refer to the MongoDB documentation .","title":"Repository APIs"},{"location":"repository-api/#repository-apis","text":"Repository API TreeRepository API MongoRepository API","title":"Repository APIs"},{"location":"repository-api/#repository-api","text":"manager - The EntityManager used by this repository. const manager = repository.manager; metadata - The EntityMetadata of the entity managed by this repository. Learn more about transactions in Entity Metadata . const metadata = repository.metadata; queryRunner - The query runner used by EntityManager . Used only in transactional instances of EntityManager. const queryRunner = repository.queryRunner; target - The target entity class managed by this repository. Used only in transactional instances of EntityManager. const target = repository.target; createQueryBuilder - Creates a query builder use to build SQL queries. Learn more about QueryBuilder . const users = await repository .createQueryBuilder(\"user\") .where(\"user.name = :name\", { name: \"John\" }) .getMany(); hasId - Checks if the given entity's primary column property is defined. if (repository.hasId(user)) { // ... do something } getId - Gets the primary column property values of the given entity. If entity has composite primary keys then the returned value will be an object with names and values of primary columns. const userId = repository.getId(user); // userId === 1 create - Creates a new instance of User . Optionally accepts an object literal with user properties which will be written into newly created user object const user = repository.create(); // same as const user = new User(); const user = repository.create({ id: 1, firstName: \"Timber\", lastName: \"Saw\" }); // same as const user = new User(); user.firstName = \"Timber\"; user.lastName = \"Saw\"; merge - Merges multiple entities into a single entity. const user = new User(); repository.merge(user, { firstName: \"Timber\" }, { lastName: \"Saw\" }); // same as user.firstName = \"Timber\"; user.lastName = \"Saw\"; preload - Creates a new entity from the given plain javascript object. If the entity already exists in the database, then it loads it (and everything related to it), replaces all values with the new ones from the given object, and returns the new entity. The new entity is actually an entity loaded from the database with all properties replaced from the new object. Note that given entity-like object must have an entity id / primary key to find entity by. Returns undefined if entity with given id was not found. const partialUser = { id: 1, firstName: \"Rizzrak\", profile: { id: 1 } }; const user = await repository.preload(partialUser); // user will contain all missing data from partialUser with partialUser property values: // { id: 1, firstName: \"Rizzrak\", lastName: \"Saw\", profile: { id: 1, ... } } save - Saves a given entity or array of entities. If the entity already exist in the database, it is updated. If the entity does not exist in the database, it is inserted. It saves all given entities in a single transaction (in the case of entity, manager is not transactional). Also supports partial updating since all undefined properties are skipped. Returns the saved entity/entities. await repository.save(user); await repository.save([ category1, category2, category3 ]); remove - Removes a given entity or array of entities. It removes all given entities in a single transaction (in the case of entity, manager is not transactional). Returns the removed entity/entities. await repository.remove(user); await repository.remove([ category1, category2, category3 ]); insert - Inserts a new entity, or array of entities. await repository.insert({ firstName: \"Timber\", lastName: \"Timber\" }); await manager.insert(User, [{ firstName: \"Foo\", lastName: \"Bar\" }, { firstName: \"Rizz\", lastName: \"Rak\" }]); update - Partially updates entity by a given update options or entity id. await repository.update({ firstName: \"Timber\" }, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE firstName = Timber await repository.update(1, { firstName: \"Rizzrak\" }); // executes UPDATE user SET firstName = Rizzrak WHERE id = 1 delete - Deletes entities by entity id, ids or given conditions: await repository.delete(1); await repository.delete([1, 2, 3]); await repository.delete({ firstName: \"Timber\" }); softDelete and restore - Soft deleting and restoring a row by id const repository = connection.getRepository(Entity); // Delete a entity await repository.softDelete(1); // And You can restore it using restore; await repository.restore(1); softRemove and recover - This is alternative to softDelete and restore . // You can soft-delete them using softRemove const entities = await repository.find(); const entitiesAfterSoftRemove = await repository.softRemove(entities); // And You can recover them using recover; await repository.recover(entitiesAfterSoftRemove); count - Counts entities that match given options. Useful for pagination. const count = await repository.count({ firstName: \"Timber\" }); increment - Increments some column by provided value of entities that match given options. await manager.increment(User, { firstName: \"Timber\" }, \"age\", 3); decrement - Decrements some column by provided value that match given options. await manager.decrement(User, { firstName: \"Timber\" }, \"age\", 3); find - Finds entities that match given options. const timbers = await repository.find({ firstName: \"Timber\" }); findAndCount - Finds entities that match given find options. Also counts all entities that match given conditions, but ignores pagination settings ( skip and take options). const [timbers, timbersCount] = await repository.findAndCount({ firstName: \"Timber\" }); findByIds - Finds multiple entities by id. const users = await repository.findByIds([1, 2, 3]); findOne - Finds first entity that matches some id or find options. const user = await repository.findOne(1); const timber = await repository.findOne({ firstName: \"Timber\" }); findOneOrFail - Finds the first entity that matches the some id or find options. Rejects the returned promise if nothing matches. const user = await repository.findOneOrFail(1); const timber = await repository.findOneOrFail({ firstName: \"Timber\" }); Note: It is strongly recommended to ensure that your id or FindOptions value is not null or undefined before calling findOne and findOneOrFail . When passed null or undefined , the query will match with every entity in the repository and return the first record. query - Executes a raw SQL query. const rawData = await repository.query(`SELECT * FROM USERS`); clear - Clears all the data from the given table (truncates/drops it). await repository.clear();","title":"Repository API"},{"location":"repository-api/#additional-options","text":"Optional SaveOptions can be passed as parameter for save . data - Additional data to be passed with persist method. This data can be used in subscribers then. listeners : boolean - Indicates if listeners and subscribers are called for this operation. By default they are enabled, you can disable them by setting { listeners: false } in save/remove options. transaction : boolean - By default transactions are enabled and all queries in persistence operation are wrapped into the transaction. You can disable this behaviour by setting { transaction: false } in the persistence options. chunk : number - Breaks save execution into multiple groups of chunks. For example, if you want to save 100.000 objects but you have issues with saving them, you can break them into 10 groups of 10.000 objects (by setting { chunk: 10000 } ) and save each group separately. This option is needed to perform very big insertions when you have issues with underlying driver parameter number limitation. reload : boolean - Flag to determine whether the entity that is being persisted should be reloaded during the persistence operation. It will work only on databases which does not support RETURNING / OUTPUT statement. Enabled by default. Example: // users contains array of User Entities userRepository.save(users, {chunk: users.length / 1000}); Optional RemoveOptions can be passed as parameter for remove and delete . data - Additional data to be passed with remove method. This data can be used in subscribers then. listener : boolean - Indicates if listeners and subscribers are called for this operation. By default they are enabled, you can disable them by setting { listeners: false } in save/remove options. transaction : boolean - By default transactions are enabled and all queries in persistence operation are wrapped into the transaction. You can disable this behaviour by setting { transaction: false } in the persistence options. chunk : number - Breaks save execution into multiple groups of chunks. For example, if you want to save 100.000 objects but you have issues saving them, you can break them into 10 groups of 10.000 objects, by setting { chunk: 10000 } , and save each group separately. This option is needed to perform very big insertions when you have issues with underlying driver parameter number limitation. Example: // users contains array of User Entities userRepository.remove(users, {chunk: entities.length / 1000});","title":"Additional Options"},{"location":"repository-api/#treerepository-api","text":"For TreeRepository API refer to the Tree Entities documentation .","title":"TreeRepository API"},{"location":"repository-api/#mongorepository-api","text":"For MongoRepository API refer to the MongoDB documentation .","title":"MongoRepository API"},{"location":"roadmap/","text":"Roadmap See what amazing new features we are expecting to land in the next TypeORM versions. Note on 1.0.0 release We are planning to release a final stable 1.0.0 version in near future. However, TypeORM is already actively used in a number of big production systems. The main API is already very stable. TypeORM follows a semantic versioning and until 1.0.0 , breaking changes may appear in 0.x.x versions. However, since the API is already quite stable we don't expect too many breaking changes. How to install latest development version? To install latest development version use the following command: npm i typeorm@next 0.3.0 [ ] research @Select and @Where decorators [ ] add addSelectAndMap functionality to QueryBuilder [ ] research internationalization features [ ] research ability to create one-to-many relations without inverse sides [ ] research ability to create a single relation with multiple entities at once [ ] more tree repository functionality [ ] cli: create database backup command [ ] extend query method functionality [ ] better internal ORM logging [ ] better error handling and user-friendly messages [ ] better JavaScript support - more docs and test coverage [ ] research NativeScript support [ ] finish naming strategy implementation [ ] implement soft deletion 0.2.0 [x] add more tree-table features: nested set and materialized path; more repository methods [x] fix Oracle driver issues and make oracle stable and ready for production use [x] implement migrations generator for all drivers [x] create example how to use TypeORM in Electron apps [x] finish subscribers and listeners implementation [x] refactor persistence mechanism [x] fix all issues with cascades and make stable functionality [x] implement API for manual migration creation [x] add sql.js driver [x] fix inheritance support issues","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"See what amazing new features we are expecting to land in the next TypeORM versions.","title":"Roadmap"},{"location":"roadmap/#note-on-100-release","text":"We are planning to release a final stable 1.0.0 version in near future. However, TypeORM is already actively used in a number of big production systems. The main API is already very stable. TypeORM follows a semantic versioning and until 1.0.0 , breaking changes may appear in 0.x.x versions. However, since the API is already quite stable we don't expect too many breaking changes.","title":"Note on 1.0.0 release"},{"location":"roadmap/#how-to-install-latest-development-version","text":"To install latest development version use the following command: npm i typeorm@next","title":"How to install latest development version?"},{"location":"roadmap/#030","text":"[ ] research @Select and @Where decorators [ ] add addSelectAndMap functionality to QueryBuilder [ ] research internationalization features [ ] research ability to create one-to-many relations without inverse sides [ ] research ability to create a single relation with multiple entities at once [ ] more tree repository functionality [ ] cli: create database backup command [ ] extend query method functionality [ ] better internal ORM logging [ ] better error handling and user-friendly messages [ ] better JavaScript support - more docs and test coverage [ ] research NativeScript support [ ] finish naming strategy implementation [ ] implement soft deletion","title":"0.3.0"},{"location":"roadmap/#020","text":"[x] add more tree-table features: nested set and materialized path; more repository methods [x] fix Oracle driver issues and make oracle stable and ready for production use [x] implement migrations generator for all drivers [x] create example how to use TypeORM in Electron apps [x] finish subscribers and listeners implementation [x] refactor persistence mechanism [x] fix all issues with cascades and make stable functionality [x] implement API for manual migration creation [x] add sql.js driver [x] fix inheritance support issues","title":"0.2.0"},{"location":"select-query-builder/","text":"Select using Query Builder What is QueryBuilder Important note when using the QueryBuilder How to create and use a QueryBuilder Getting values using QueryBuilder What are aliases for? Using parameters to escape data Adding WHERE expression Adding HAVING expression Adding ORDER BY expression Adding GROUP BY expression Adding LIMIT expression Adding OFFSET expression Joining relations Inner and left joins Join without selection Joining any entity or table Joining and mapping functionality Getting the generated query Getting raw results Streaming result data Using pagination Set locking Max execution time Partial selection Using subqueries Hidden Columns Querying Deleted rows What is QueryBuilder QueryBuilder is one of the most powerful features of TypeORM - it allows you to build SQL queries using elegant and convenient syntax, execute them and get automatically transformed entities. Simple example of QueryBuilder : const firstUser = await connection .getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); It builds the following SQL query: SELECT user.id as userId, user.firstName as userFirstName, user.lastName as userLastName FROM users user WHERE user.id = 1 and returns you an instance of User : User { id: 1, firstName: \"Timber\", lastName: \"Saw\" } Important note when using the QueryBuilder When using the QueryBuilder , you need to provide unique parameters in your WHERE expressions. This will not work : const result = await getConnection() .createQueryBuilder('user') .leftJoinAndSelect('user.linkedSheep', 'linkedSheep') .leftJoinAndSelect('user.linkedCow', 'linkedCow') .where('user.linkedSheep = :id', { id: sheepId }) .andWhere('user.linkedCow = :id', { id: cowId }); ... but this will: const result = await getConnection() .createQueryBuilder('user') .leftJoinAndSelect('user.linkedSheep', 'linkedSheep') .leftJoinAndSelect('user.linkedCow', 'linkedCow') .where('user.linkedSheep = :sheepId', { sheepId }) .andWhere('user.linkedCow = :cowId', { cowId }); Note that we uniquely named :sheepId and :cowId instead of using :id twice for different parameters. How to create and use a QueryBuilder There are several ways how you can create a Query Builder : Using connection: ```typescript import {getConnection} from \"typeorm\"; const user = await getConnection() .createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` Using entity manager: ```typescript import {getManager} from \"typeorm\"; const user = await getManager() .createQueryBuilder(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` Using repository: ```typescript import {getRepository} from \"typeorm\"; const user = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` There are 5 different QueryBuilder types available: SelectQueryBuilder - used to build and execute SELECT queries. Example: ```typescript import {getConnection} from \"typeorm\"; const user = await getConnection() .createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` InsertQueryBuilder - used to build and execute INSERT queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values([ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Phantom\", lastName: \"Lancer\" } ]) .execute(); ``` UpdateQueryBuilder - used to build and execute UPDATE queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\" }) .where(\"id = :id\", { id: 1 }) .execute(); `` * DeleteQueryBuilder - used to build and execute DELETE` queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .delete() .from(User) .where(\"id = :id\", { id: 1 }) .execute(); ``` RelationQueryBuilder - used to build and execute relation-specific operations [TBD]. You can switch between different types of query builder within any of them, once you do, you will get a new instance of query builder (unlike all other methods). Getting values using QueryBuilder To get a single result from the database, for example to get a user by id or name, you must use getOne : const timber = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id OR user.name = :name\", { id: 1, name: \"Timber\" }) .getOne(); getOneOrFail will get a single result from the database, but if no result exists it will throw an EntityNotFoundError : const timber = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id OR user.name = :name\", { id: 1, name: \"Timber\" }) .getOneOrFail(); To get multiple results from the database, for example, to get all users from the database, use getMany : const users = await getRepository(User) .createQueryBuilder(\"user\") .getMany(); There are two types of results you can get using select query builder: entities or raw results . Most of the time, you need to select real entities from your database, for example, users. For this purpose, you use getOne and getMany . But sometimes you need to select some specific data, let's say the sum of all user photos . This data is not an entity, it's called raw data. To get raw data, you use getRawOne and getRawMany . Examples: const { sum } = await getRepository(User) .createQueryBuilder(\"user\") .select(\"SUM(user.photosCount)\", \"sum\") .where(\"user.id = :id\", { id: 1 }) .getRawOne(); const photosSums = await getRepository(User) .createQueryBuilder(\"user\") .select(\"user.id\") .addSelect(\"SUM(user.photosCount)\", \"sum\") .groupBy(\"user.id\") .getRawMany(); // result will be like this: [{ id: 1, sum: 25 }, { id: 2, sum: 13 }, ...] What are aliases for? We used createQueryBuilder(\"user\") . But what is \"user\"? It's just a regular SQL alias. We use aliases everywhere, except when we work with selected data. createQueryBuilder(\"user\") is equivalent to: createQueryBuilder() .select(\"user\") .from(User, \"user\") Which will result in the following sql query: SELECT ... FROM users user In this SQL query, users is the table name, and user is an alias we assign to this table. Later we use this alias to access the table: createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.name = :name\", { name: \"Timber\" }) Which produces the following SQL query: SELECT ... FROM users user WHERE user.name = 'Timber' See, we used the users table by using the user alias we assigned when we created a query builder. One query builder is not limited to one alias, they can have multiple aliases. Each select can have its own alias, you can select from multiple tables each with its own alias, you can join multiple tables each with its own alias. You can use those aliases to access tables are you selecting (or data you are selecting). Using parameters to escape data We used where(\"user.name = :name\", { name: \"Timber\" }) . What does { name: \"Timber\" } stand for? It's a parameter we used to prevent SQL injection. We could have written: where(\"user.name = '\" + name + \"') , however this is not safe, as it opens the code to SQL injections. The safe way is to use this special syntax: where(\"user.name = :name\", { name: \"Timber\" }) , where :name is a parameter name and the value is specified in an object: { name: \"Timber\" } . .where(\"user.name = :name\", { name: \"Timber\" }) is a shortcut for: .where(\"user.name = :name\") .setParameter(\"name\", \"Timber\") Note: do not use the same parameter name for different values across the query builder. Values will be overridden if you set them multiple times. You can also supply an array of values, and have them transformed into a list of values in the SQL statement, by using the special expansion syntax: .where(\"user.name IN (:...names)\", { names: [ \"Timber\", \"Cristal\", \"Lina\" ] }) Which becomes: WHERE user.name IN ('Timber', 'Cristal', 'Lina') Adding WHERE expression Adding a WHERE expression is as easy as: createQueryBuilder(\"user\") .where(\"user.name = :name\", { name: \"Timber\" }) Which will produce: SELECT ... FROM users user WHERE user.name = 'Timber' You can add AND into an existing WHERE expression: createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .andWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user WHERE user.firstName = 'Timber' AND user.lastName = 'Saw' You can add OR into an existing WHERE expression: createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user WHERE user.firstName = 'Timber' OR user.lastName = 'Saw' You can do an IN query with the WHERE expression: createQueryBuilder(\"user\") .where(\"user.id IN (:...ids)\", { ids: [1, 2, 3, 4] }) Which will produce the following SQL query: SELECT ... FROM users user WHERE user.id IN (1, 2, 3, 4) You can add a complex WHERE expression into an existing WHERE using Brackets createQueryBuilder(\"user\") .where(\"user.registered = :registered\", { registered: true }) .andWhere(new Brackets(qb => { qb.where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) })) Which will produce the following SQL query: SELECT ... FROM users user WHERE user.registered = true AND (user.firstName = 'Timber' OR user.lastName = 'Saw') You can combine as many AND and OR expressions as you need. If you use .where more than once you'll override all previous WHERE expressions. Note: be careful with orWhere - if you use complex expressions with both AND and OR expressions, keep in mind that they are stacked without any pretences. Sometimes you'll need to create a where string instead, and avoid using orWhere . Adding HAVING expression Adding a HAVING expression is easy as: createQueryBuilder(\"user\") .having(\"user.name = :name\", { name: \"Timber\" }) Which will produce following SQL query: SELECT ... FROM users user HAVING user.name = 'Timber' You can add AND into an exist HAVING expression: createQueryBuilder(\"user\") .having(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .andHaving(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user HAVING user.firstName = 'Timber' AND user.lastName = 'Saw' You can add OR into a exist HAVING expression: createQueryBuilder(\"user\") .having(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orHaving(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user HAVING user.firstName = 'Timber' OR user.lastName = 'Saw' You can combine as many AND and OR expressions as you need. If you use .having more than once you'll override all previous HAVING expressions. Adding ORDER BY expression Adding an ORDER BY expression is easy as: createQueryBuilder(\"user\") .orderBy(\"user.id\") Which will produce: SELECT ... FROM users user ORDER BY user.id You can change the ordering direction from ascending to descending (or versa): createQueryBuilder(\"user\") .orderBy(\"user.id\", \"DESC\") createQueryBuilder(\"user\") .orderBy(\"user.id\", \"ASC\") You can add multiple order-by criteria: createQueryBuilder(\"user\") .orderBy(\"user.name\") .addOrderBy(\"user.id\"); You can also use a map of order-by fields: createQueryBuilder(\"user\") .orderBy({ \"user.name\": \"ASC\", \"user.id\": \"DESC\" }); If you use .orderBy more than once you'll override all previous ORDER BY expressions. Adding DISTINCT ON expression (Postgres only) When using both distinct-on with an order-by expression, the distinct-on expression must match the leftmost order-by. The distinct-on expressions are interpreted using the same rules as order-by. Please note that, using distinct-on without an order-by expression means that the first row of each set is unpredictable. Adding a DISTINCT ON expression is easy as: createQueryBuilder(\"user\") .distinctOn([\"user.id\"]) .orderBy(\"user.id\") Which will produce: SELECT DISTINCT ON (user.id) ... FROM users user ORDER BY user.id Adding GROUP BY expression Adding a GROUP BY expression is easy as: createQueryBuilder(\"user\") .groupBy(\"user.id\") Which will produce the following SQL query: SELECT ... FROM users user GROUP BY user.id To add more group-by criteria use addGroupBy : createQueryBuilder(\"user\") .groupBy(\"user.name\") .addGroupBy(\"user.id\"); If you use .groupBy more than once you'll override all previous GROUP BY expressions. Adding LIMIT expression Adding a LIMIT expression is easy as: createQueryBuilder(\"user\") .limit(10) Which will produce the following SQL query: SELECT ... FROM users user LIMIT 10 The resulting SQL query depends on the type of database (SQL, mySQL, Postgres, etc). Note: LIMIT may not work as you may expect if you are using complex queries with joins or subqueries. If you are using pagination, it's recommended to use take instead. Adding OFFSET expression Adding an SQL OFFSET expression is easy as: createQueryBuilder(\"user\") .offset(10) Which will produce the following SQL query: SELECT ... FROM users user OFFSET 10 The resulting SQL query depends on the type of database (SQL, mySQL, Postgres, etc). Note: OFFSET may not work as you may expect if you are using complex queries with joins or subqueries. If you are using pagination, it's recommended to use skip instead. Joining relations Let's say you have the following entities: import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(type => Photo, photo => photo.user) photos: Photo[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(type => User, user => user.photos) user: User; } Now let's say you want to load user \"Timber\" with all of his photos: const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); You'll get the following result: { id: 1, name: \"Timber\", photos: [{ id: 1, url: \"me-with-chakram.jpg\" }, { id: 2, url: \"me-with-trees.jpg\" }] } As you can see leftJoinAndSelect automatically loaded all of Timber's photos. The first argument is the relation you want to load and the second argument is an alias you assign to this relation's table. You can use this alias anywhere in query builder. For example, let's take all Timber's photos which aren't removed. const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .andWhere(\"photo.isRemoved = :isRemoved\", { isRemoved: false }) .getOne(); This will generate following sql query: SELECT user.*, photo.* FROM users user LEFT JOIN photos photo ON photo.user = user.id WHERE user.name = 'Timber' AND photo.isRemoved = FALSE You can also add conditions to the join expression instead of using \"where\": const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\", \"photo.isRemoved = :isRemoved\", { isRemoved: false }) .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate the following sql query: SELECT user.*, photo.* FROM users user LEFT JOIN photos photo ON photo.user = user.id AND photo.isRemoved = FALSE WHERE user.name = 'Timber' Inner and left joins If you want to use INNER JOIN instead of LEFT JOIN just use innerJoinAndSelect instead: const user = await createQueryBuilder(\"user\") .innerJoinAndSelect(\"user.photos\", \"photo\", \"photo.isRemoved = :isRemoved\", { isRemoved: false }) .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate: SELECT user.*, photo.* FROM users user INNER JOIN photos photo ON photo.user = user.id AND photo.isRemoved = FALSE WHERE user.name = 'Timber' The difference between LEFT JOIN and INNER JOIN is that INNER JOIN won't return a user if it does not have any photos. LEFT JOIN will return you the user even if it doesn't have photos. To learn more about different join types, refer to the SQL documentation . Join without selection You can join data without its selection. To do that, use leftJoin or innerJoin : const user = await createQueryBuilder(\"user\") .innerJoin(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate: SELECT user.* FROM users user INNER JOIN photos photo ON photo.user = user.id WHERE user.name = 'Timber' This will select Timber if he has photos, but won't return his photos. Joining any entity or table You can join not only relations, but also other unrelated entities or tables. Examples: const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(Photo, \"photo\", \"photo.userId = user.id\") .getMany(); const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"photos\", \"photo\", \"photo.userId = user.id\") .getMany(); Joining and mapping functionality Add profilePhoto to User entity and you can map any data into that property using QueryBuilder : export class User { /// ... profilePhoto: Photo; } const user = await createQueryBuilder(\"user\") .leftJoinAndMapOne(\"user.profilePhoto\", \"user.photos\", \"photo\", \"photo.isForProfile = TRUE\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will load Timber's profile photo and set it to user.profilePhoto . If you want to load and map a single entity use leftJoinAndMapOne . If you want to load and map multiple entities use leftJoinAndMapMany . Getting the generated query Sometimes you may want to get the SQL query generated by QueryBuilder . To do so, use getSql : const sql = createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) .getSql(); For debugging purposes you can use printSql : const users = await createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) .printSql() .getMany(); This query will return users and print the used sql statement to the console. Getting raw results There are two types of results you can get using select query builder: entities and raw results . Most of the time, you need to select real entities from your database, for example, users. For this purpose, you use getOne and getMany . However, sometimes you need to select specific data, like the sum of all user photos . Such data is not a entity, it's called raw data. To get raw data, you use getRawOne and getRawMany . Examples: const { sum } = await getRepository(User) .createQueryBuilder(\"user\") .select(\"SUM(user.photosCount)\", \"sum\") .where(\"user.id = :id\", { id: 1 }) .getRawOne(); const photosSums = await getRepository(User) .createQueryBuilder(\"user\") .select(\"user.id\") .addSelect(\"SUM(user.photosCount)\", \"sum\") .groupBy(\"user.id\") .getRawMany(); // result will be like this: [{ id: 1, sum: 25 }, { id: 2, sum: 13 }, ...] Streaming result data You can use stream which returns you a stream. Streaming returns you raw data and you must handle entity transformation manually: const stream = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .stream(); Using pagination Most of the time when you develop an application, you need pagination functionality. This is used if you have pagination, page slider, or infinite scroll components in your application. const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .take(10) .getMany(); This will give you the first 10 users with their photos. const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .skip(10) .getMany(); This will give you all except the first 10 users with their photos. You can combine those methods: const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .skip(5) .take(10) .getMany(); This will skip the first 5 users and take 10 users after them. take and skip may look like we are using limit and offset , but they aren't. limit and offset may not work as you expect once you have more complicated queries with joins or subqueries. Using take and skip will prevent those issues. Set locking QueryBuilder supports both optimistic and pessimistic locking. To use pessimistic read locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"pessimistic_read\") .getMany(); To use pessimistic write locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"pessimistic_write\") .getMany(); To use dirty read locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"dirty_read\") .getMany(); To use optimistic locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"optimistic\", existUser.version) .getMany(); Optimistic locking works in conjunction with both @Version and @UpdatedDate decorators. Max execution time We can drop slow query to avoid crashing the server. Only MySQL driver is supported at the moment: const users = await getRepository(User) .createQueryBuilder(\"user\") .maxExecutionTime(1000) // milliseconds. .getMany(); Partial selection If you want to select only some entity properties, you can use the following syntax: const users = await getRepository(User) .createQueryBuilder(\"user\") .select([ \"user.id\", \"user.name\" ]) .getMany(); This will only select the id and name of User . Using subqueries You can easily create subqueries. Subqueries are supported in FROM , WHERE and JOIN expressions. Example: const qb = await getRepository(Post).createQueryBuilder(\"post\"); const posts = qb .where(\"post.title IN \" + qb.subQuery().select(\"user.name\").from(User, \"user\").where(\"user.registered = :registered\").getQuery()) .setParameter(\"registered\", true) .getMany(); A more elegant way to do the same: const posts = await connection.getRepository(Post) .createQueryBuilder(\"post\") .where(qb => { const subQuery = qb.subQuery() .select(\"user.name\") .from(User, \"user\") .where(\"user.registered = :registered\") .getQuery(); return \"post.title IN \" + subQuery; }) .setParameter(\"registered\", true) .getMany(); Alternatively, you can create a separate query builder and use its generated SQL: const userQb = await connection.getRepository(User) .createQueryBuilder(\"user\") .select(\"user.name\") .where(\"user.registered = :registered\", { registered: true }); const posts = await connection.getRepository(Post) .createQueryBuilder(\"post\") .where(\"post.title IN (\" + userQb.getQuery() + \")\") .setParameters(userQb.getParameters()) .getMany(); You can create subqueries in FROM like this: const userQb = await connection.getRepository(User) .createQueryBuilder(\"user\") .select(\"user.name\", \"name\") .where(\"user.registered = :registered\", { registered: true }); const posts = await connection .createQueryBuilder() .select(\"user.name\", \"name\") .from(\"(\" + userQb.getQuery() + \")\", \"user\") .setParameters(userQb.getParameters()) .getRawMany(); or using more a elegant syntax: const posts = await connection .createQueryBuilder() .select(\"user.name\", \"name\") .from(subQuery => { return subQuery .select(\"user.name\", \"name\") .from(User, \"user\") .where(\"user.registered = :registered\", { registered: true }); }, \"user\") .getRawMany(); If you want to add a subselect as a \"second from\" use addFrom . You can use subselects in SELECT statements as well: const posts = await connection .createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(subQuery => { return subQuery .select(\"user.name\", \"name\") .from(User, \"user\") .limit(1); }, \"name\") .from(Post, \"post\") .getRawMany(); Hidden Columns If the model you are querying has a column with a select: false column, you must use the addSelect function in order to retrieve the information from the column. Let's say you have the following entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column({select: false}) password: string; } Using a standard find or query, you will not receive the password property for the model. However, if you do the following: const users = await connection.getRepository(User) .createQueryBuilder() .select(\"user.id\", \"id\") .addSelect(\"user.password\") .getMany(); You will get the property password in your query. Querying Deleted rows If the model you are querying has a column with the attribute @DeleteDateColumn set, the query builder will automatically query rows which are 'soft deleted'. Let's say you have the following entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @DeleteDateColumn() deletedAt?: Date; } Using a standard find or query, you will not receive the rows which have a value in that row. However, if you do the following: const users = await connection.getRepository(User) .createQueryBuilder() .select(\"user.id\", \"id\") .withDeleted() .getMany(); You will get all the rows, including the ones which are deleted.","title":"Select using Query Builder"},{"location":"select-query-builder/#select-using-query-builder","text":"What is QueryBuilder Important note when using the QueryBuilder How to create and use a QueryBuilder Getting values using QueryBuilder What are aliases for? Using parameters to escape data Adding WHERE expression Adding HAVING expression Adding ORDER BY expression Adding GROUP BY expression Adding LIMIT expression Adding OFFSET expression Joining relations Inner and left joins Join without selection Joining any entity or table Joining and mapping functionality Getting the generated query Getting raw results Streaming result data Using pagination Set locking Max execution time Partial selection Using subqueries Hidden Columns Querying Deleted rows","title":"Select using Query Builder"},{"location":"select-query-builder/#what-is-querybuilder","text":"QueryBuilder is one of the most powerful features of TypeORM - it allows you to build SQL queries using elegant and convenient syntax, execute them and get automatically transformed entities. Simple example of QueryBuilder : const firstUser = await connection .getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); It builds the following SQL query: SELECT user.id as userId, user.firstName as userFirstName, user.lastName as userLastName FROM users user WHERE user.id = 1 and returns you an instance of User : User { id: 1, firstName: \"Timber\", lastName: \"Saw\" }","title":"What is QueryBuilder"},{"location":"select-query-builder/#important-note-when-using-the-querybuilder","text":"When using the QueryBuilder , you need to provide unique parameters in your WHERE expressions. This will not work : const result = await getConnection() .createQueryBuilder('user') .leftJoinAndSelect('user.linkedSheep', 'linkedSheep') .leftJoinAndSelect('user.linkedCow', 'linkedCow') .where('user.linkedSheep = :id', { id: sheepId }) .andWhere('user.linkedCow = :id', { id: cowId }); ... but this will: const result = await getConnection() .createQueryBuilder('user') .leftJoinAndSelect('user.linkedSheep', 'linkedSheep') .leftJoinAndSelect('user.linkedCow', 'linkedCow') .where('user.linkedSheep = :sheepId', { sheepId }) .andWhere('user.linkedCow = :cowId', { cowId }); Note that we uniquely named :sheepId and :cowId instead of using :id twice for different parameters.","title":"Important note when using the QueryBuilder"},{"location":"select-query-builder/#how-to-create-and-use-a-querybuilder","text":"There are several ways how you can create a Query Builder : Using connection: ```typescript import {getConnection} from \"typeorm\"; const user = await getConnection() .createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` Using entity manager: ```typescript import {getManager} from \"typeorm\"; const user = await getManager() .createQueryBuilder(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` Using repository: ```typescript import {getRepository} from \"typeorm\"; const user = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` There are 5 different QueryBuilder types available: SelectQueryBuilder - used to build and execute SELECT queries. Example: ```typescript import {getConnection} from \"typeorm\"; const user = await getConnection() .createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.id = :id\", { id: 1 }) .getOne(); ``` InsertQueryBuilder - used to build and execute INSERT queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .insert() .into(User) .values([ { firstName: \"Timber\", lastName: \"Saw\" }, { firstName: \"Phantom\", lastName: \"Lancer\" } ]) .execute(); ``` UpdateQueryBuilder - used to build and execute UPDATE queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\" }) .where(\"id = :id\", { id: 1 }) .execute(); `` * DeleteQueryBuilder - used to build and execute DELETE` queries. Example: ```typescript import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .delete() .from(User) .where(\"id = :id\", { id: 1 }) .execute(); ``` RelationQueryBuilder - used to build and execute relation-specific operations [TBD]. You can switch between different types of query builder within any of them, once you do, you will get a new instance of query builder (unlike all other methods).","title":"How to create and use a QueryBuilder"},{"location":"select-query-builder/#getting-values-using-querybuilder","text":"To get a single result from the database, for example to get a user by id or name, you must use getOne : const timber = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id OR user.name = :name\", { id: 1, name: \"Timber\" }) .getOne(); getOneOrFail will get a single result from the database, but if no result exists it will throw an EntityNotFoundError : const timber = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id OR user.name = :name\", { id: 1, name: \"Timber\" }) .getOneOrFail(); To get multiple results from the database, for example, to get all users from the database, use getMany : const users = await getRepository(User) .createQueryBuilder(\"user\") .getMany(); There are two types of results you can get using select query builder: entities or raw results . Most of the time, you need to select real entities from your database, for example, users. For this purpose, you use getOne and getMany . But sometimes you need to select some specific data, let's say the sum of all user photos . This data is not an entity, it's called raw data. To get raw data, you use getRawOne and getRawMany . Examples: const { sum } = await getRepository(User) .createQueryBuilder(\"user\") .select(\"SUM(user.photosCount)\", \"sum\") .where(\"user.id = :id\", { id: 1 }) .getRawOne(); const photosSums = await getRepository(User) .createQueryBuilder(\"user\") .select(\"user.id\") .addSelect(\"SUM(user.photosCount)\", \"sum\") .groupBy(\"user.id\") .getRawMany(); // result will be like this: [{ id: 1, sum: 25 }, { id: 2, sum: 13 }, ...]","title":"Getting values using QueryBuilder"},{"location":"select-query-builder/#what-are-aliases-for","text":"We used createQueryBuilder(\"user\") . But what is \"user\"? It's just a regular SQL alias. We use aliases everywhere, except when we work with selected data. createQueryBuilder(\"user\") is equivalent to: createQueryBuilder() .select(\"user\") .from(User, \"user\") Which will result in the following sql query: SELECT ... FROM users user In this SQL query, users is the table name, and user is an alias we assign to this table. Later we use this alias to access the table: createQueryBuilder() .select(\"user\") .from(User, \"user\") .where(\"user.name = :name\", { name: \"Timber\" }) Which produces the following SQL query: SELECT ... FROM users user WHERE user.name = 'Timber' See, we used the users table by using the user alias we assigned when we created a query builder. One query builder is not limited to one alias, they can have multiple aliases. Each select can have its own alias, you can select from multiple tables each with its own alias, you can join multiple tables each with its own alias. You can use those aliases to access tables are you selecting (or data you are selecting).","title":"What are aliases for?"},{"location":"select-query-builder/#using-parameters-to-escape-data","text":"We used where(\"user.name = :name\", { name: \"Timber\" }) . What does { name: \"Timber\" } stand for? It's a parameter we used to prevent SQL injection. We could have written: where(\"user.name = '\" + name + \"') , however this is not safe, as it opens the code to SQL injections. The safe way is to use this special syntax: where(\"user.name = :name\", { name: \"Timber\" }) , where :name is a parameter name and the value is specified in an object: { name: \"Timber\" } . .where(\"user.name = :name\", { name: \"Timber\" }) is a shortcut for: .where(\"user.name = :name\") .setParameter(\"name\", \"Timber\") Note: do not use the same parameter name for different values across the query builder. Values will be overridden if you set them multiple times. You can also supply an array of values, and have them transformed into a list of values in the SQL statement, by using the special expansion syntax: .where(\"user.name IN (:...names)\", { names: [ \"Timber\", \"Cristal\", \"Lina\" ] }) Which becomes: WHERE user.name IN ('Timber', 'Cristal', 'Lina')","title":"Using parameters to escape data"},{"location":"select-query-builder/#adding-where-expression","text":"Adding a WHERE expression is as easy as: createQueryBuilder(\"user\") .where(\"user.name = :name\", { name: \"Timber\" }) Which will produce: SELECT ... FROM users user WHERE user.name = 'Timber' You can add AND into an existing WHERE expression: createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .andWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user WHERE user.firstName = 'Timber' AND user.lastName = 'Saw' You can add OR into an existing WHERE expression: createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user WHERE user.firstName = 'Timber' OR user.lastName = 'Saw' You can do an IN query with the WHERE expression: createQueryBuilder(\"user\") .where(\"user.id IN (:...ids)\", { ids: [1, 2, 3, 4] }) Which will produce the following SQL query: SELECT ... FROM users user WHERE user.id IN (1, 2, 3, 4) You can add a complex WHERE expression into an existing WHERE using Brackets createQueryBuilder(\"user\") .where(\"user.registered = :registered\", { registered: true }) .andWhere(new Brackets(qb => { qb.where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) })) Which will produce the following SQL query: SELECT ... FROM users user WHERE user.registered = true AND (user.firstName = 'Timber' OR user.lastName = 'Saw') You can combine as many AND and OR expressions as you need. If you use .where more than once you'll override all previous WHERE expressions. Note: be careful with orWhere - if you use complex expressions with both AND and OR expressions, keep in mind that they are stacked without any pretences. Sometimes you'll need to create a where string instead, and avoid using orWhere .","title":"Adding WHERE expression"},{"location":"select-query-builder/#adding-having-expression","text":"Adding a HAVING expression is easy as: createQueryBuilder(\"user\") .having(\"user.name = :name\", { name: \"Timber\" }) Which will produce following SQL query: SELECT ... FROM users user HAVING user.name = 'Timber' You can add AND into an exist HAVING expression: createQueryBuilder(\"user\") .having(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .andHaving(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user HAVING user.firstName = 'Timber' AND user.lastName = 'Saw' You can add OR into a exist HAVING expression: createQueryBuilder(\"user\") .having(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orHaving(\"user.lastName = :lastName\", { lastName: \"Saw\" }); Which will produce the following SQL query: SELECT ... FROM users user HAVING user.firstName = 'Timber' OR user.lastName = 'Saw' You can combine as many AND and OR expressions as you need. If you use .having more than once you'll override all previous HAVING expressions.","title":"Adding HAVING expression"},{"location":"select-query-builder/#adding-order-by-expression","text":"Adding an ORDER BY expression is easy as: createQueryBuilder(\"user\") .orderBy(\"user.id\") Which will produce: SELECT ... FROM users user ORDER BY user.id You can change the ordering direction from ascending to descending (or versa): createQueryBuilder(\"user\") .orderBy(\"user.id\", \"DESC\") createQueryBuilder(\"user\") .orderBy(\"user.id\", \"ASC\") You can add multiple order-by criteria: createQueryBuilder(\"user\") .orderBy(\"user.name\") .addOrderBy(\"user.id\"); You can also use a map of order-by fields: createQueryBuilder(\"user\") .orderBy({ \"user.name\": \"ASC\", \"user.id\": \"DESC\" }); If you use .orderBy more than once you'll override all previous ORDER BY expressions.","title":"Adding ORDER BY expression"},{"location":"select-query-builder/#adding-distinct-on-expression-postgres-only","text":"When using both distinct-on with an order-by expression, the distinct-on expression must match the leftmost order-by. The distinct-on expressions are interpreted using the same rules as order-by. Please note that, using distinct-on without an order-by expression means that the first row of each set is unpredictable. Adding a DISTINCT ON expression is easy as: createQueryBuilder(\"user\") .distinctOn([\"user.id\"]) .orderBy(\"user.id\") Which will produce: SELECT DISTINCT ON (user.id) ... FROM users user ORDER BY user.id","title":"Adding DISTINCT ON expression (Postgres only)"},{"location":"select-query-builder/#adding-group-by-expression","text":"Adding a GROUP BY expression is easy as: createQueryBuilder(\"user\") .groupBy(\"user.id\") Which will produce the following SQL query: SELECT ... FROM users user GROUP BY user.id To add more group-by criteria use addGroupBy : createQueryBuilder(\"user\") .groupBy(\"user.name\") .addGroupBy(\"user.id\"); If you use .groupBy more than once you'll override all previous GROUP BY expressions.","title":"Adding GROUP BY expression"},{"location":"select-query-builder/#adding-limit-expression","text":"Adding a LIMIT expression is easy as: createQueryBuilder(\"user\") .limit(10) Which will produce the following SQL query: SELECT ... FROM users user LIMIT 10 The resulting SQL query depends on the type of database (SQL, mySQL, Postgres, etc). Note: LIMIT may not work as you may expect if you are using complex queries with joins or subqueries. If you are using pagination, it's recommended to use take instead.","title":"Adding LIMIT expression"},{"location":"select-query-builder/#adding-offset-expression","text":"Adding an SQL OFFSET expression is easy as: createQueryBuilder(\"user\") .offset(10) Which will produce the following SQL query: SELECT ... FROM users user OFFSET 10 The resulting SQL query depends on the type of database (SQL, mySQL, Postgres, etc). Note: OFFSET may not work as you may expect if you are using complex queries with joins or subqueries. If you are using pagination, it's recommended to use skip instead.","title":"Adding OFFSET expression"},{"location":"select-query-builder/#joining-relations","text":"Let's say you have the following entities: import {Entity, PrimaryGeneratedColumn, Column, OneToMany} from \"typeorm\"; import {Photo} from \"./Photo\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @OneToMany(type => Photo, photo => photo.user) photos: Photo[]; } import {Entity, PrimaryGeneratedColumn, Column, ManyToOne} from \"typeorm\"; import {User} from \"./User\"; @Entity() export class Photo { @PrimaryGeneratedColumn() id: number; @Column() url: string; @ManyToOne(type => User, user => user.photos) user: User; } Now let's say you want to load user \"Timber\" with all of his photos: const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); You'll get the following result: { id: 1, name: \"Timber\", photos: [{ id: 1, url: \"me-with-chakram.jpg\" }, { id: 2, url: \"me-with-trees.jpg\" }] } As you can see leftJoinAndSelect automatically loaded all of Timber's photos. The first argument is the relation you want to load and the second argument is an alias you assign to this relation's table. You can use this alias anywhere in query builder. For example, let's take all Timber's photos which aren't removed. const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .andWhere(\"photo.isRemoved = :isRemoved\", { isRemoved: false }) .getOne(); This will generate following sql query: SELECT user.*, photo.* FROM users user LEFT JOIN photos photo ON photo.user = user.id WHERE user.name = 'Timber' AND photo.isRemoved = FALSE You can also add conditions to the join expression instead of using \"where\": const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\", \"photo.isRemoved = :isRemoved\", { isRemoved: false }) .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate the following sql query: SELECT user.*, photo.* FROM users user LEFT JOIN photos photo ON photo.user = user.id AND photo.isRemoved = FALSE WHERE user.name = 'Timber'","title":"Joining relations"},{"location":"select-query-builder/#inner-and-left-joins","text":"If you want to use INNER JOIN instead of LEFT JOIN just use innerJoinAndSelect instead: const user = await createQueryBuilder(\"user\") .innerJoinAndSelect(\"user.photos\", \"photo\", \"photo.isRemoved = :isRemoved\", { isRemoved: false }) .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate: SELECT user.*, photo.* FROM users user INNER JOIN photos photo ON photo.user = user.id AND photo.isRemoved = FALSE WHERE user.name = 'Timber' The difference between LEFT JOIN and INNER JOIN is that INNER JOIN won't return a user if it does not have any photos. LEFT JOIN will return you the user even if it doesn't have photos. To learn more about different join types, refer to the SQL documentation .","title":"Inner and left joins"},{"location":"select-query-builder/#join-without-selection","text":"You can join data without its selection. To do that, use leftJoin or innerJoin : const user = await createQueryBuilder(\"user\") .innerJoin(\"user.photos\", \"photo\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will generate: SELECT user.* FROM users user INNER JOIN photos photo ON photo.user = user.id WHERE user.name = 'Timber' This will select Timber if he has photos, but won't return his photos.","title":"Join without selection"},{"location":"select-query-builder/#joining-any-entity-or-table","text":"You can join not only relations, but also other unrelated entities or tables. Examples: const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(Photo, \"photo\", \"photo.userId = user.id\") .getMany(); const user = await createQueryBuilder(\"user\") .leftJoinAndSelect(\"photos\", \"photo\", \"photo.userId = user.id\") .getMany();","title":"Joining any entity or table"},{"location":"select-query-builder/#joining-and-mapping-functionality","text":"Add profilePhoto to User entity and you can map any data into that property using QueryBuilder : export class User { /// ... profilePhoto: Photo; } const user = await createQueryBuilder(\"user\") .leftJoinAndMapOne(\"user.profilePhoto\", \"user.photos\", \"photo\", \"photo.isForProfile = TRUE\") .where(\"user.name = :name\", { name: \"Timber\" }) .getOne(); This will load Timber's profile photo and set it to user.profilePhoto . If you want to load and map a single entity use leftJoinAndMapOne . If you want to load and map multiple entities use leftJoinAndMapMany .","title":"Joining and mapping functionality"},{"location":"select-query-builder/#getting-the-generated-query","text":"Sometimes you may want to get the SQL query generated by QueryBuilder . To do so, use getSql : const sql = createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) .getSql(); For debugging purposes you can use printSql : const users = await createQueryBuilder(\"user\") .where(\"user.firstName = :firstName\", { firstName: \"Timber\" }) .orWhere(\"user.lastName = :lastName\", { lastName: \"Saw\" }) .printSql() .getMany(); This query will return users and print the used sql statement to the console.","title":"Getting the generated query"},{"location":"select-query-builder/#getting-raw-results","text":"There are two types of results you can get using select query builder: entities and raw results . Most of the time, you need to select real entities from your database, for example, users. For this purpose, you use getOne and getMany . However, sometimes you need to select specific data, like the sum of all user photos . Such data is not a entity, it's called raw data. To get raw data, you use getRawOne and getRawMany . Examples: const { sum } = await getRepository(User) .createQueryBuilder(\"user\") .select(\"SUM(user.photosCount)\", \"sum\") .where(\"user.id = :id\", { id: 1 }) .getRawOne(); const photosSums = await getRepository(User) .createQueryBuilder(\"user\") .select(\"user.id\") .addSelect(\"SUM(user.photosCount)\", \"sum\") .groupBy(\"user.id\") .getRawMany(); // result will be like this: [{ id: 1, sum: 25 }, { id: 2, sum: 13 }, ...]","title":"Getting raw results"},{"location":"select-query-builder/#streaming-result-data","text":"You can use stream which returns you a stream. Streaming returns you raw data and you must handle entity transformation manually: const stream = await getRepository(User) .createQueryBuilder(\"user\") .where(\"user.id = :id\", { id: 1 }) .stream();","title":"Streaming result data"},{"location":"select-query-builder/#using-pagination","text":"Most of the time when you develop an application, you need pagination functionality. This is used if you have pagination, page slider, or infinite scroll components in your application. const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .take(10) .getMany(); This will give you the first 10 users with their photos. const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .skip(10) .getMany(); This will give you all except the first 10 users with their photos. You can combine those methods: const users = await getRepository(User) .createQueryBuilder(\"user\") .leftJoinAndSelect(\"user.photos\", \"photo\") .skip(5) .take(10) .getMany(); This will skip the first 5 users and take 10 users after them. take and skip may look like we are using limit and offset , but they aren't. limit and offset may not work as you expect once you have more complicated queries with joins or subqueries. Using take and skip will prevent those issues.","title":"Using pagination"},{"location":"select-query-builder/#set-locking","text":"QueryBuilder supports both optimistic and pessimistic locking. To use pessimistic read locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"pessimistic_read\") .getMany(); To use pessimistic write locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"pessimistic_write\") .getMany(); To use dirty read locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"dirty_read\") .getMany(); To use optimistic locking use the following method: const users = await getRepository(User) .createQueryBuilder(\"user\") .setLock(\"optimistic\", existUser.version) .getMany(); Optimistic locking works in conjunction with both @Version and @UpdatedDate decorators.","title":"Set locking"},{"location":"select-query-builder/#max-execution-time","text":"We can drop slow query to avoid crashing the server. Only MySQL driver is supported at the moment: const users = await getRepository(User) .createQueryBuilder(\"user\") .maxExecutionTime(1000) // milliseconds. .getMany();","title":"Max execution time"},{"location":"select-query-builder/#partial-selection","text":"If you want to select only some entity properties, you can use the following syntax: const users = await getRepository(User) .createQueryBuilder(\"user\") .select([ \"user.id\", \"user.name\" ]) .getMany(); This will only select the id and name of User .","title":"Partial selection"},{"location":"select-query-builder/#using-subqueries","text":"You can easily create subqueries. Subqueries are supported in FROM , WHERE and JOIN expressions. Example: const qb = await getRepository(Post).createQueryBuilder(\"post\"); const posts = qb .where(\"post.title IN \" + qb.subQuery().select(\"user.name\").from(User, \"user\").where(\"user.registered = :registered\").getQuery()) .setParameter(\"registered\", true) .getMany(); A more elegant way to do the same: const posts = await connection.getRepository(Post) .createQueryBuilder(\"post\") .where(qb => { const subQuery = qb.subQuery() .select(\"user.name\") .from(User, \"user\") .where(\"user.registered = :registered\") .getQuery(); return \"post.title IN \" + subQuery; }) .setParameter(\"registered\", true) .getMany(); Alternatively, you can create a separate query builder and use its generated SQL: const userQb = await connection.getRepository(User) .createQueryBuilder(\"user\") .select(\"user.name\") .where(\"user.registered = :registered\", { registered: true }); const posts = await connection.getRepository(Post) .createQueryBuilder(\"post\") .where(\"post.title IN (\" + userQb.getQuery() + \")\") .setParameters(userQb.getParameters()) .getMany(); You can create subqueries in FROM like this: const userQb = await connection.getRepository(User) .createQueryBuilder(\"user\") .select(\"user.name\", \"name\") .where(\"user.registered = :registered\", { registered: true }); const posts = await connection .createQueryBuilder() .select(\"user.name\", \"name\") .from(\"(\" + userQb.getQuery() + \")\", \"user\") .setParameters(userQb.getParameters()) .getRawMany(); or using more a elegant syntax: const posts = await connection .createQueryBuilder() .select(\"user.name\", \"name\") .from(subQuery => { return subQuery .select(\"user.name\", \"name\") .from(User, \"user\") .where(\"user.registered = :registered\", { registered: true }); }, \"user\") .getRawMany(); If you want to add a subselect as a \"second from\" use addFrom . You can use subselects in SELECT statements as well: const posts = await connection .createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(subQuery => { return subQuery .select(\"user.name\", \"name\") .from(User, \"user\") .limit(1); }, \"name\") .from(Post, \"post\") .getRawMany();","title":"Using subqueries"},{"location":"select-query-builder/#hidden-columns","text":"If the model you are querying has a column with a select: false column, you must use the addSelect function in order to retrieve the information from the column. Let's say you have the following entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column({select: false}) password: string; } Using a standard find or query, you will not receive the password property for the model. However, if you do the following: const users = await connection.getRepository(User) .createQueryBuilder() .select(\"user.id\", \"id\") .addSelect(\"user.password\") .getMany(); You will get the property password in your query.","title":"Hidden Columns"},{"location":"select-query-builder/#querying-deleted-rows","text":"If the model you are querying has a column with the attribute @DeleteDateColumn set, the query builder will automatically query rows which are 'soft deleted'. Let's say you have the following entity: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class User { @PrimaryGeneratedColumn() id: number; @Column() name: string; @DeleteDateColumn() deletedAt?: Date; } Using a standard find or query, you will not receive the rows which have a value in that row. However, if you do the following: const users = await connection.getRepository(User) .createQueryBuilder() .select(\"user.id\", \"id\") .withDeleted() .getMany(); You will get all the rows, including the ones which are deleted.","title":"Querying Deleted rows"},{"location":"separating-entity-definition/","text":"Separating Entity Definition Defining Schemas Extending Schemas Using Schemas Defining Schemas You can define an entity and its columns right in the model, using decorators. But some people prefer to define an entity and its columns inside separate files which are called \"entity schemas\" in TypeORM. Simple definition example: import {EntitySchema} from \"typeorm\"; export const CategoryEntity = new EntitySchema({ name: \"category\", columns: { id: { type: Number, primary: true, generated: true }, name: { type: String } } }); Example with relations: import {EntitySchema} from \"typeorm\"; export const PostEntity = new EntitySchema({ name: \"post\", columns: { id: { type: Number, primary: true, generated: true }, title: { type: String }, text: { type: String } }, relations: { categories: { type: \"many-to-many\", target: \"category\" // CategoryEntity } } }); Complex example: import {EntitySchema} from \"typeorm\"; export const PersonSchema = new EntitySchema({ name: \"person\", columns: { id: { primary: true, type: \"int\", generated: \"increment\" }, firstName: { type: String, length: 30 }, lastName: { type: String, length: 50, nullable: false }, age: { type: Number, nullable: false } }, checks: [ { expression: `\"firstName\" <> 'John' AND \"lastName\" <> 'Doe'` }, { expression: `\"age\" > 18` } ], indices: [ { name: \"IDX_TEST\", unique: true, columns: [ \"firstName\", \"lastName\" ] } ], uniques: [ { name: \"UNIQUE_TEST\", columns: [ \"firstName\", \"lastName\" ] } ] }); If you want to make your entity typesafe, you can define a model and specify it in schema definition: import {EntitySchema} from \"typeorm\"; export interface Category { id: number; name: string; } export const CategoryEntity = new EntitySchema<Category>({ name: \"category\", columns: { id: { type: Number, primary: true, generated: true }, name: { type: String } } }); Extending Schemas When using the Decorator approach it is easy to extend basic columns to an abstract class and simply extend this. For example, your id , createdAt and updatedAt columns may be defined in such a BaseEntity . For more details, see the documentation on concrete table inheritance . When using the EntitySchema approach, this is not possible. However, you can use the Spread Operator ( ... ) to your advantage. Reconsider the Category example from above. You may want to extract basic column descriptions and reuse it across your other schemas. This may be done in the following way: import {EntitySchemaColumnOptions} from \"typeorm\"; export const BaseColumnSchemaPart = { id: { type: Number, primary: true, generated: true, } as EntitySchemaColumnOptions, createdAt: { name: 'created_at', type: 'timestamp with time zone', createDate: true, } as EntitySchemaColumnOptions, updatedAt: { name: 'updated_at', type: 'timestamp with time zone', updateDate: true, } as EntitySchemaColumnOptions, }; Now you can use the BaseColumnSchemaPart in your other schema models, like this: export const CategoryEntity = new EntitySchema<Category>({ name: \"category\", columns: { ...BaseColumnSchemaPart, // the CategoryEntity now has the defined id, createdAt, updatedAt columns! // in addition, the following NEW fields are defined name: { type: String } } }); Be sure to add the extended columns also to the Category interface (e.g., via export interface Category extend BaseEntity ). Using Schemas to Query / Insert Data Of course, you can use the defined schemas in your repositories or entity manager as you would use the decorators. Consider the previously defined Category example (with its Interface and CategoryEntity schema in order to get some data or manipulate the database. // request data const categoryRepository = getRepository<Category>(CategoryEntity); const category = await categoryRepository.findOne(1); // category is properly typed! // insert a new category into the database const categoryDTO = { // note that the ID is autogenerated; see the schema above name: 'new category', }; const newCategory = await categoryRepository.save(categoryDTO);","title":"Separating Entity Definition"},{"location":"separating-entity-definition/#separating-entity-definition","text":"Defining Schemas Extending Schemas Using Schemas","title":"Separating Entity Definition"},{"location":"separating-entity-definition/#defining-schemas","text":"You can define an entity and its columns right in the model, using decorators. But some people prefer to define an entity and its columns inside separate files which are called \"entity schemas\" in TypeORM. Simple definition example: import {EntitySchema} from \"typeorm\"; export const CategoryEntity = new EntitySchema({ name: \"category\", columns: { id: { type: Number, primary: true, generated: true }, name: { type: String } } }); Example with relations: import {EntitySchema} from \"typeorm\"; export const PostEntity = new EntitySchema({ name: \"post\", columns: { id: { type: Number, primary: true, generated: true }, title: { type: String }, text: { type: String } }, relations: { categories: { type: \"many-to-many\", target: \"category\" // CategoryEntity } } }); Complex example: import {EntitySchema} from \"typeorm\"; export const PersonSchema = new EntitySchema({ name: \"person\", columns: { id: { primary: true, type: \"int\", generated: \"increment\" }, firstName: { type: String, length: 30 }, lastName: { type: String, length: 50, nullable: false }, age: { type: Number, nullable: false } }, checks: [ { expression: `\"firstName\" <> 'John' AND \"lastName\" <> 'Doe'` }, { expression: `\"age\" > 18` } ], indices: [ { name: \"IDX_TEST\", unique: true, columns: [ \"firstName\", \"lastName\" ] } ], uniques: [ { name: \"UNIQUE_TEST\", columns: [ \"firstName\", \"lastName\" ] } ] }); If you want to make your entity typesafe, you can define a model and specify it in schema definition: import {EntitySchema} from \"typeorm\"; export interface Category { id: number; name: string; } export const CategoryEntity = new EntitySchema<Category>({ name: \"category\", columns: { id: { type: Number, primary: true, generated: true }, name: { type: String } } });","title":"Defining Schemas"},{"location":"separating-entity-definition/#extending-schemas","text":"When using the Decorator approach it is easy to extend basic columns to an abstract class and simply extend this. For example, your id , createdAt and updatedAt columns may be defined in such a BaseEntity . For more details, see the documentation on concrete table inheritance . When using the EntitySchema approach, this is not possible. However, you can use the Spread Operator ( ... ) to your advantage. Reconsider the Category example from above. You may want to extract basic column descriptions and reuse it across your other schemas. This may be done in the following way: import {EntitySchemaColumnOptions} from \"typeorm\"; export const BaseColumnSchemaPart = { id: { type: Number, primary: true, generated: true, } as EntitySchemaColumnOptions, createdAt: { name: 'created_at', type: 'timestamp with time zone', createDate: true, } as EntitySchemaColumnOptions, updatedAt: { name: 'updated_at', type: 'timestamp with time zone', updateDate: true, } as EntitySchemaColumnOptions, }; Now you can use the BaseColumnSchemaPart in your other schema models, like this: export const CategoryEntity = new EntitySchema<Category>({ name: \"category\", columns: { ...BaseColumnSchemaPart, // the CategoryEntity now has the defined id, createdAt, updatedAt columns! // in addition, the following NEW fields are defined name: { type: String } } }); Be sure to add the extended columns also to the Category interface (e.g., via export interface Category extend BaseEntity ).","title":"Extending Schemas"},{"location":"separating-entity-definition/#using-schemas-to-query-insert-data","text":"Of course, you can use the defined schemas in your repositories or entity manager as you would use the decorators. Consider the previously defined Category example (with its Interface and CategoryEntity schema in order to get some data or manipulate the database. // request data const categoryRepository = getRepository<Category>(CategoryEntity); const category = await categoryRepository.findOne(1); // category is properly typed! // insert a new category into the database const categoryDTO = { // note that the ID is autogenerated; see the schema above name: 'new category', }; const newCategory = await categoryRepository.save(categoryDTO);","title":"Using Schemas to Query / Insert Data"},{"location":"sequelize-migration/","text":"Migration from Sequelize to TypeORM Setting up a connection Schema synchronization Creating a models Other model settings Working with models Setting up a connection In sequelize you create a connection this way: const sequelize = new Sequelize(\"database\", \"username\", \"password\", { host: \"localhost\", dialect: \"mysql\" }); sequelize .authenticate() .then(() => { console.log(\"Connection has been established successfully.\"); }) .catch(err => { console.error(\"Unable to connect to the database:\", err); }); In TypeORM you create a connection like this: import {createConnection} from \"typeorm\"; createConnection({ type: \"mysql\", host: \"localhost\", username: \"username\", password: \"password\" }).then(connection => { console.log(\"Connection has been established successfully.\"); }) .catch(err => { console.error(\"Unable to connect to the database:\", err); }); Then you can get your connection instance from anywhere in your app using getConnection . Learn more about Connections Schema synchronization In sequelize you do schema synchronization this way: Project.sync({force: true}); Task.sync({force: true}); In TypeORM you just add synchronize: true in the connection options: createConnection({ type: \"mysql\", host: \"localhost\", username: \"username\", password: \"password\", synchronize: true }); Creating a models This is how models are defined in sequelize: module.exports = function(sequelize, DataTypes) { const Project = sequelize.define(\"project\", { title: DataTypes.STRING, description: DataTypes.TEXT }); return Project; }; module.exports = function(sequelize, DataTypes) { const Task = sequelize.define(\"task\", { title: DataTypes.STRING, description: DataTypes.TEXT, deadline: DataTypes.DATE }); return Task; }; In TypeORM these models are called entities and you can define them like this: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Project { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Task { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column(\"text\") description: string; @Column() deadline: Date; } It's highly recommended to define one entity class per file. TypeORM allows you to use your classes as database models and provides a declarative way to define what part of your model will become part of your database table. The power of TypeScript gives you type hinting and other useful features that you can use in classes. Learn more about Entities and columns Other model settings The following in sequelize: flag: { type: Sequelize.BOOLEAN, allowNull: true, defaultValue: true }, Can be achieved in TypeORM like this: @Column({ nullable: true, default: true }) flag: boolean; Following in sequelize: flag: { type: Sequelize.DATE, defaultValue: Sequelize.NOW } Is written like this in TypeORM: @Column({ default: () => \"NOW()\" }) myDate: Date; Following in sequelize: someUnique: { type: Sequelize.STRING, unique: true }, Can be achieved this way in TypeORM: @Column({ unique: true }) someUnique: string; Following in sequelize: fieldWithUnderscores: { type: Sequelize.STRING, field: \"field_with_underscores\" }, Translates to this in TypeORM: @Column({ name: \"field_with_underscores\" }) fieldWithUnderscores: string; Following in sequelize: incrementMe: { type: Sequelize.INTEGER, autoIncrement: true }, Can be achieved this way in TypeORM: @Column() @Generated() incrementMe: number; Following in sequelize: identifier: { type: Sequelize.STRING, primaryKey: true }, Can be achieved this way in TypeORM: @Column({ primary: true }) identifier: string; To create createDate and updateDate -like columns you need to defined two columns (name it what you want) in your entity: @CreateDateColumn(); createDate: Date; @UpdateDateColumn(); updateDate: Date; Working with models To create and save a new model in sequelize you write: const employee = await Employee.create({ name: \"John Doe\", title: \"senior engineer\" }); In TypeORM there are several ways to create and save a new model: const employee = new Employee(); // you can use constructor parameters as well employee.name = \"John Doe\"; employee.title = \"senior engineer\"; await getRepository(Employee).save(employee) or active record pattern const employee = Employee.create({ name: \"John Doe\", title: \"senior engineer\" }); await employee.save(); if you want to load an existing entity from the database and replace some of its properties you can use the following method: const employee = await Employee.preload({ id: 1, name: \"John Doe\" }); Learn more about Active Record vs Data Mapper and Repository API . To access properties in sequelize you do the following: console.log(employee.get(\"name\")); In TypeORM you simply do: console.log(employee.name); To create an index in sequelize you do: sequelize.define(\"user\", {}, { indexes: [ { unique: true, fields: [\"firstName\", \"lastName\"] } ] }); In TypeORM you do: @Entity() @Index([\"firstName\", \"lastName\"], { unique: true }) export class User { } Learn more about Indices","title":"Migration from Sequelize to TypeORM"},{"location":"sequelize-migration/#migration-from-sequelize-to-typeorm","text":"Setting up a connection Schema synchronization Creating a models Other model settings Working with models","title":"Migration from Sequelize to TypeORM"},{"location":"sequelize-migration/#setting-up-a-connection","text":"In sequelize you create a connection this way: const sequelize = new Sequelize(\"database\", \"username\", \"password\", { host: \"localhost\", dialect: \"mysql\" }); sequelize .authenticate() .then(() => { console.log(\"Connection has been established successfully.\"); }) .catch(err => { console.error(\"Unable to connect to the database:\", err); }); In TypeORM you create a connection like this: import {createConnection} from \"typeorm\"; createConnection({ type: \"mysql\", host: \"localhost\", username: \"username\", password: \"password\" }).then(connection => { console.log(\"Connection has been established successfully.\"); }) .catch(err => { console.error(\"Unable to connect to the database:\", err); }); Then you can get your connection instance from anywhere in your app using getConnection . Learn more about Connections","title":"Setting up a connection"},{"location":"sequelize-migration/#schema-synchronization","text":"In sequelize you do schema synchronization this way: Project.sync({force: true}); Task.sync({force: true}); In TypeORM you just add synchronize: true in the connection options: createConnection({ type: \"mysql\", host: \"localhost\", username: \"username\", password: \"password\", synchronize: true });","title":"Schema synchronization"},{"location":"sequelize-migration/#creating-a-models","text":"This is how models are defined in sequelize: module.exports = function(sequelize, DataTypes) { const Project = sequelize.define(\"project\", { title: DataTypes.STRING, description: DataTypes.TEXT }); return Project; }; module.exports = function(sequelize, DataTypes) { const Task = sequelize.define(\"task\", { title: DataTypes.STRING, description: DataTypes.TEXT, deadline: DataTypes.DATE }); return Task; }; In TypeORM these models are called entities and you can define them like this: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Project { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column() description: string; } import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Task { @PrimaryGeneratedColumn() id: number; @Column() title: string; @Column(\"text\") description: string; @Column() deadline: Date; } It's highly recommended to define one entity class per file. TypeORM allows you to use your classes as database models and provides a declarative way to define what part of your model will become part of your database table. The power of TypeScript gives you type hinting and other useful features that you can use in classes. Learn more about Entities and columns","title":"Creating a models"},{"location":"sequelize-migration/#other-model-settings","text":"The following in sequelize: flag: { type: Sequelize.BOOLEAN, allowNull: true, defaultValue: true }, Can be achieved in TypeORM like this: @Column({ nullable: true, default: true }) flag: boolean; Following in sequelize: flag: { type: Sequelize.DATE, defaultValue: Sequelize.NOW } Is written like this in TypeORM: @Column({ default: () => \"NOW()\" }) myDate: Date; Following in sequelize: someUnique: { type: Sequelize.STRING, unique: true }, Can be achieved this way in TypeORM: @Column({ unique: true }) someUnique: string; Following in sequelize: fieldWithUnderscores: { type: Sequelize.STRING, field: \"field_with_underscores\" }, Translates to this in TypeORM: @Column({ name: \"field_with_underscores\" }) fieldWithUnderscores: string; Following in sequelize: incrementMe: { type: Sequelize.INTEGER, autoIncrement: true }, Can be achieved this way in TypeORM: @Column() @Generated() incrementMe: number; Following in sequelize: identifier: { type: Sequelize.STRING, primaryKey: true }, Can be achieved this way in TypeORM: @Column({ primary: true }) identifier: string; To create createDate and updateDate -like columns you need to defined two columns (name it what you want) in your entity: @CreateDateColumn(); createDate: Date; @UpdateDateColumn(); updateDate: Date;","title":"Other model settings"},{"location":"sequelize-migration/#working-with-models","text":"To create and save a new model in sequelize you write: const employee = await Employee.create({ name: \"John Doe\", title: \"senior engineer\" }); In TypeORM there are several ways to create and save a new model: const employee = new Employee(); // you can use constructor parameters as well employee.name = \"John Doe\"; employee.title = \"senior engineer\"; await getRepository(Employee).save(employee) or active record pattern const employee = Employee.create({ name: \"John Doe\", title: \"senior engineer\" }); await employee.save(); if you want to load an existing entity from the database and replace some of its properties you can use the following method: const employee = await Employee.preload({ id: 1, name: \"John Doe\" }); Learn more about Active Record vs Data Mapper and Repository API . To access properties in sequelize you do the following: console.log(employee.get(\"name\")); In TypeORM you simply do: console.log(employee.name); To create an index in sequelize you do: sequelize.define(\"user\", {}, { indexes: [ { unique: true, fields: [\"firstName\", \"lastName\"] } ] }); In TypeORM you do: @Entity() @Index([\"firstName\", \"lastName\"], { unique: true }) export class User { } Learn more about Indices","title":"Working with models"},{"location":"support/","text":"Support Found a bug or want to propose a new feature? If you found a bug, issue, or you just want to propose a new feature, create an issue on github . Have a question? If you have a question, you can ask it on StackOverflow or other community support channels. Want community support? If you want community support, or simply want to chat with friendly TypeORM enthusiasts and users, you can do it on Slack . Want professional commercial support? The TypeORM core team is always ready to provide professional commercial support. We are ready to work with any team in any part of the world. Please contact us .","title":"Support"},{"location":"support/#support","text":"","title":"Support"},{"location":"support/#found-a-bug-or-want-to-propose-a-new-feature","text":"If you found a bug, issue, or you just want to propose a new feature, create an issue on github .","title":"Found a bug or want to propose a new feature?"},{"location":"support/#have-a-question","text":"If you have a question, you can ask it on StackOverflow or other community support channels.","title":"Have a question?"},{"location":"support/#want-community-support","text":"If you want community support, or simply want to chat with friendly TypeORM enthusiasts and users, you can do it on Slack .","title":"Want community support?"},{"location":"support/#want-professional-commercial-support","text":"The TypeORM core team is always ready to provide professional commercial support. We are ready to work with any team in any part of the world. Please contact us .","title":"Want professional commercial support?"},{"location":"supported-platforms/","text":"Supported platforms NodeJS Browser Cordova / PhoneGap / Ionic apps React Native Expo NativeScript NodeJS TypeORM was tested on Node.js version 12 and above. Browser You can use sql.js in the browser. Webpack configuration In the browser folder the package also includes a version compiled as a ES2015 module. If you want to use a different loader this is the point to start. Prior to TypeORM 0.1.7, the package is setup in a way that loaders like webpack will automatically use the browser folder. With 0.1.7 this was dropped to support Webpack usage in Node.js projects. This means, that the NormalModuleReplacementPlugin has to be used to insure that the correct version is loaded for browser projects. The configuration in your webpack config file, for this plugin looks like this: plugins: [ ..., // any existing plugins that you already have new webpack.NormalModuleReplacementPlugin(/typeorm$/, function (result) { result.request = result.request.replace(/typeorm/, \"typeorm/browser\"); }), new webpack.ProvidePlugin({ 'window.SQL': 'sql.js/dist/sql-wasm.js' }) ] and make sure sql-wasm.wasm file exists in your public path. Example of configuration createConnection({ type: \"sqljs\", entities: [ Photo ], synchronize: true }); Don't forget to include reflect-metadata In your main html page, you need to include reflect-metadata: <script src=\"./node_modules/reflect-metadata/Reflect.js\"></script> Cordova / PhoneGap / Ionic apps TypeORM is able to run on Cordova, PhoneGap, Ionic apps using the cordova-sqlite-storage plugin You have the option to choose between module loaders just like in browser package. For an example how to use TypeORM in Cordova see typeorm/cordova-example and for Ionic see typeorm/ionic-example . Important : For use with Ionic, a custom webpack config file is needed! Please checkout the example to see the needed changes. React Native TypeORM is able to run on React Native apps using the react-native-sqlite-storage plugin. For an example see typeorm/react-native-example . Expo TypeORM is able to run on Expo apps using the Expo SQLite API . For an example how to use TypeORM in Expo see typeorm/expo-example . NativeScript tns install webpack (read below why webpack is required) tns plugin add nativescript-sqlite Create Database connection in your app's entry point ```typescript import driver from 'nativescript-sqlite' const connection = await createConnection({ database: 'test.db', type: 'nativescript', driver, entities: [ Todo //... whatever entities you have ], logging: true }) ``` Note: This works only with NativeScript 4.x and above When using with NativeScript, using webpack is compulsory . The typeorm/browser package is raw ES7 code with import/export which will NOT run as it is. It has to be bundled. Please use the tns run --bundle method Checkout example here !","title":"Supported platforms"},{"location":"supported-platforms/#supported-platforms","text":"NodeJS Browser Cordova / PhoneGap / Ionic apps React Native Expo NativeScript","title":"Supported platforms"},{"location":"supported-platforms/#nodejs","text":"TypeORM was tested on Node.js version 12 and above.","title":"NodeJS"},{"location":"supported-platforms/#browser","text":"You can use sql.js in the browser. Webpack configuration In the browser folder the package also includes a version compiled as a ES2015 module. If you want to use a different loader this is the point to start. Prior to TypeORM 0.1.7, the package is setup in a way that loaders like webpack will automatically use the browser folder. With 0.1.7 this was dropped to support Webpack usage in Node.js projects. This means, that the NormalModuleReplacementPlugin has to be used to insure that the correct version is loaded for browser projects. The configuration in your webpack config file, for this plugin looks like this: plugins: [ ..., // any existing plugins that you already have new webpack.NormalModuleReplacementPlugin(/typeorm$/, function (result) { result.request = result.request.replace(/typeorm/, \"typeorm/browser\"); }), new webpack.ProvidePlugin({ 'window.SQL': 'sql.js/dist/sql-wasm.js' }) ] and make sure sql-wasm.wasm file exists in your public path. Example of configuration createConnection({ type: \"sqljs\", entities: [ Photo ], synchronize: true }); Don't forget to include reflect-metadata In your main html page, you need to include reflect-metadata: <script src=\"./node_modules/reflect-metadata/Reflect.js\"></script>","title":"Browser"},{"location":"supported-platforms/#cordova-phonegap-ionic-apps","text":"TypeORM is able to run on Cordova, PhoneGap, Ionic apps using the cordova-sqlite-storage plugin You have the option to choose between module loaders just like in browser package. For an example how to use TypeORM in Cordova see typeorm/cordova-example and for Ionic see typeorm/ionic-example . Important : For use with Ionic, a custom webpack config file is needed! Please checkout the example to see the needed changes.","title":"Cordova / PhoneGap / Ionic apps"},{"location":"supported-platforms/#react-native","text":"TypeORM is able to run on React Native apps using the react-native-sqlite-storage plugin. For an example see typeorm/react-native-example .","title":"React Native"},{"location":"supported-platforms/#expo","text":"TypeORM is able to run on Expo apps using the Expo SQLite API . For an example how to use TypeORM in Expo see typeorm/expo-example .","title":"Expo"},{"location":"supported-platforms/#nativescript","text":"tns install webpack (read below why webpack is required) tns plugin add nativescript-sqlite Create Database connection in your app's entry point ```typescript import driver from 'nativescript-sqlite' const connection = await createConnection({ database: 'test.db', type: 'nativescript', driver, entities: [ Todo //... whatever entities you have ], logging: true }) ``` Note: This works only with NativeScript 4.x and above When using with NativeScript, using webpack is compulsory . The typeorm/browser package is raw ES7 code with import/export which will NOT run as it is. It has to be bundled. Please use the tns run --bundle method Checkout example here !","title":"NativeScript"},{"location":"transactions/","text":"Transactions Creating and using transactions Specifying Isolation Levels Transaction decorators Using QueryRunner to create and control state of single database connection Creating and using transactions Transactions are created using Connection or EntityManager . Examples: import {getConnection} from \"typeorm\"; await getConnection().transaction(async transactionalEntityManager => { }); or import {getManager} from \"typeorm\"; await getManager().transaction(async transactionalEntityManager => { }); Everything you want to run in a transaction must be executed in a callback: import {getManager} from \"typeorm\"; await getManager().transaction(async transactionalEntityManager => { await transactionalEntityManager.save(users); await transactionalEntityManager.save(photos); // ... }); The most important restriction when working in an transaction is, to ALWAYS use the provided instance of entity manager - transactionalEntityManager in this example. If you'll use global manager (from getManager or manager from connection) you'll have problems. You also cannot use classes which use global manager or connection to execute their queries. All operations MUST be executed using the provided transactional entity manager. Specifying Isolation Levels Specifying the isolation level for the transaction can be done by supplying it as the first parameter: import {getManager} from \"typeorm\"; await getManager().transaction(\"SERIALIZABLE\", transactionalEntityManager => { }); Isolation level implementations are not agnostic across all databases. The following database drivers support the standard isolation levels ( READ UNCOMMITTED , READ COMMITTED , REPEATABLE READ , SERIALIZABLE ): * MySQL * Postgres * SQL Server SQlite defaults transactions to SERIALIZABLE , but if shared cache mode is enabled, a transaction can use the READ UNCOMMITTED isolation level. Oracle only supports the READ COMMITTED and SERIALIZABLE isolation levels. Transaction decorators There are a few decorators which can help you organize your transactions - @Transaction , @TransactionManager and @TransactionRepository . @Transaction wraps all its execution into a single database transaction, and @TransactionManager provides a transaction entity manager which must be used to execute queries inside this transaction: @Transaction() save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } with isolation level: @Transaction({ isolation: \"SERIALIZABLE\" }) save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } You must always use the manager provided by @TransactionManager . However, you can also inject transaction repository (which uses transaction entity manager under the hood), using @TransactionRepository : @Transaction() save(user: User, @TransactionRepository(User) userRepository: Repository<User>) { return userRepository.save(user); } You can inject both built-in TypeORM's repositories like Repository , TreeRepository and MongoRepository (using @TransactionRepository(Entity) entityRepository: Repository<Entity> ) or custom repositories (classes extending the built-in TypeORM's repositories classes and decorated with @EntityRepository ) using the @TransactionRepository() customRepository: CustomRepository . Using QueryRunner to create and control state of single database connection QueryRunner provides a single database connection. Transactions are organized using query runners. Single transactions can only be established on a single query runner. You can manually create a query runner instance and use it to manually control transaction state. Example: import {getConnection} from \"typeorm\"; // get a connection and create a new query runner const connection = getConnection(); const queryRunner = connection.createQueryRunner(); // establish real database connection using our new query runner await queryRunner.connect(); // now we can execute any queries on a query runner, for example: await queryRunner.query(\"SELECT * FROM users\"); // we can also access entity manager that works with connection created by a query runner: const users = await queryRunner.manager.find(User); // lets now open a new transaction: await queryRunner.startTransaction(); try { // execute some operations on this transaction: await queryRunner.manager.save(user1); await queryRunner.manager.save(user2); await queryRunner.manager.save(photos); // commit transaction now: await queryRunner.commitTransaction(); } catch (err) { // since we have errors let's rollback changes we made await queryRunner.rollbackTransaction(); } finally { // you need to release query runner which is manually created: await queryRunner.release(); } There are 3 methods to control transactions in QueryRunner : startTransaction - starts a new transaction inside the query runner instance. commitTransaction - commits all changes made using the query runner instance. rollbackTransaction - rolls all changes made using the query runner instance back. Learn more about Query Runner .","title":"Transactions"},{"location":"transactions/#transactions","text":"Creating and using transactions Specifying Isolation Levels Transaction decorators Using QueryRunner to create and control state of single database connection","title":"Transactions"},{"location":"transactions/#creating-and-using-transactions","text":"Transactions are created using Connection or EntityManager . Examples: import {getConnection} from \"typeorm\"; await getConnection().transaction(async transactionalEntityManager => { }); or import {getManager} from \"typeorm\"; await getManager().transaction(async transactionalEntityManager => { }); Everything you want to run in a transaction must be executed in a callback: import {getManager} from \"typeorm\"; await getManager().transaction(async transactionalEntityManager => { await transactionalEntityManager.save(users); await transactionalEntityManager.save(photos); // ... }); The most important restriction when working in an transaction is, to ALWAYS use the provided instance of entity manager - transactionalEntityManager in this example. If you'll use global manager (from getManager or manager from connection) you'll have problems. You also cannot use classes which use global manager or connection to execute their queries. All operations MUST be executed using the provided transactional entity manager.","title":"Creating and using transactions"},{"location":"transactions/#specifying-isolation-levels","text":"Specifying the isolation level for the transaction can be done by supplying it as the first parameter: import {getManager} from \"typeorm\"; await getManager().transaction(\"SERIALIZABLE\", transactionalEntityManager => { }); Isolation level implementations are not agnostic across all databases. The following database drivers support the standard isolation levels ( READ UNCOMMITTED , READ COMMITTED , REPEATABLE READ , SERIALIZABLE ): * MySQL * Postgres * SQL Server SQlite defaults transactions to SERIALIZABLE , but if shared cache mode is enabled, a transaction can use the READ UNCOMMITTED isolation level. Oracle only supports the READ COMMITTED and SERIALIZABLE isolation levels.","title":"Specifying Isolation Levels"},{"location":"transactions/#transaction-decorators","text":"There are a few decorators which can help you organize your transactions - @Transaction , @TransactionManager and @TransactionRepository . @Transaction wraps all its execution into a single database transaction, and @TransactionManager provides a transaction entity manager which must be used to execute queries inside this transaction: @Transaction() save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } with isolation level: @Transaction({ isolation: \"SERIALIZABLE\" }) save(@TransactionManager() manager: EntityManager, user: User) { return manager.save(user); } You must always use the manager provided by @TransactionManager . However, you can also inject transaction repository (which uses transaction entity manager under the hood), using @TransactionRepository : @Transaction() save(user: User, @TransactionRepository(User) userRepository: Repository<User>) { return userRepository.save(user); } You can inject both built-in TypeORM's repositories like Repository , TreeRepository and MongoRepository (using @TransactionRepository(Entity) entityRepository: Repository<Entity> ) or custom repositories (classes extending the built-in TypeORM's repositories classes and decorated with @EntityRepository ) using the @TransactionRepository() customRepository: CustomRepository .","title":"Transaction decorators"},{"location":"transactions/#using-queryrunner-to-create-and-control-state-of-single-database-connection","text":"QueryRunner provides a single database connection. Transactions are organized using query runners. Single transactions can only be established on a single query runner. You can manually create a query runner instance and use it to manually control transaction state. Example: import {getConnection} from \"typeorm\"; // get a connection and create a new query runner const connection = getConnection(); const queryRunner = connection.createQueryRunner(); // establish real database connection using our new query runner await queryRunner.connect(); // now we can execute any queries on a query runner, for example: await queryRunner.query(\"SELECT * FROM users\"); // we can also access entity manager that works with connection created by a query runner: const users = await queryRunner.manager.find(User); // lets now open a new transaction: await queryRunner.startTransaction(); try { // execute some operations on this transaction: await queryRunner.manager.save(user1); await queryRunner.manager.save(user2); await queryRunner.manager.save(photos); // commit transaction now: await queryRunner.commitTransaction(); } catch (err) { // since we have errors let's rollback changes we made await queryRunner.rollbackTransaction(); } finally { // you need to release query runner which is manually created: await queryRunner.release(); } There are 3 methods to control transactions in QueryRunner : startTransaction - starts a new transaction inside the query runner instance. commitTransaction - commits all changes made using the query runner instance. rollbackTransaction - rolls all changes made using the query runner instance back. Learn more about Query Runner .","title":"Using QueryRunner to create and control state of single database connection"},{"location":"tree-entities/","text":"Tree Entities TypeORM supports the Adjacency list and Closure table patterns for storing tree structures. To learn more about hierarchy table take a look at this awesome presentation by Bill Karwin . Adjacency list Nested set Materialized Path (aka Path Enumeration) Closure table Working with tree entities Adjacency list Adjacency list is a simple model with self-referencing. The benefit of this approach is simplicity, drawback is that you can't load big trees in all at once because of join limitations. To learn more about the benefits and use of Adjacency Lists look at this article by Matthew Schinckel . Example: import {Entity, Column, PrimaryGeneratedColumn, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @ManyToOne(type => Category, category => category.children) parent: Category; @OneToMany(type => Category, category => category.parent) children: Category[]; } Nested set Nested set is another pattern of storing tree structures in the database. Its very efficient for reads, but bad for writes. You cannot have multiple roots in nested set. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"nested-set\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; } Materialized Path (aka Path Enumeration) Materialized Path (also called Path Enumeration) is another pattern of storing tree structures in the database. Its simple and effective. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"materialized-path\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; } Closure table Closure table stores relations between parent and child in a separate table in a special way. It's efficient in both reads and writes. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"closure-table\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; } You can specify closure table name and / or closure table columns names by setting optional parameter options into @Tree(\"closure-table\", options) . ancestorColumnName and descandantColumnName are callback functions, which receive primary column's metadata and return column's name. @Tree(\"closure-table\", { closureTableName: \"category_closure\", ancestorColumnName: (column) => \"ancestor_\" + column.propertyName, descendantColumnName: (column) => \"descendant_\" + column.propertyName, }) Working with tree entities To bind tree entities to each other, it is required to set the parent in the child entity and then save them. for example: const manager = getManager(); const a1 = new Category(\"a1\"); a1.name = \"a1\"; await manager.save(a1); const a11 = new Category(); a11.name = \"a11\"; a11.parent = a1; await manager.save(a11); const a12 = new Category(); a12.name = \"a12\"; a12.parent = a1; await manager.save(a12); const a111 = new Category(); a111.name = \"a111\"; a111.parent = a11; await manager.save(a111); const a112 = new Category(); a112.name = \"a112\"; a112.parent = a11; await manager.save(a112); To load such a tree use TreeRepository : const manager = getManager(); const trees = await manager.getTreeRepository(Category).findTrees(); trees will be following: [{ \"id\": 1, \"name\": \"a1\", \"children\": [{ \"id\": 2, \"name\": \"a11\", \"children\": [{ \"id\": 4, \"name\": \"a111\" }, { \"id\": 5, \"name\": \"a112\" }] }, { \"id\": 3, \"name\": \"a12\" }] }] There are other special methods to work with tree entities through TreeRepository : findTrees - Returns all trees in the database with all their children, children of children, etc. const treeCategories = await repository.findTrees(); // returns root categories with sub categories inside const treeCategoriesWithRelations = await repository.findTrees({ relations: [\"sites\"] }); // automatically joins the sites relation findRoots - Roots are entities that have no ancestors. Finds them all. Does not load children leafs. const rootCategories = await repository.findRoots(); // returns root categories without sub categories inside findDescendants - Gets all children (descendants) of the given entity. Returns them all in a flat array. const children = await repository.findDescendants(parentCategory); // returns all direct subcategories (without its nested categories) of a parentCategory findDescendantsTree - Gets all children (descendants) of the given entity. Returns them in a tree - nested into each other. const childrenTree = await repository.findDescendantsTree(parentCategory); // returns all direct subcategories (with its nested categories) of a parentCategory createDescendantsQueryBuilder - Creates a query builder used to get descendants of the entities in a tree. const children = await repository .createDescendantsQueryBuilder(\"category\", \"categoryClosure\", parentCategory) .andWhere(\"category.type = 'secondary'\") .getMany(); countDescendants - Gets number of descendants of the entity. const childrenCount = await repository.countDescendants(parentCategory); findAncestors - Gets all parent (ancestors) of the given entity. Returns them all in a flat array. const parents = await repository.findAncestors(childCategory); // returns all direct childCategory's parent categories (without \"parent of parents\") findAncestorsTree - Gets all parent (ancestors) of the given entity. Returns them in a tree - nested into each other. const parentsTree = await repository.findAncestorsTree(childCategory); // returns all direct childCategory's parent categories (with \"parent of parents\") createAncestorsQueryBuilder - Creates a query builder used to get ancestors of the entities in a tree. const parents = await repository .createAncestorsQueryBuilder(\"category\", \"categoryClosure\", childCategory) .andWhere(\"category.type = 'secondary'\") .getMany(); countAncestors - Gets the number of ancestors of the entity. const parentsCount = await repository.countAncestors(childCategory);","title":"Tree Entities"},{"location":"tree-entities/#tree-entities","text":"TypeORM supports the Adjacency list and Closure table patterns for storing tree structures. To learn more about hierarchy table take a look at this awesome presentation by Bill Karwin . Adjacency list Nested set Materialized Path (aka Path Enumeration) Closure table Working with tree entities","title":"Tree Entities"},{"location":"tree-entities/#adjacency-list","text":"Adjacency list is a simple model with self-referencing. The benefit of this approach is simplicity, drawback is that you can't load big trees in all at once because of join limitations. To learn more about the benefits and use of Adjacency Lists look at this article by Matthew Schinckel . Example: import {Entity, Column, PrimaryGeneratedColumn, ManyToOne, OneToMany} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() description: string; @ManyToOne(type => Category, category => category.children) parent: Category; @OneToMany(type => Category, category => category.parent) children: Category[]; }","title":"Adjacency list"},{"location":"tree-entities/#nested-set","text":"Nested set is another pattern of storing tree structures in the database. Its very efficient for reads, but bad for writes. You cannot have multiple roots in nested set. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"nested-set\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; }","title":"Nested set"},{"location":"tree-entities/#materialized-path-aka-path-enumeration","text":"Materialized Path (also called Path Enumeration) is another pattern of storing tree structures in the database. Its simple and effective. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"materialized-path\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; }","title":"Materialized Path (aka Path Enumeration)"},{"location":"tree-entities/#closure-table","text":"Closure table stores relations between parent and child in a separate table in a special way. It's efficient in both reads and writes. Example: import {Entity, Tree, Column, PrimaryGeneratedColumn, TreeChildren, TreeParent, TreeLevelColumn} from \"typeorm\"; @Entity() @Tree(\"closure-table\") export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; @TreeChildren() children: Category[]; @TreeParent() parent: Category; } You can specify closure table name and / or closure table columns names by setting optional parameter options into @Tree(\"closure-table\", options) . ancestorColumnName and descandantColumnName are callback functions, which receive primary column's metadata and return column's name. @Tree(\"closure-table\", { closureTableName: \"category_closure\", ancestorColumnName: (column) => \"ancestor_\" + column.propertyName, descendantColumnName: (column) => \"descendant_\" + column.propertyName, })","title":"Closure table"},{"location":"tree-entities/#working-with-tree-entities","text":"To bind tree entities to each other, it is required to set the parent in the child entity and then save them. for example: const manager = getManager(); const a1 = new Category(\"a1\"); a1.name = \"a1\"; await manager.save(a1); const a11 = new Category(); a11.name = \"a11\"; a11.parent = a1; await manager.save(a11); const a12 = new Category(); a12.name = \"a12\"; a12.parent = a1; await manager.save(a12); const a111 = new Category(); a111.name = \"a111\"; a111.parent = a11; await manager.save(a111); const a112 = new Category(); a112.name = \"a112\"; a112.parent = a11; await manager.save(a112); To load such a tree use TreeRepository : const manager = getManager(); const trees = await manager.getTreeRepository(Category).findTrees(); trees will be following: [{ \"id\": 1, \"name\": \"a1\", \"children\": [{ \"id\": 2, \"name\": \"a11\", \"children\": [{ \"id\": 4, \"name\": \"a111\" }, { \"id\": 5, \"name\": \"a112\" }] }, { \"id\": 3, \"name\": \"a12\" }] }] There are other special methods to work with tree entities through TreeRepository : findTrees - Returns all trees in the database with all their children, children of children, etc. const treeCategories = await repository.findTrees(); // returns root categories with sub categories inside const treeCategoriesWithRelations = await repository.findTrees({ relations: [\"sites\"] }); // automatically joins the sites relation findRoots - Roots are entities that have no ancestors. Finds them all. Does not load children leafs. const rootCategories = await repository.findRoots(); // returns root categories without sub categories inside findDescendants - Gets all children (descendants) of the given entity. Returns them all in a flat array. const children = await repository.findDescendants(parentCategory); // returns all direct subcategories (without its nested categories) of a parentCategory findDescendantsTree - Gets all children (descendants) of the given entity. Returns them in a tree - nested into each other. const childrenTree = await repository.findDescendantsTree(parentCategory); // returns all direct subcategories (with its nested categories) of a parentCategory createDescendantsQueryBuilder - Creates a query builder used to get descendants of the entities in a tree. const children = await repository .createDescendantsQueryBuilder(\"category\", \"categoryClosure\", parentCategory) .andWhere(\"category.type = 'secondary'\") .getMany(); countDescendants - Gets number of descendants of the entity. const childrenCount = await repository.countDescendants(parentCategory); findAncestors - Gets all parent (ancestors) of the given entity. Returns them all in a flat array. const parents = await repository.findAncestors(childCategory); // returns all direct childCategory's parent categories (without \"parent of parents\") findAncestorsTree - Gets all parent (ancestors) of the given entity. Returns them in a tree - nested into each other. const parentsTree = await repository.findAncestorsTree(childCategory); // returns all direct childCategory's parent categories (with \"parent of parents\") createAncestorsQueryBuilder - Creates a query builder used to get ancestors of the entities in a tree. const parents = await repository .createAncestorsQueryBuilder(\"category\", \"categoryClosure\", childCategory) .andWhere(\"category.type = 'secondary'\") .getMany(); countAncestors - Gets the number of ancestors of the entity. const parentsCount = await repository.countAncestors(childCategory);","title":"Working with tree entities"},{"location":"troubleshooting/","text":"Troubleshooting Glob patterns Glob Patterns Glob patterns are used in the TypeOrm to specify the locations of entities, migrations, subscriber and other information. Errors in the patterns can lead to the common RepositoryNotFoundError and familiar errors. In order to check if any files were loaded by TypeOrm using the glob patterns, all you need to do is set the logging level to info such as explained in the Logging section of the documentation. This will allow you to have logs in the console that may look like this: # in case of an error INFO: No classes were found using the provided glob pattern: \"dist/**/*.entity{.ts}\" # when files are found INFO: All classes found using provided glob pattern \"dist/**/*.entity{.js,.ts}\" : \"dist/app/user/user.entity.js | dist/app/common/common.entity.js\"","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting","text":"Glob patterns","title":"Troubleshooting"},{"location":"troubleshooting/#glob-patterns","text":"Glob patterns are used in the TypeOrm to specify the locations of entities, migrations, subscriber and other information. Errors in the patterns can lead to the common RepositoryNotFoundError and familiar errors. In order to check if any files were loaded by TypeOrm using the glob patterns, all you need to do is set the logging level to info such as explained in the Logging section of the documentation. This will allow you to have logs in the console that may look like this: # in case of an error INFO: No classes were found using the provided glob pattern: \"dist/**/*.entity{.ts}\" # when files are found INFO: All classes found using provided glob pattern \"dist/**/*.entity{.js,.ts}\" : \"dist/app/user/user.entity.js | dist/app/common/common.entity.js\"","title":"Glob Patterns"},{"location":"update-query-builder/","text":"Update using Query Builder You can create UPDATE queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\" }) .where(\"id = :id\", { id: 1 }) .execute(); This is the most efficient way in terms of performance to update entities in your database. Raw SQL support In some cases when you need to execute SQL queries you need to use function style value: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\", age: () => \"age + 1\" }) .where(\"id = :id\", { id: 1 }) .execute(); This syntax doesn't escape your values, you need to handle escape on your own.","title":"Update using Query Builder"},{"location":"update-query-builder/#update-using-query-builder","text":"You can create UPDATE queries using QueryBuilder . Examples: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\" }) .where(\"id = :id\", { id: 1 }) .execute(); This is the most efficient way in terms of performance to update entities in your database.","title":"Update using Query Builder"},{"location":"update-query-builder/#raw-sql-support","text":"In some cases when you need to execute SQL queries you need to use function style value: import {getConnection} from \"typeorm\"; await getConnection() .createQueryBuilder() .update(User) .set({ firstName: \"Timber\", lastName: \"Saw\", age: () => \"age + 1\" }) .where(\"id = :id\", { id: 1 }) .execute(); This syntax doesn't escape your values, you need to handle escape on your own.","title":"Raw SQL support"},{"location":"usage-with-javascript/","text":"Using with JavaScript TypeORM can be used not only with TypeScript, but also with JavaScript. Everything is the same, except you need to omit types and if your platform does not support ES6 classes then you need to define objects with all required metadata. app.js var typeorm = require(\"typeorm\"); typeorm.createConnection({ type: \"postgres\", host: \"localhost\", port: 5432, username: \"test\", password: \"admin\", database: \"test\", synchronize: true, entities: [ require(\"./entity/Post\"), require(\"./entity/Category\") ] }).then(function (connection) { var category1 = { name: \"TypeScript\" }; var category2 = { name: \"Programming\" }; var post = { title: \"Control flow based type analysis\", text: \"TypeScript 2.0 implements a control flow-based type analysis for local variables and parameters.\", categories: [ category1, category2 ] }; var postRepository = connection.getRepository(\"Post\"); postRepository.save(post) .then(function(savedPost) { console.log(\"Post has been saved: \", savedPost); console.log(\"Now lets load all posts: \"); return postRepository.find(); }) .then(function(allPosts) { console.log(\"All posts: \", allPosts); }); }).catch(function(error) { console.log(\"Error: \", error); }); entity/Category.js var EntitySchema = require(\"typeorm\").EntitySchema; module.exports = new EntitySchema({ name: \"Category\", // Will use table name `category` as default behaviour. tableName: \"categories\", // Optional: Provide `tableName` property to override the default behaviour for table name. columns: { id: { primary: true, type: \"int\", generated: true }, name: { type: \"varchar\" } } }); entity/Post.js var EntitySchema = require(\"typeorm\").EntitySchema; module.exports = new EntitySchema({ name: \"Post\", // Will use table name `post` as default behaviour. tableName: \"posts\", // Optional: Provide `tableName` property to override the default behaviour for table name. columns: { id: { primary: true, type: \"int\", generated: true }, title: { type: \"varchar\" }, text: { type: \"text\" } }, relations: { categories: { target: \"Category\", type: \"many-to-many\", joinTable: true, cascade: true } } }); You can checkout this example typeorm/javascript-example to learn more.","title":"Using with JavaScript"},{"location":"usage-with-javascript/#using-with-javascript","text":"TypeORM can be used not only with TypeScript, but also with JavaScript. Everything is the same, except you need to omit types and if your platform does not support ES6 classes then you need to define objects with all required metadata.","title":"Using with JavaScript"},{"location":"usage-with-javascript/#appjs","text":"var typeorm = require(\"typeorm\"); typeorm.createConnection({ type: \"postgres\", host: \"localhost\", port: 5432, username: \"test\", password: \"admin\", database: \"test\", synchronize: true, entities: [ require(\"./entity/Post\"), require(\"./entity/Category\") ] }).then(function (connection) { var category1 = { name: \"TypeScript\" }; var category2 = { name: \"Programming\" }; var post = { title: \"Control flow based type analysis\", text: \"TypeScript 2.0 implements a control flow-based type analysis for local variables and parameters.\", categories: [ category1, category2 ] }; var postRepository = connection.getRepository(\"Post\"); postRepository.save(post) .then(function(savedPost) { console.log(\"Post has been saved: \", savedPost); console.log(\"Now lets load all posts: \"); return postRepository.find(); }) .then(function(allPosts) { console.log(\"All posts: \", allPosts); }); }).catch(function(error) { console.log(\"Error: \", error); });","title":"app.js"},{"location":"usage-with-javascript/#entitycategoryjs","text":"var EntitySchema = require(\"typeorm\").EntitySchema; module.exports = new EntitySchema({ name: \"Category\", // Will use table name `category` as default behaviour. tableName: \"categories\", // Optional: Provide `tableName` property to override the default behaviour for table name. columns: { id: { primary: true, type: \"int\", generated: true }, name: { type: \"varchar\" } } });","title":"entity/Category.js"},{"location":"usage-with-javascript/#entitypostjs","text":"var EntitySchema = require(\"typeorm\").EntitySchema; module.exports = new EntitySchema({ name: \"Post\", // Will use table name `post` as default behaviour. tableName: \"posts\", // Optional: Provide `tableName` property to override the default behaviour for table name. columns: { id: { primary: true, type: \"int\", generated: true }, title: { type: \"varchar\" }, text: { type: \"text\" } }, relations: { categories: { target: \"Category\", type: \"many-to-many\", joinTable: true, cascade: true } } }); You can checkout this example typeorm/javascript-example to learn more.","title":"entity/Post.js"},{"location":"using-cli/","text":"Using CLI Installing CLI Initialize a new TypeORM project Create a new entity Create a new subscriber Create a new migration Generate a migration from existing table schema Run migrations Revert migrations Show migrations Sync database schema Log sync database schema queries without actual running them Drop database schema Run any sql query Clear cache Check version Installing CLI If entities files are in javascript If you have a local typeorm version, make sure it matches the global version we are going to install. Install typeorm globally with npm i -g typeorm . You can also chose to use npx typeorm <params> for each command if you prefer not having to install it. If entities files are in typescript This CLI tool is written in javascript and to be run on node. If your entity files are in typescript, you will need to transpile them to javascript before using CLI. You may skip this section if you only use javascript. You may setup ts-node in your project to ease the operation as follows: Install ts-node globally: npm install -g ts-node Add typeorm command under scripts section in package.json \"scripts\": { ... \"typeorm\": \"node --require ts-node/register ./node_modules/typeorm/cli.js\" } If you want to load more modules like module-alias you can add more --require my-module-supporting-register Then you may run the command like this: npm run typeorm migration:run If you need to pass parameter with dash to npm script, you will need to add them after --. For example, if you need to generate , the command is like this: npm run typeorm migration:generate -- -n migrationNameHere How to read the documentation To reduce verbosity of the documentation, the following sections are using a globally installed typeorm CLI. Depending on how you installed the CLI, you may replace typeorm at the start of the command, by either npx typeorm or npm run typeorm . Initialize a new TypeORM project You can create a new project with everything already setup: typeorm init It creates all files needed for a basic project with TypeORM: .gitignore package.json README.md tsconfig.json ormconfig.json src/entity/User.ts src/index.ts Then you can run npm install to install all dependencies. Once all dependencies are installed, you need to modify ormconfig.json and insert your own database settings. After that, you can run your application by running npm start . All files are generated in the current directory. If you want to generate them in a special directory you can use --name : typeorm init --name my-project To specify a specific database you use you can use --database : typeorm init --database mssql You can also generate a base project with Express: typeorm init --name my-project --express If you are using docker you can generate a docker-compose.yml file using: typeorm init --docker typeorm init is the easiest and fastest way to setup a TypeORM project. Create a new entity You can create a new entity using CLI: typeorm entity:create -n User where User is an entity file and class name. Running the command will create a new empty entity in entitiesDir of the project. To setup the entitiesDir of the project you must add it in connection options: { cli: { entitiesDir: \"src/entity\" } } Learn more about connection options . If you have a multi-module project structure with multiple entities in different directories you can provide the path to the CLI command where you want to generate an entity: typeorm entity:create -n User -d src/user/entity Learn more about entities . Create a new subscriber You can create a new subscriber using CLI: typeorm subscriber:create -n UserSubscriber where UserSubscriber is a subscriber file and class name. Running the following command will create a new empty subscriber in the subscribersDir of the project. To setup subscribersDir you must add it in connection options: { cli: { subscribersDir: \"src/subscriber\" } } Learn more about connection options . If you have a multi-module project structure with multiple subscribers in different directories you can provide a path to the CLI command where you want to generate a subscriber: typeorm subscriber:create -n UserSubscriber -d src/user/subscriber Learn more about Subscribers . Create a new migration You can create a new migration using CLI: typeorm migration:create -n UserMigration where UserMigration is a migration file and class name. Running the command will create a new empty migration in the migrationsDir of the project. To setup migrationsDir you must add it in connection options: { cli: { migrationsDir: \"src/migration\" } } Learn more about connection options . If you have a multi-module project structure with multiple migrations in different directories you can provide a path to the CLI command where you want to generate a migration: typeorm migration:create -n UserMigration -d src/user/migration Learn more about Migrations . Generate a migration from existing table schema Automatic migration generation creates a new migration file and writes all sql queries that must be executed to update the database. If no there were no changes generated, the command will exit with code 1. typeorm migration:generate -n UserMigration The rule of thumb is to generate a migration after each entity change. Learn more about Migrations . Run migrations To execute all pending migrations use following command: typeorm migration:run Learn more about Migrations . Revert migrations To revert the most recently executed migration use the following command: typeorm migration:revert This command will undo only the last executed migration. You can execute this command multiple times to revert multiple migrations. Learn more about Migrations . Show migrations To show all migrations and whether they've been run or not use following command: typeorm migration:show [X] = Migration has been ran [ ] = Migration is pending/unapplied This command also returns an error code if there are unapplied migrations. Sync database schema To synchronize a database schema use: typeorm schema:sync Be careful running this command in production - schema sync may cause data loss if you don't use it wisely. Check which sql queries it will run before running on production. Log sync database schema queries without actual running them To check what sql queries schema:sync is going to run use: typeorm schema:log Drop database schema To completely drop a database schema use: typeorm schema:drop Be careful with this command on production since it completely removes data from your database. Run any sql query You can execute any sql query you want directly in the database using: typeorm query \"SELECT * FROM USERS\" Clear cache If you are using QueryBuilder caching, sometimes you may want to clear everything stored in the cache. You can do it using the following command: typeorm cache:clear Check version You can check what typeorm version you have installed (both local and global) by running: typeorm version","title":"Using CLI"},{"location":"using-cli/#using-cli","text":"Installing CLI Initialize a new TypeORM project Create a new entity Create a new subscriber Create a new migration Generate a migration from existing table schema Run migrations Revert migrations Show migrations Sync database schema Log sync database schema queries without actual running them Drop database schema Run any sql query Clear cache Check version","title":"Using CLI"},{"location":"using-cli/#installing-cli","text":"","title":"Installing CLI"},{"location":"using-cli/#if-entities-files-are-in-javascript","text":"If you have a local typeorm version, make sure it matches the global version we are going to install. Install typeorm globally with npm i -g typeorm . You can also chose to use npx typeorm <params> for each command if you prefer not having to install it.","title":"If entities files are in javascript"},{"location":"using-cli/#if-entities-files-are-in-typescript","text":"This CLI tool is written in javascript and to be run on node. If your entity files are in typescript, you will need to transpile them to javascript before using CLI. You may skip this section if you only use javascript. You may setup ts-node in your project to ease the operation as follows: Install ts-node globally: npm install -g ts-node Add typeorm command under scripts section in package.json \"scripts\": { ... \"typeorm\": \"node --require ts-node/register ./node_modules/typeorm/cli.js\" } If you want to load more modules like module-alias you can add more --require my-module-supporting-register Then you may run the command like this: npm run typeorm migration:run If you need to pass parameter with dash to npm script, you will need to add them after --. For example, if you need to generate , the command is like this: npm run typeorm migration:generate -- -n migrationNameHere","title":"If entities files are in typescript"},{"location":"using-cli/#how-to-read-the-documentation","text":"To reduce verbosity of the documentation, the following sections are using a globally installed typeorm CLI. Depending on how you installed the CLI, you may replace typeorm at the start of the command, by either npx typeorm or npm run typeorm .","title":"How to read the documentation"},{"location":"using-cli/#initialize-a-new-typeorm-project","text":"You can create a new project with everything already setup: typeorm init It creates all files needed for a basic project with TypeORM: .gitignore package.json README.md tsconfig.json ormconfig.json src/entity/User.ts src/index.ts Then you can run npm install to install all dependencies. Once all dependencies are installed, you need to modify ormconfig.json and insert your own database settings. After that, you can run your application by running npm start . All files are generated in the current directory. If you want to generate them in a special directory you can use --name : typeorm init --name my-project To specify a specific database you use you can use --database : typeorm init --database mssql You can also generate a base project with Express: typeorm init --name my-project --express If you are using docker you can generate a docker-compose.yml file using: typeorm init --docker typeorm init is the easiest and fastest way to setup a TypeORM project.","title":"Initialize a new TypeORM project"},{"location":"using-cli/#create-a-new-entity","text":"You can create a new entity using CLI: typeorm entity:create -n User where User is an entity file and class name. Running the command will create a new empty entity in entitiesDir of the project. To setup the entitiesDir of the project you must add it in connection options: { cli: { entitiesDir: \"src/entity\" } } Learn more about connection options . If you have a multi-module project structure with multiple entities in different directories you can provide the path to the CLI command where you want to generate an entity: typeorm entity:create -n User -d src/user/entity Learn more about entities .","title":"Create a new entity"},{"location":"using-cli/#create-a-new-subscriber","text":"You can create a new subscriber using CLI: typeorm subscriber:create -n UserSubscriber where UserSubscriber is a subscriber file and class name. Running the following command will create a new empty subscriber in the subscribersDir of the project. To setup subscribersDir you must add it in connection options: { cli: { subscribersDir: \"src/subscriber\" } } Learn more about connection options . If you have a multi-module project structure with multiple subscribers in different directories you can provide a path to the CLI command where you want to generate a subscriber: typeorm subscriber:create -n UserSubscriber -d src/user/subscriber Learn more about Subscribers .","title":"Create a new subscriber"},{"location":"using-cli/#create-a-new-migration","text":"You can create a new migration using CLI: typeorm migration:create -n UserMigration where UserMigration is a migration file and class name. Running the command will create a new empty migration in the migrationsDir of the project. To setup migrationsDir you must add it in connection options: { cli: { migrationsDir: \"src/migration\" } } Learn more about connection options . If you have a multi-module project structure with multiple migrations in different directories you can provide a path to the CLI command where you want to generate a migration: typeorm migration:create -n UserMigration -d src/user/migration Learn more about Migrations .","title":"Create a new migration"},{"location":"using-cli/#generate-a-migration-from-existing-table-schema","text":"Automatic migration generation creates a new migration file and writes all sql queries that must be executed to update the database. If no there were no changes generated, the command will exit with code 1. typeorm migration:generate -n UserMigration The rule of thumb is to generate a migration after each entity change. Learn more about Migrations .","title":"Generate a migration from existing table schema"},{"location":"using-cli/#run-migrations","text":"To execute all pending migrations use following command: typeorm migration:run Learn more about Migrations .","title":"Run migrations"},{"location":"using-cli/#revert-migrations","text":"To revert the most recently executed migration use the following command: typeorm migration:revert This command will undo only the last executed migration. You can execute this command multiple times to revert multiple migrations. Learn more about Migrations .","title":"Revert migrations"},{"location":"using-cli/#show-migrations","text":"To show all migrations and whether they've been run or not use following command: typeorm migration:show [X] = Migration has been ran [ ] = Migration is pending/unapplied This command also returns an error code if there are unapplied migrations.","title":"Show migrations"},{"location":"using-cli/#sync-database-schema","text":"To synchronize a database schema use: typeorm schema:sync Be careful running this command in production - schema sync may cause data loss if you don't use it wisely. Check which sql queries it will run before running on production.","title":"Sync database schema"},{"location":"using-cli/#log-sync-database-schema-queries-without-actual-running-them","text":"To check what sql queries schema:sync is going to run use: typeorm schema:log","title":"Log sync database schema queries without actual running them"},{"location":"using-cli/#drop-database-schema","text":"To completely drop a database schema use: typeorm schema:drop Be careful with this command on production since it completely removes data from your database.","title":"Drop database schema"},{"location":"using-cli/#run-any-sql-query","text":"You can execute any sql query you want directly in the database using: typeorm query \"SELECT * FROM USERS\"","title":"Run any sql query"},{"location":"using-cli/#clear-cache","text":"If you are using QueryBuilder caching, sometimes you may want to clear everything stored in the cache. You can do it using the following command: typeorm cache:clear","title":"Clear cache"},{"location":"using-cli/#check-version","text":"You can check what typeorm version you have installed (both local and global) by running: typeorm version","title":"Check version"},{"location":"using-ormconfig/","text":"Using Configuration Sources Creating a new connection from the configuration file Using ormconfig.json Using ormconfig.js Using environment variables Using ormconfig.yml Using ormconfig.xml Overriding options defined in ormconfig Creating a new connection from the configuration file Most of the times you want to store your connection options in a separate configuration file. It makes it convenient and easy to manage. TypeORM supports multiple configuration sources. You only need to create a ormconfig.[format] file in the root directory of your application (near package.json ), put your configuration there and in your app call createConnection() without any configuration passed: import {createConnection} from \"typeorm\"; // createConnection method will automatically read connection options // from your ormconfig file or environment variables const connection = await createConnection(); Supported ormconfig file formats are: .json , .js , .ts , .env , .yml and .xml . Using ormconfig.json Create ormconfig.json in the project root (near package.json ). It should have the following content: { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } You can specify any other options from ConnectionOptions . If you want to create multiple connections then simply create multiple connections in a single array: [{ \"name\": \"default\", \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" }, { \"name\": \"second-connection\", \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" }] Using ormconfig.js Create ormconfig.js in the project root (near package.json ). It should have following content: module.exports = { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } Alternatively, you may use the ECMAScript module format if your environment supports it: export default { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } You can specify any other options from ConnectionOptions . If you want to create multiple connections then simply create multiple connections in a single array and return it. Using environment variables Create .env or ormconfig.env in the project root (near package.json ). It should have the following content: TYPEORM_CONNECTION = mysql TYPEORM_HOST = localhost TYPEORM_USERNAME = root TYPEORM_PASSWORD = admin TYPEORM_DATABASE = test TYPEORM_PORT = 3000 TYPEORM_SYNCHRONIZE = true TYPEORM_LOGGING = true TYPEORM_ENTITIES = entity/*.js,modules/**/entity/*.js List of available env variables you can set: TYPEORM_CACHE TYPEORM_CACHE_ALWAYS_ENABLED TYPEORM_CACHE_DURATION TYPEORM_CACHE_OPTIONS TYPEORM_CONNECTION TYPEORM_DATABASE TYPEORM_DEBUG TYPEORM_DRIVER_EXTRA TYPEORM_DROP_SCHEMA TYPEORM_ENTITIES TYPEORM_ENTITIES_DIR TYPEORM_ENTITY_PREFIX TYPEORM_HOST TYPEORM_LOGGER TYPEORM_LOGGING TYPEORM_MAX_QUERY_EXECUTION_TIME TYPEORM_MIGRATIONS TYPEORM_MIGRATIONS_DIR TYPEORM_MIGRATIONS_RUN TYPEORM_MIGRATIONS_TABLE_NAME TYPEORM_PASSWORD TYPEORM_PORT TYPEORM_SCHEMA TYPEORM_SID TYPEORM_SUBSCRIBERS TYPEORM_SUBSCRIBERS_DIR TYPEORM_SYNCHRONIZE TYPEORM_URL TYPEORM_USERNAME TYPEORM_UUID_EXTENSION TYPEORM_CACHE should be boolean or string of cache type ormconfig.env should be used only during development. On production you can set all these values in real ENVIRONMENT VARIABLES. You cannot define multiple connections using an env file or environment variables. If your app has multiple connections then use alternative configuration storage format. If you need to pass a driver-specific option, e.g. charset for MySQL, you could use the TYPEORM_DRIVER_EXTRA variable in JSON format, e.g. TYPEORM_DRIVER_EXTRA='{\"charset\": \"utf8mb4\"}' Using ormconfig.yml Create ormconfig.yml in the project root (near package.json ). It should have the following content: default: # default connection host: \"localhost\" port: 3306 username: \"test\" password: \"test\" database: \"test\" second-connection: # other connection host: \"localhost\" port: 3306 username: \"test\" password: \"test\" database: \"test2\" You can use any connection options available. Using ormconfig.xml Create ormconfig.xml in the project root (near package.json ). It should have the following content: <connections> <connection type=\"mysql\" name=\"default\"> <host>localhost</host> <username>root</username> <password>admin</password> <database>test</database> <port>3000</port> <logging>true</logging> </connection> <connection type=\"mysql\" name=\"second-connection\"> <host>localhost</host> <username>root</username> <password>admin</password> <database>test2</database> <port>3000</port> <logging>true</logging> </connection> </connections> You can use any connection options available. Which configuration file is used by Typeorm Sometimes, you may want to use multiple configurations using different formats. When calling getConnectionOptions() or attempting to use createConnection() without the connection options, Typeorm will attempt to load the configurations, in this order: From the environment variables. Typeorm will attempt to load the .env file using dotEnv if it exists. If the environment variables TYPEORM_CONNECTION or TYPEORM_URL are set, Typeorm will use this method. From the ormconfig.env . From the other ormconfig.[format] files, in this order: [js, ts, json, yml, yaml, xml] . Note that Typeorm will use the first valid method found and will not load the others. For example, Typeorm will not load the ormconfig.[format] files if the configuration was found in the environment. Overriding options defined in ormconfig Sometimes you want to override values defined in your ormconfig file, or you might want to append some TypeScript / JavaScript logic to your configuration. In such cases you can load options from ormconfig and get ConnectionOptions built, then you can do whatever you want with those options, before passing them to createConnection function: // read connection options from ormconfig file (or ENV variables) const connectionOptions = await getConnectionOptions(); // do something with connectionOptions, // for example append a custom naming strategy or a custom logger Object.assign(connectionOptions, { namingStrategy: new MyNamingStrategy() }); // create a connection using modified connection options const connection = await createConnection(connectionOptions);","title":"Using Configuration Sources"},{"location":"using-ormconfig/#using-configuration-sources","text":"Creating a new connection from the configuration file Using ormconfig.json Using ormconfig.js Using environment variables Using ormconfig.yml Using ormconfig.xml Overriding options defined in ormconfig","title":"Using Configuration Sources"},{"location":"using-ormconfig/#creating-a-new-connection-from-the-configuration-file","text":"Most of the times you want to store your connection options in a separate configuration file. It makes it convenient and easy to manage. TypeORM supports multiple configuration sources. You only need to create a ormconfig.[format] file in the root directory of your application (near package.json ), put your configuration there and in your app call createConnection() without any configuration passed: import {createConnection} from \"typeorm\"; // createConnection method will automatically read connection options // from your ormconfig file or environment variables const connection = await createConnection(); Supported ormconfig file formats are: .json , .js , .ts , .env , .yml and .xml .","title":"Creating a new connection from the configuration file"},{"location":"using-ormconfig/#using-ormconfigjson","text":"Create ormconfig.json in the project root (near package.json ). It should have the following content: { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } You can specify any other options from ConnectionOptions . If you want to create multiple connections then simply create multiple connections in a single array: [{ \"name\": \"default\", \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" }, { \"name\": \"second-connection\", \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" }]","title":"Using ormconfig.json"},{"location":"using-ormconfig/#using-ormconfigjs","text":"Create ormconfig.js in the project root (near package.json ). It should have following content: module.exports = { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } Alternatively, you may use the ECMAScript module format if your environment supports it: export default { \"type\": \"mysql\", \"host\": \"localhost\", \"port\": 3306, \"username\": \"test\", \"password\": \"test\", \"database\": \"test\" } You can specify any other options from ConnectionOptions . If you want to create multiple connections then simply create multiple connections in a single array and return it.","title":"Using ormconfig.js"},{"location":"using-ormconfig/#using-environment-variables","text":"Create .env or ormconfig.env in the project root (near package.json ). It should have the following content: TYPEORM_CONNECTION = mysql TYPEORM_HOST = localhost TYPEORM_USERNAME = root TYPEORM_PASSWORD = admin TYPEORM_DATABASE = test TYPEORM_PORT = 3000 TYPEORM_SYNCHRONIZE = true TYPEORM_LOGGING = true TYPEORM_ENTITIES = entity/*.js,modules/**/entity/*.js List of available env variables you can set: TYPEORM_CACHE TYPEORM_CACHE_ALWAYS_ENABLED TYPEORM_CACHE_DURATION TYPEORM_CACHE_OPTIONS TYPEORM_CONNECTION TYPEORM_DATABASE TYPEORM_DEBUG TYPEORM_DRIVER_EXTRA TYPEORM_DROP_SCHEMA TYPEORM_ENTITIES TYPEORM_ENTITIES_DIR TYPEORM_ENTITY_PREFIX TYPEORM_HOST TYPEORM_LOGGER TYPEORM_LOGGING TYPEORM_MAX_QUERY_EXECUTION_TIME TYPEORM_MIGRATIONS TYPEORM_MIGRATIONS_DIR TYPEORM_MIGRATIONS_RUN TYPEORM_MIGRATIONS_TABLE_NAME TYPEORM_PASSWORD TYPEORM_PORT TYPEORM_SCHEMA TYPEORM_SID TYPEORM_SUBSCRIBERS TYPEORM_SUBSCRIBERS_DIR TYPEORM_SYNCHRONIZE TYPEORM_URL TYPEORM_USERNAME TYPEORM_UUID_EXTENSION TYPEORM_CACHE should be boolean or string of cache type ormconfig.env should be used only during development. On production you can set all these values in real ENVIRONMENT VARIABLES. You cannot define multiple connections using an env file or environment variables. If your app has multiple connections then use alternative configuration storage format. If you need to pass a driver-specific option, e.g. charset for MySQL, you could use the TYPEORM_DRIVER_EXTRA variable in JSON format, e.g. TYPEORM_DRIVER_EXTRA='{\"charset\": \"utf8mb4\"}'","title":"Using environment variables"},{"location":"using-ormconfig/#using-ormconfigyml","text":"Create ormconfig.yml in the project root (near package.json ). It should have the following content: default: # default connection host: \"localhost\" port: 3306 username: \"test\" password: \"test\" database: \"test\" second-connection: # other connection host: \"localhost\" port: 3306 username: \"test\" password: \"test\" database: \"test2\" You can use any connection options available.","title":"Using ormconfig.yml"},{"location":"using-ormconfig/#using-ormconfigxml","text":"Create ormconfig.xml in the project root (near package.json ). It should have the following content: <connections> <connection type=\"mysql\" name=\"default\"> <host>localhost</host> <username>root</username> <password>admin</password> <database>test</database> <port>3000</port> <logging>true</logging> </connection> <connection type=\"mysql\" name=\"second-connection\"> <host>localhost</host> <username>root</username> <password>admin</password> <database>test2</database> <port>3000</port> <logging>true</logging> </connection> </connections> You can use any connection options available.","title":"Using ormconfig.xml"},{"location":"using-ormconfig/#which-configuration-file-is-used-by-typeorm","text":"Sometimes, you may want to use multiple configurations using different formats. When calling getConnectionOptions() or attempting to use createConnection() without the connection options, Typeorm will attempt to load the configurations, in this order: From the environment variables. Typeorm will attempt to load the .env file using dotEnv if it exists. If the environment variables TYPEORM_CONNECTION or TYPEORM_URL are set, Typeorm will use this method. From the ormconfig.env . From the other ormconfig.[format] files, in this order: [js, ts, json, yml, yaml, xml] . Note that Typeorm will use the first valid method found and will not load the others. For example, Typeorm will not load the ormconfig.[format] files if the configuration was found in the environment.","title":"Which configuration file is used by Typeorm"},{"location":"using-ormconfig/#overriding-options-defined-in-ormconfig","text":"Sometimes you want to override values defined in your ormconfig file, or you might want to append some TypeScript / JavaScript logic to your configuration. In such cases you can load options from ormconfig and get ConnectionOptions built, then you can do whatever you want with those options, before passing them to createConnection function: // read connection options from ormconfig file (or ENV variables) const connectionOptions = await getConnectionOptions(); // do something with connectionOptions, // for example append a custom naming strategy or a custom logger Object.assign(connectionOptions, { namingStrategy: new MyNamingStrategy() }); // create a connection using modified connection options const connection = await createConnection(connectionOptions);","title":"Overriding options defined in ormconfig"},{"location":"validation/","text":"Using Validation To use validation use class-validator . Example how to use class-validator with TypeORM: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Contains, IsInt, Length, IsEmail, IsFQDN, IsDate, Min, Max} from \"class-validator\"; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() @Length(10, 20) title: string; @Column() @Contains(\"hello\") text: string; @Column() @IsInt() @Min(0) @Max(10) rating: number; @Column() @IsEmail() email: string; @Column() @IsFQDN() site: string; @Column() @IsDate() createDate: Date; } Validation: import {getManager} from \"typeorm\"; import {validate} from \"class-validator\"; let post = new Post(); post.title = \"Hello\"; // should not pass post.text = \"this is a great post about hell world\"; // should not pass post.rating = 11; // should not pass post.email = \"google.com\"; // should not pass post.site = \"googlecom\"; // should not pass const errors = await validate(post); if (errors.length > 0) { throw new Error(`Validation failed!`); } else { await getManager().save(post); }","title":"Using Validation"},{"location":"validation/#using-validation","text":"To use validation use class-validator . Example how to use class-validator with TypeORM: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; import {Contains, IsInt, Length, IsEmail, IsFQDN, IsDate, Min, Max} from \"class-validator\"; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() @Length(10, 20) title: string; @Column() @Contains(\"hello\") text: string; @Column() @IsInt() @Min(0) @Max(10) rating: number; @Column() @IsEmail() email: string; @Column() @IsFQDN() site: string; @Column() @IsDate() createDate: Date; } Validation: import {getManager} from \"typeorm\"; import {validate} from \"class-validator\"; let post = new Post(); post.title = \"Hello\"; // should not pass post.text = \"this is a great post about hell world\"; // should not pass post.rating = 11; // should not pass post.email = \"google.com\"; // should not pass post.site = \"googlecom\"; // should not pass const errors = await validate(post); if (errors.length > 0) { throw new Error(`Validation failed!`); } else { await getManager().save(post); }","title":"Using Validation"},{"location":"view-entities/","text":"View Entities What is View Entity? View Entity columns Complete example What is View Entity? View entity is a class that maps to a database view. You can create a view entity by defining a new class and mark it with @ViewEntity() : @ViewEntity() accepts following options: name - view name. If not specified, then view name is generated from entity class name. database - database name in selected DB server. schema - schema name. expression - view definition. Required parameter . expression can be string with properly escaped columns and tables, depend on database used (postgres in example): @ViewEntity({ expression: ` SELECT \"post\".\"id\" AS \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) or an instance of QueryBuilder @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) Note: parameter binding is not supported due to drivers limitations. Use the literal parameters instead. @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") .where(\"category.name = :name\", { name: \"Cars\" }) // <-- this is wrong .where(\"category.name = 'Cars'\") // <-- and this is right }) Each view entity must be registered in your connection options: import {createConnection, Connection} from \"typeorm\"; import {UserView} from \"./entity/UserView\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [UserView] }); Or you can specify the whole directory with all entities inside - and all of them will be loaded: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [\"entity/*.js\"] }); View Entity columns To map data from view into the correct entity columns you must mark entity columns with @ViewColumn() decorator and specify these columns as select statement aliases. example with string expression definition: import {ViewEntity, ViewColumn} from \"typeorm\"; @ViewEntity({ expression: ` SELECT \"post\".\"id\" AS \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; } example using QueryBuilder: import {ViewEntity, ViewColumn} from \"typeorm\"; @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; } Complete example Let create two entities and a view containing aggregated data from these entities: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; } import {Entity, PrimaryGeneratedColumn, Column, ManyToOne, JoinColumn} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() categoryId: number; @ManyToOne(() => Category) @JoinColumn({ name: \"categoryId\" }) category: Category; } import {ViewEntity, ViewColumn, Connection} from \"typeorm\"; @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; } then fill these tables with data and request all data from PostCategory view: import {getManager} from \"typeorm\"; import {Category} from \"./entity/Category\"; import {Post} from \"./entity/Post\"; import {PostCategory} from \"./entity/PostCategory\"; const entityManager = getManager(); const category1 = new Category(); category1.name = \"Cars\"; await entityManager.save(category1); const category2 = new Category(); category2.name = \"Airplanes\"; await entityManager.save(category2); const post1 = new Post(); post1.name = \"About BMW\"; post1.categoryId = category1.id; await entityManager.save(post1); const post2 = new Post(); post2.name = \"About Boeing\"; post2.categoryId = category2.id; await entityManager.save(post2); const postCategories = await entityManager.find(PostCategory); const postCategory = await entityManager.findOne(PostCategory, { id: 1 }); the result in postCategories will be: [ PostCategory { id: 1, name: 'About BMW', categoryName: 'Cars' }, PostCategory { id: 2, name: 'About Boeing', categoryName: 'Airplanes' } ] and in postCategory : PostCategory { id: 1, name: 'About BMW', categoryName: 'Cars' }","title":"View Entities"},{"location":"view-entities/#view-entities","text":"What is View Entity? View Entity columns Complete example","title":"View Entities"},{"location":"view-entities/#what-is-view-entity","text":"View entity is a class that maps to a database view. You can create a view entity by defining a new class and mark it with @ViewEntity() : @ViewEntity() accepts following options: name - view name. If not specified, then view name is generated from entity class name. database - database name in selected DB server. schema - schema name. expression - view definition. Required parameter . expression can be string with properly escaped columns and tables, depend on database used (postgres in example): @ViewEntity({ expression: ` SELECT \"post\".\"id\" AS \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) or an instance of QueryBuilder @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) Note: parameter binding is not supported due to drivers limitations. Use the literal parameters instead. @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") .where(\"category.name = :name\", { name: \"Cars\" }) // <-- this is wrong .where(\"category.name = 'Cars'\") // <-- and this is right }) Each view entity must be registered in your connection options: import {createConnection, Connection} from \"typeorm\"; import {UserView} from \"./entity/UserView\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [UserView] }); Or you can specify the whole directory with all entities inside - and all of them will be loaded: import {createConnection, Connection} from \"typeorm\"; const connection: Connection = await createConnection({ type: \"mysql\", host: \"localhost\", port: 3306, username: \"test\", password: \"test\", database: \"test\", entities: [\"entity/*.js\"] });","title":"What is View Entity?"},{"location":"view-entities/#view-entity-columns","text":"To map data from view into the correct entity columns you must mark entity columns with @ViewColumn() decorator and specify these columns as select statement aliases. example with string expression definition: import {ViewEntity, ViewColumn} from \"typeorm\"; @ViewEntity({ expression: ` SELECT \"post\".\"id\" AS \"id\", \"post\".\"name\" AS \"name\", \"category\".\"name\" AS \"categoryName\" FROM \"post\" \"post\" LEFT JOIN \"category\" \"category\" ON \"post\".\"categoryId\" = \"category\".\"id\" ` }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; } example using QueryBuilder: import {ViewEntity, ViewColumn} from \"typeorm\"; @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; }","title":"View Entity columns"},{"location":"view-entities/#complete-example","text":"Let create two entities and a view containing aggregated data from these entities: import {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\"; @Entity() export class Category { @PrimaryGeneratedColumn() id: number; @Column() name: string; } import {Entity, PrimaryGeneratedColumn, Column, ManyToOne, JoinColumn} from \"typeorm\"; import {Category} from \"./Category\"; @Entity() export class Post { @PrimaryGeneratedColumn() id: number; @Column() name: string; @Column() categoryId: number; @ManyToOne(() => Category) @JoinColumn({ name: \"categoryId\" }) category: Category; } import {ViewEntity, ViewColumn, Connection} from \"typeorm\"; @ViewEntity({ expression: (connection: Connection) => connection.createQueryBuilder() .select(\"post.id\", \"id\") .addSelect(\"post.name\", \"name\") .addSelect(\"category.name\", \"categoryName\") .from(Post, \"post\") .leftJoin(Category, \"category\", \"category.id = post.categoryId\") }) export class PostCategory { @ViewColumn() id: number; @ViewColumn() name: string; @ViewColumn() categoryName: string; } then fill these tables with data and request all data from PostCategory view: import {getManager} from \"typeorm\"; import {Category} from \"./entity/Category\"; import {Post} from \"./entity/Post\"; import {PostCategory} from \"./entity/PostCategory\"; const entityManager = getManager(); const category1 = new Category(); category1.name = \"Cars\"; await entityManager.save(category1); const category2 = new Category(); category2.name = \"Airplanes\"; await entityManager.save(category2); const post1 = new Post(); post1.name = \"About BMW\"; post1.categoryId = category1.id; await entityManager.save(post1); const post2 = new Post(); post2.name = \"About Boeing\"; post2.categoryId = category2.id; await entityManager.save(post2); const postCategories = await entityManager.find(PostCategory); const postCategory = await entityManager.findOne(PostCategory, { id: 1 }); the result in postCategories will be: [ PostCategory { id: 1, name: 'About BMW', categoryName: 'Cars' }, PostCategory { id: 2, name: 'About Boeing', categoryName: 'Airplanes' } ] and in postCategory : PostCategory { id: 1, name: 'About BMW', categoryName: 'Cars' }","title":"Complete example"},{"location":"working-with-entity-manager/","text":"What is EntityManager Using EntityManager you can manage (insert, update, delete, load, etc.) any entity. EntityManager is just like a collection of all entity repositories in a single place. You can access the entity manager via getManager() or from Connection . Example how to use it: import {getManager} from \"typeorm\"; import {User} from \"./entity/User\"; const entityManager = getManager(); // you can also get it via getConnection().manager const user = await entityManager.findOne(User, 1); user.name = \"Umed\"; await entityManager.save(user);","title":"What is EntityManager"},{"location":"working-with-entity-manager/#what-is-entitymanager","text":"Using EntityManager you can manage (insert, update, delete, load, etc.) any entity. EntityManager is just like a collection of all entity repositories in a single place. You can access the entity manager via getManager() or from Connection . Example how to use it: import {getManager} from \"typeorm\"; import {User} from \"./entity/User\"; const entityManager = getManager(); // you can also get it via getConnection().manager const user = await entityManager.findOne(User, 1); user.name = \"Umed\"; await entityManager.save(user);","title":"What is EntityManager"},{"location":"working-with-repository/","text":"What is Repository Repository is just like EntityManager but its operations are limited to a concrete entity. You can access repository via getRepository(Entity) , Connection#getRepository , or EntityManager#getRepository . Example: import {getRepository} from \"typeorm\"; import {User} from \"./entity/User\"; const userRepository = getRepository(User); // you can also get it via getConnection().getRepository() or getManager().getRepository() const user = await userRepository.findOne(1); user.name = \"Umed\"; await userRepository.save(user); There are 3 types of repositories: * Repository - Regular repository for any entity. * TreeRepository - Repository, extensions of Repository used for tree-entities (like entities marked with @Tree decorator). Has special methods to work with tree structures. * MongoRepository - Repository with special functions used only with MongoDB.","title":"What is Repository"},{"location":"working-with-repository/#what-is-repository","text":"Repository is just like EntityManager but its operations are limited to a concrete entity. You can access repository via getRepository(Entity) , Connection#getRepository , or EntityManager#getRepository . Example: import {getRepository} from \"typeorm\"; import {User} from \"./entity/User\"; const userRepository = getRepository(User); // you can also get it via getConnection().getRepository() or getManager().getRepository() const user = await userRepository.findOne(1); user.name = \"Umed\"; await userRepository.save(user); There are 3 types of repositories: * Repository - Regular repository for any entity. * TreeRepository - Repository, extensions of Repository used for tree-entities (like entities marked with @Tree decorator). Has special methods to work with tree structures. * MongoRepository - Repository with special functions used only with MongoDB.","title":"What is Repository"}]}